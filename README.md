# Mini RAG / Chat Agent â€” AIâ€‘First Workflow

A minimal, productionâ€‘ready Retrievalâ€‘Augmented Generation (RAG) agent that:
- indexes a few local text/markdown files,
- serves a tiny chat UI + API to ask questions with context,
- documents the AIâ€‘assisted workflow,
- includes a smoke test and Docker + Fly.io deployment files.

> Works fully **offline for embeddings & retrieval** using `sentence-transformers/all-MiniLM-L6-v2`.  
> For generation, it can use any **OpenAIâ€‘compatible** endpoint (OpenAI, Groq API w/ proxy, local llama.cpp server, etc.).  
> If no LLM key is set, it returns a **grounded context answer fallback** (useful for demos).

---

## âœ¨ Features
- **FastAPI** app with HTMX/Tailwind mini UI (`/`), JSON endpoint (`/ask`), and ingestion endpoint (`/ingest`).
- **FAISS** vector index persisted to `app/index/`.
- **Local embeddings** via `sentence-transformers` (no API needed).
- **Pluggable LLM provider** (OpenAIâ€‘compatible) with `OPENAI_API_KEY` and optional `OPENAI_BASE_URL`.
- **Deterministic system prompt** to enforce *cite-from-context* answers.
- **Smoke test** with `pytest` to validate happyâ€‘path.
- **Dockerfile** and **Fly.io** manifest.
- **How I used AI** log stub in `AI_NOTES.md`.

---

## ðŸ§± Project Structure
```
mini-rag-agent/
â”œâ”€ app/
â”‚  â”œâ”€ main.py                # FastAPI app (UI + API)
â”‚  â”œâ”€ rag.py                 # RAG pipeline (retrieve, route, generate)
â”‚  â”œâ”€ embed.py               # Embedding & FAISS indexing helpers
â”‚  â”œâ”€ ai_providers.py        # OpenAI-compatible LLM wrapper + fallback
â”‚  â”œâ”€ index/
â”‚  â”‚  â”œâ”€ build_index.py      # CLI to (re)build index from /data
â”‚  â”‚  â””â”€ store/              # Persisted FAISS + meta
â”‚  â”œâ”€ templates/
â”‚  â”‚  â””â”€ index.html          # HTMX chat UI
â”‚  â””â”€ static/
â”‚     â””â”€ styles.css          # Minimal extras on top of Tailwind CDN
â”œâ”€ data/                     # Your notes (.md/.txt) go here
â”‚  â””â”€ sample/                # Example content
â”œâ”€ tests/
â”‚  â””â”€ test_smoke.py
â”œâ”€ scripts/
â”‚  â””â”€ dev.sh                 # one-liner dev run
â”œâ”€ .env.example
â”œâ”€ requirements.txt
â”œâ”€ Dockerfile
â”œâ”€ fly.toml
â”œâ”€ AI_NOTES.md               # Log how AI assisted you
â””â”€ README.md
```

---

## ðŸš€ Quick Start (Local)

**1) Python env**
```bash
python -m venv .venv && source .venv/bin/activate  # (Windows: .venv\Scripts\activate)
pip install -r requirements.txt
```

**2) (Optional) Configure LLM**
Create `.env` (or set shell env vars):
```
OPENAI_API_KEY=sk-...
# Optional if using a local/OpenAI-compatible endpoint:
# OPENAI_BASE_URL=http://localhost:11434/v1
# OPENAI_MODEL=gpt-4o-mini
```

**3) Build the index**
```bash
python app/index/build_index.py --src data --out app/index/store
```

**4) Run the app**
```bash
uvicorn app.main:app --reload --port 8000
```

Open http://localhost:8000 and ask questions!

---

## ðŸ§ª Test
```bash
pytest -q
```

---

## ðŸ³ Docker
```bash
docker build -t mini-rag-agent:latest .
docker run -it --rm -p 8000:8000   -e OPENAI_API_KEY=$OPENAI_API_KEY   mini-rag-agent:latest
```
Open http://localhost:8000

---

## ðŸ•Šï¸ Fly.io (minimal)
> Ensure you have `flyctl` installed and are logged in.

```bash
fly launch --now --copy-config --name mini-rag-agent-$(openssl rand -hex 3)
# or: fly deploy
```
**Notes**
- Fly uses the provided `Dockerfile` & `fly.toml`.
- For private data, mount a volume or bake into the image at build time.
- Set secrets:
```bash
fly secrets set OPENAI_API_KEY=...
# (Optional) OPENAI_BASE_URL=... OPENAI_MODEL=...
```

---

## ðŸ““ How I used AI
Record your AIâ€‘assisted workflow here: prompts, diffs, code suggestions, and how it sped you up. See `AI_NOTES.md` for a template.

---

## ðŸ”’ Security & Footguns
- Never ship API keys in the repo. Use env vars or Fly secrets.
- Validate user prompts if you index sensitive data.
- For large corpora, prefer chunkâ€‘aware reranking; see TODOs in `rag.py`.

---

## âœ… Bonus: Smoke Check Script
`tests/test_smoke.py` runs a tiny endâ€‘toâ€‘end check (ingest + ask).

---

## ðŸ“š Attribution
- `sentence-transformers/all-MiniLM-L6-v2`
- FAISS
- FastAPI, HTMX, Tailwind CDN

Enjoy!
"# Mini-RAG-Agent-chatbot" 
