[
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\1) Counting (Basics → Advanced).pdf",
    "page": 1,
    "text": "explain me all this topics in realy detailed as i am preparing for gate and i iwant to do top in \ngate exam i want u to explain me each topic with very easy example and then i want u to take \nupto gate level advancement\nPlease write in English language.\nAwesome—let’s nail these four pillars for GATE DA/CS: Counting, Permutation, Combination, and\nBinomial Probability. I’ll go from super-simple intuition →  standard formulas →  tricky constraints →\nGATE-level tactics, with small solved examples and quick practice at the end of each section.\n1) Counting (Basics →  Advanced)\nA. First principles\nRule of Sum (OR): If task A can be done in m ways and task B in n disjoint ways →  m + n.\nRule of Product (AND): If you do step1 in m ways and step2 in n ways (independent choices) →  m\n× n.\nEasy example: A password is 1 letter or 1 digit. Letters (26) + digits (10) = 36.\nEasy example (AND): A 4-digit"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\1) Counting (Basics → Advanced).pdf",
    "page": 1,
    "text": "PIN (0–9): .\nCommon constraints you’ll see\n“Cannot start with 0”\n“No repetition” vs “repetition allowed”\n“At least one vowel/even digit…” →  usually complement counting is easier.\nExample (no leading zero, repetition allowed): 4-digit number\n1st place: 9 (1–9), others: 10 each →  .\n10 =4 10000\n9⋅10 =3 9000\nPrinted using ChatGPT to PDF, powered by PDFCrowd HTML to PDF API. 1/14"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\1) Counting (Basics → Advanced).pdf",
    "page": 2,
    "text": "B. Inclusion–Exclusion (PIE)\nCount “A or B (or C…)” when sets overlap.\nExample (classic GATE ﬂavor): Integers 1..100 divisible by 2 or 5 or 7.\nDivisible by 2: 50; by 5: 20; by 7: 14.\nPairs: by 10 →  10; by 14 →  7; by 35 →  2.\nTriple: by 70 →  1.\nTotal .\nC. Pigeonhole Principle (PHP)\nIf  objects in  boxes and  ⇒  some box has ≥ 2 objects.\nGATE-ish: Among 13 people, two share a birth-month (12 months ⇒  13>12).\n2) Permutations (Order matters)\nA. Distinct objects, no repetition\nArrange n distinct: \nArrange r chosen from n: \nEasy example: Arrange A,B,C on a shelf: .\nB. With repetition allowed\nLength-r string from an alphabet of size k: \nExample: 5-char string from lowercase (26): .\nC. With repeated items (multiset)\nIf word has counts  (sum ):\nExample: “BALLOON” (B1,A1,L2,O2,N1): .\nD. Circular permutations\nRound table, rotations identical: .\nIf reﬂections also identical (necklaces):  for .\n∣"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\1) Counting (Basics → Advanced).pdf",
    "page": 2,
    "text": "A∪B∣=∣A∣+∣B∣−∣A∩B∣, ∣A∪B∪C∣= ∣A ∣−∑ i ∣A ∩∑ i A ∣+j ∣A∩B∩C∣\n=50+20+14−(10+7+2)+1=66\nN k N>k\nn!\nP =n r\n \n(n−r)!\nn!\n3!=6\nkr\n265\nn  ,n  ,…,n  \n1 2 k =n\n \nn  !n  !⋯n  !1 2 k\nn!\n =2!2!7! 1260\n(n−1)!\n \n2(n−1)! n>2\nPrinted using ChatGPT to PDF, powered by PDFCrowd HTML to PDF API. 2/14"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\1) Counting (Basics → Advanced).pdf",
    "page": 3,
    "text": "Example: Seat 5 people around a round table: .\nE. “Together / Not together” tricks\nTogether: treat the group as a block.\nNot together: total −  together.\nExample: 6 people; A & B together.\nMake [AB] a block →  now 5 units ⇒  . Inside block AB/BA ⇒  ×2 →  240.\nF. Derangements (no element in its own place)\n (advanced but useful):\nor . Roughly .\n3) Combinations (Order doesn’t matter)\nA. Distinct objects, no repetition\nExample: Choose 3 books from 10: .\nB. With repetition (multicombinations; “stars & bars”)\nNumber of solutions to  with :\nIf  (at least one each): let  ⇒  total , so .\nEasy example: Distribute 7 identical balls into 4 boxes (allow empty):\n.\nAt least one per box: .\nC. Mixed constraints (typical exam traps)\n“At least / at most” →  convert via shift ( ≥ 1) or complement (total −  forbidden).\n“No two adjacent” →  use gaps method.\nExample (gaps): Place 4 identical balls into slots s"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\1) Counting (Basics → Advanced).pdf",
    "page": 3,
    "text": "o no two adjacent among 7 positions □ .\nThink of choosing 4 slots with at least 1 empty between ⇒  Equivalent to choose 4 from 7 with separation\n4!=24\n5!=120\n!n\n!n=n! 1−  +  −  +⋯+  ( 1!\n1\n2!\n1\n3!\n1\nn!\n(−1)n\n)\n!(n)=(n−1)(!(n−1)+!(n−2)) ≈  \nen!\nC =n r\n =r!(n−r)!\nn!\n \nr!\nnP \nr\nC =10 3 120\nx  +1 x  +2 ⋯+x  =k n x ≥i 0\nC  \nn+k−1 k−1\nx ≥i 1 y =i x −i 1 =n−k C  =(n−k)+k−1 k−1 C  \nn−1 k−1\nC  =7+4−1 4−1 C =10 3 120\nC  =7−1 4−1 C =6 3 20\nPrinted using ChatGPT to PDF, powered by PDFCrowd HTML to PDF API. 3/14"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\1) Counting (Basics → Advanced).pdf",
    "page": 4,
    "text": "→  use transformation  after ﬁxing mandatory gaps.\n4) Binomial Probability (Bernoulli trials)\nA. Model\n independent trials, each success with probability  (fail ).\nRandom variable  number of successes →  .\nPMF:  for .\nMean: ; Variance: .\nEasy example: Toss a fair coin 5 times, probability of exactly 2 heads:\n.\nQuality-control example (numbers computed): 10 items, defect prob .\nExactly 2 defectives: .\nAt least 1 defective: .\nMean defects , variance .\nB. Cumulative & complement tricks\n“At most r” = sum  or use complementary if shorter.\n“At least one” = .\nSymmetry for .\nC. Approximations (edge GATE)\nFor large , small , use Poisson with .\nFor large , moderate , use Normal with mean , var  (with continuity correction). These are\nrare but good to know.\nCommon Pitfalls (high-yield)\nMixing order: use permutations vs combinations correctly.\nLeading zero in numbers.\nMutual exclusivity vs independe"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\1) Counting (Basics → Advanced).pdf",
    "page": 4,
    "text": "nce (they’re diﬀerent).\nOvercounting when groups can be permuted internally (divide by  when order doesn’t matter).\nCircular vs linear arrangements.\nFor words with repeated letters: divide by repeat factorials.\ny ≥i 0\nn p q =1−p\nX= X∼Bin(n,p)\nPr[X=k]= C p qn k k n−k k=0,…,n\nE[X]=np Var(X)=npq\nC (0.5) (0.5) =5 2 2 3 10/32=0.3125\np=0.1\nC (0.1) (0.9) =10 2 2 8 45×0.01×0.43046721≈0.1937\n1−(0.9) ≈10 0.6513\n=np=1 =0.9\nk=0..r\n1−Pr[0]\np=  \n21\nn p λ=np\nn p np npq\nr!\nPrinted using ChatGPT to PDF, powered by PDFCrowd HTML to PDF API. 4/14"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\1) Counting (Basics → Advanced).pdf",
    "page": 5,
    "text": "Worked GATE-style mini set\nQ1 (Counting + complement)\nHow many 6-digit numbers (no leading zero) have at least one repeated digit?\nTotal 6-digit numbers: ﬁrst 9, others 10 ⇒  .\nWith all distinct digits: ﬁrst 9, then choose 5 from remaining 9 in order: \n.\nAnswer = .\nQ2 (PIE)\nHow many integers in 1..1000 are divisible by 3 or 5 or 7?\nCompute with PIE (similar to earlier), careful with 1000.\n/3: 333, /5: 200, /7: 142\npairs: /15: 66, /21: 47, /35: 28\ntriple: /105: 9\nAnswer .\nQ3 (Permutations with block)\nArrangements of the word ASSESS with the two S’s at the ends.\nLetters: A(1), S(4), E(1), S(we already count), total 6. Fix ends as S _ _ _ _ S →  remaining letters A,S,S,E to\narrange with S(2),A(1),E(1): .\nQ4 (Circular + restriction)\nSeat 6 people around a table so that A and B are not adjacent.\nTotal circular: . Together as a block: treat [AB] as one unit →  .\nNot adjacent =  ❌  (trap!)\nCorr"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\1) Counting (Basics → Advanced).pdf",
    "page": 5,
    "text": "ect: For circular with block: number of units = 5 ⇒  ; internal AB/BA ×2 ⇒  48.\nAnswer .\nQ5 (Stars & bars with caps)\nNumber of non-negative integer solutions to  with .\nTotal without cap: .\nSubtract : let  ⇒   ⇒  .\nAnswer .\nQ6 (Binomial)\nA fair die rolled 8 times. Probability of exactly two “6”s.\n.\n9⋅10 =5 900000\n9⋅ P =9 5 9⋅9⋅8⋅7⋅6⋅\n5=136,080\n900,000−136,080=763,920\n=(333+200+142)−(66+47+28)+9=543\n =2!4! 12\n5!=120 5!×2=240\n120−240\n4!=24\n=120−48=72\nx  +1 x  +2 x  =3 10 x  ≤1 4\nC  =10+3−1 3−1 C =12 2 66\nx  ≥1 5 x  =1′ x  −1 5 x  +1′ x  +2 x  =3 5 C =5+3−1 2 C =7 2 21\n=66−21=45\nC (1/6) (5/6)8 2 2 6\nPrinted using ChatGPT to PDF, powered by PDFCrowd HTML to PDF API. 5/14"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\1) Counting (Basics → Advanced).pdf",
    "page": 6,
    "text": "Quick Revision Sheet (memory hooks)\nSum/Product: OR →  +, AND →  ×.\nPIE 3-sets: .\nPermute: ; ; circular ; multiset .\nCombine: ; with repetition  (choose r from n types).\nStars & Bars: ; .\nBinomial: ; , .\nDerangements: .\nPractice (try now)\n1. How many 7-letter passwords using A–Z and digits 0–9 without repeating characters and must\nstart with a letter?\n2. Number of integers in 1..10,000 not divisible by 2, 3, or 5.\n3. Arrangements of MISSISSIPPI.\n4. Place 6 identical balls into 4 distinct boxes with each box holding at most 3 balls.\n5. A component works daily with probability . Over 50 days, probability it works on all 50 days; on\nat least 48 days (write the binomial sums).\nIf you want, I’ll check your answers and then we can step up to derangements proofs, advanced\nconstraints (caps + adjacency), combinatorial identities, and binomial approximations\n(Poisson/Normal) with tougher GATE PYQ"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\1) Counting (Basics → Advanced).pdf",
    "page": 6,
    "text": "s.\n∣A ∣−∑ i ∣A ∩∑ i A ∣+j ∣A ∩1 A ∩2 A ∣3\nn! nP \nr (n−1)!  \nn !∏ i\nn!\nnC \nr C \nn+r−1 r\nx  +1 ⋯+x  =k n,x ≥i 0⇒ C  \nn+k−1 k−1 x ≥i 1⇒ C  \nn−1 k−1\nP(X=k)= C p (1−n k k p)n−k E[X]=np Var=np(1−p)\n!n≈n!/e\n0.98\nPrinted using ChatGPT to PDF, powered by PDFCrowd HTML to PDF API. 6/14"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\1) Counting (Basics → Advanced).pdf",
    "page": 7,
    "text": "get me more details in each topic and with easy examples i want more and more example as i \nwant to clear my topic\nPlease write in English language.\nPerfect — let’s go deep dive into these four GATE-core topics:\nCounting →  Permutation →  Combination →  Binomial Probability, each explained from school-level\nintuition →  GATE-level reasoning, with many step-by-step examples and common traps.\n🌟  1. Counting Principles — the foundation of everything\nPrinted using ChatGPT to PDF, powered by PDFCrowd HTML to PDF API. 7/14"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\1) Counting (Basics → Advanced).pdf",
    "page": 8,
    "text": "🔹  Rule of Product (AND rule)\nIf one event can occur in m ways and another in n ways →  total = m × n.\nExample 1:\nA pizza shop oﬀers 3 crusts and 5 toppings.\n👉  Crust choice: 3 ways\n👉  Topping choice: 5 ways\n➡  Total = 3 × 5 = 15 pizzas\n🔹  Rule of Sum (OR rule)\nIf an event can occur in m ways or n ways (mutually exclusive) →  total = m + n.\nExample 2:\nYou can go to college by car (2 routes) or bus (3 routes).\nTotal = 2 + 3 = 5 ways.\n🔹  Both rules together\nExample 3:\nLicense plates →  2 letters + 2 digits\nLetters: 26 choices each →  26²\nDigits: 10 choices each →  10²\nTotal = 26² × 10² = 67600 plates\n🔹  Counting with restrictions\nExample 4: 4-digit number cannot start with 0\n→  ﬁrst place: 9 choices (1–9)\n→  rest: 10³ = 1000\nTotal = 9 × 1000 = 9000 numbers\nExample 5: 4-digit number no repetition\n→  ﬁrst: 9 (1–9)\n→  second: 9\n→  third: 8\n→  fourth: 7\nTotal = 9 × 9 × 8 × 7 = 4536\n🔹  Compleme"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\1) Counting (Basics → Advanced).pdf",
    "page": 8,
    "text": "nt rule\nSometimes it’s easier to count what you don’t want and subtract.\nExample 6:\nHow many 3-digit numbers have at least one 7?\n→  Total 3-digit numbers: 900 (100–999)\nPrinted using ChatGPT to PDF, powered by PDFCrowd HTML to PDF API. 8/14"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\1) Counting (Basics → Advanced).pdf",
    "page": 9,
    "text": "→  Without 7: each digit 9 options (no 7) →  9×9×9 = 729\n→  Answer = 900 −  729 = 171\n🔹  Inclusion–Exclusion (PIE)\nUsed when sets overlap (e.g., multiples of 2 or 3).\nExample 7:\nNumbers ≤ 30 divisible by 2 or 3\n|A| = 15 (2s), |B| = 10 (3s), |A ∩ B| = 5 (6s)\n→  |A ∪ B| = 15 + 10 −  5 = 20\n🔹  Pigeonhole Principle\nIf n items go into k boxes and n>k ⇒  some box has ≥ 2 items.\nExample 8: Among 13 people, two share a birth month (12 months).\n🌟  2. Permutations — order matters\n🔹  Formula\nExample 1: Arrange 4 books from 10 →  10P4 = 5040.\n🔹  All n distinct →  n!\nExample 2: Arrange A, B, C →  3! = 6 sequences.\n🔹  Repetition allowed\nIf each position can be ﬁlled by k choices: \nExample 3: 5-letter password (A–Z): 26⁵.\n🔹  Identical objects\nIf items repeat, divide by factorials of repeats.\nExample 4: “BALLOON” →  7 letters (L×2, O×2)\n= 7! / (2!·2!) = 1260\nP =n r\n \n(n−r)!\nn!\nkr\nArrangements=  \nn  !n"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\1) Counting (Basics → Advanced).pdf",
    "page": 9,
    "text": "!n  !...1 2 3\nn!\nPrinted using ChatGPT to PDF, powered by PDFCrowd HTML to PDF API. 9/14"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\1) Counting (Basics → Advanced).pdf",
    "page": 10,
    "text": "🔹  Circular permutations\nRotations considered same →  (n–1)!\nReﬂections same too →  (n–1)! / 2\nExample 5: 5 people around table →  4! = 24.\n🔹  Restrictions — “Together / Not together”\nExample 6: 6 people, A & B together.\nTreat AB as block →  5 units →  5! = 120 × 2 = 240\nIf NOT together →  6! −  240 = 480.\n🔹  Word example\nExample 7: “MISSISSIPPI”\nLetters: 11; I×4, S×4, P×2\n= 11! / (4!·4!·2!) = 34650\n🔹  Derangements (no one in own seat)\nExample 8: 3 letters A,B,C wrong envelopes →  !3 = 2.\n🌟  3. Combinations — order doesn’t matter\n🔹  Formula\nExample 1: Choose 3 from 5 →  5C3 = 10.\n🔹  Relation with permutation\n🔹  Repetition allowed (multicombination)\nWhen you can choose same element multiple times:\nExample 2: Choose 3 fruits from {apple, mango, banana} (can repeat):\n= 3+3 − 1 C 3 = 5C3 = 10.\n!n=n! 1−  +  −  +⋯( 1!\n1\n2!\n1\n3!\n1 )\nC =n r\n \nr!(n−r)!\nn!\nP =n r C ×n r r!\nC \nn+r−1 r\nPrinted using"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\1) Counting (Basics → Advanced).pdf",
    "page": 10,
    "text": "ChatGPT to PDF, powered by PDFCrowd HTML to PDF API. 10/14"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\1) Counting (Basics → Advanced).pdf",
    "page": 11,
    "text": "🔹  Stars and Bars (distribution)\nSolutions of , :\nExample 3: 5 identical balls into 3 boxes →  5+3 − 1 C 3 − 1 = 7C2 = 21\n🔹  If each box ≥ 1\nLet , total = n − k\nExample 4: 5 balls, 3 boxes, each ≥ 1 →  5 − 1 C 3 − 1 = 4C2 = 6.\n🔹  “At most / At least” constraints\nUse complement or shift.\nExample 5: How many ways to distribute 8 chocolates to 3 kids, each ≤ 5.\nWithout restriction: 8+3 − 1 C 3 − 1 = 10C2 = 45\nSubtract cases where someone gets >5 →  treat separately.\n🔹  “No two adjacent”\nExample 6: Place 3 stars among 7 boxes with gaps between →  use “gaps method.”\nPut 4 bars to separate →  count via transformed stars & bars.\n🔹  Combination identities\n1. nCr = nC(n − r)\n2. nCr + nC(r − 1) = (n+1)Cr\n3. Σr nCr = 2ⁿ\n→  GATE often tests identity simpliﬁcation.\nExample 7: 6C0 + 6C1 + … + 6C6 = 2⁶ = 64.\n🌟  4. Binomial Probability\n🔹  Model\nn independent Bernoulli trials (success prob p, fail q=1 −"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\1) Counting (Basics → Advanced).pdf",
    "page": 11,
    "text": "p).\nX = number of successes.\nx  +1 x  +2 ⋯+x  =k n x ≥i 0\nC  \nn+k−1 k−1\ny =i x −i 1\nC  \nn−1 k−1\nP(X=k)= C p qn k k n−k\nPrinted using ChatGPT to PDF, powered by PDFCrowd HTML to PDF API. 11/14"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\1) Counting (Basics → Advanced).pdf",
    "page": 12,
    "text": "Example 1: 5 coin tosses →  exactly 2 heads\n= 5C2 (½)²(½)³ = 10/32 = 0.3125\n🔹  Properties\nE[X] = np\nVar[X] = npq\nσ = √ (npq)\nExample 2: n=10, p=0.3 →  E[X]=3, Var=2.1.\n🔹  Cumulative (at most / at least)\nExample 3: P(X ≥ 1) = 1 −  P(X=0) = 1 −  qⁿ.\nFor fair coin, 3 tosses: 1 −  (½)³ = 0.875\n🔹  “At most r”\nSum from 0 to r.\nExample 4: n=4, p=0.5, P(X ≤ 2) = 4C0(0.5)⁴ + 4C1(0.5)⁴ + 4C2(0.5)⁴\n= (1 + 4 + 6)/16 = 11/16\n🔹  Mean veriﬁcation via symmetry\nBinomial is symmetric if p=q=0.5.\nExample 5: For 5 tosses, P(0)=P(5), P(1)=P(4), etc.\n🔹  Approximation (edge)\nLarge n, small p ⇒  Poisson(λ=np)\nLarge n, moderate p ⇒  Normal(np, npq)\nExample 6: If n=100, p=0.02 →  λ=2\nP(X=0) ≈ e⁻²=0.135.\n🔹  Application example\nA bulb works with probability 0.9. In 5 bulbs, ﬁnd:\nAll work →  (0.9)⁵ = 0.59049\nExactly 4 work →  5C4(0.9)⁴(0.1)=0.32805\nAt least 4 work →  sum = 0.59049 + 0.32805 = 0.91854\nPrinted using C"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\1) Counting (Basics → Advanced).pdf",
    "page": 12,
    "text": "hatGPT to PDF, powered by PDFCrowd HTML to PDF API. 12/14"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\1) Counting (Basics → Advanced).pdf",
    "page": 13,
    "text": "🧠  GATE-Level Practice Examples\n1. (Counting) 6-digit numbers from 1–9 that are divisible by 5 and have no repeated digits.\n→  must end with 0 or 5, so handle both cases separately.\n2. (Permutation) Arrange 8 people where 3 speciﬁc people never sit together.\n→  Total −  cases where they do sit together.\n3. (Combination) Choose committee of 5 from 8 men and 6 women with ≥ 3 women.\n= 3W+2M + 4W+1M + 5W = 6C3·8C2 + 6C4·8C1 + 6C5.\n4. (Binomial) A biased coin (p=0.6) tossed 10 times.\nFind P(at least 8 heads). Sum 10C8(0.6)⁸(0.4)² + 10C9(0.6)⁹(0.4) + (0.6)¹⁰.\n✅  Quick Summary Sheet\nConcept Key Formula Example Result\nRule of Sum m+n car/bus route\nRule of Product m×n crust×topping\nPermutation nPr = n!/(n − r)! 10P4=5040\nRepetition n^r 26⁵\nCombination nCr = n!/[r!(n − r)!] 10C3=120\nWith repetition n+r − 1 C r 3 fruits repeat →  10\nCircular (n − 1)! 5 → 24\nBinomial nCk p^k(1 − p)^{n − k} coin toss"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\1) Counting (Basics → Advanced).pdf",
    "page": 13,
    "text": "Expectation np 10,0.3 →  3\nVariance npq 2.1\nWould you like me to continue this series with Part 2: Advanced GATE Examples + Problem-Solving\nTechniques (covering tricky restrictions, inclusion–exclusion proofs, and PYQs from GATE 2022–2024)?\nI can explain every question step-by-step until mastery.\nPrinted using ChatGPT to PDF, powered by PDFCrowd HTML to PDF API. 13/14"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\1) Counting (Basics → Advanced).pdf",
    "page": 14,
    "text": "Printed using ChatGPT to PDF, powered by PDFCrowd HTML to PDF API. 14/14"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 3,
    "text": "Acknowledgements  \n \nPatrons:  \n• Mr. Rahul Singh, IAS, Chairperson, Central Board of Secondary Education  \n \nGuidance and Support:  \n• Dr. Biswajit Saha, Director (Skill Education & Training), Central Board of Secondary Education \n• Ms. Shweta Khurana, Senior Director APJ, Government Partnerships and Initiatives, International \nGovernment Affairs Group, Intel \n \nEducation Value adder, Curator and Coordinator:  \n• Sh. Ravinder Pal Singh, Joint Secretary, Department of Skill Education, Central Board of Secondary Education \n• Ms. Saloni Singhal, Program Manager APJ, Intel Digital Readiness Programs \n• Ms. Sarita Manuja, Educational Consultant & Program Director, NHES  \n• Ms. Shatarupa Dasgupta, National Program Manager, Intel Digital Readiness Program \n \nContent Curation Team:  \n• Ms. Ambika Saxena, Intel AI for Youth Coach \n• Ms. Prachi Chandra, Intel AI for Youth Coach \n• Ms. Yukti, Army"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 3,
    "text": "Public School, Meerut \n• Ms. Namita Mohanty, Delhi Public School, Rourkela \n• Ms. A. Sayeesubbulakshmi, Delhi Public School, Bangalore (South) \n• Ms. Vineeta Garg, Shaheed Rajpal DAV Public School, Delhi \n• Ms. Shilpa Sethi, D.A.V. Public School, Sector-14, Gurugram \n• Ms. Shipra Panigrahi, Indirapuram Public School, Ghaziabad"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 4,
    "text": "About the Book \nIn the rapidly evolving landscape of the global digital economy, Artificial Intelligence (AI) stands as the \ncornerstone of future innovation and growth. Recognizing this, nations worldwide are strategically positioning \nthemselves to harness the transformative potential of AI. India, in particular, views AI not just as a technological \nadvancement but as an opportunity to foster inclusive economic growth and social development. \n \nAt the forefront of this vision is the Central Board of Secondary Education (CBSE), which is on a mission to equip \nthe next generation with the skills and mindset necessary to thrive in an AI-driven world. As part of this initiative, \nCBSE has collaborated with Intel India since 2019, to curate a comprehensive Facilitator Handbook and \naccompanying AI training resources. The resources aim to empower educators and students alike, fostering a \nd"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 4,
    "text": "eeper understanding of AI concepts and their practical applications. \n \nThis edition of the ‘AI Facilitator Handbook’ is more than just a curriculum; it's a roadmap for students to \nnavigate the complexities of AI with confidence and creativity. Enriched with updated AI tech and social \nconcepts, real-life examples, and AI proje ct development guides using no -code tools, this book is designed to \ninspire students to not only understand AI but also to leverage it to drive positive social change. \n \n \nKey features include: \n \n• Enhanced Content: Concepts are presented with further elaboration and fresh examples to facilitate \ndeeper engagement and comprehension. \n• Real-Life Examples: Additional real-world scenarios are integrated to offer clearer explanations, making \ncomplex AI concepts accessible to students. \n• AI enabled social impact solutions: Students are encouraged to develop AI"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 4,
    "text": "solutions for social impact in \na straightforward manner, fostering understanding and empowerment. \n• Use Case Walkthroughs: Practical implementation of AI concepts is demonstrated across various \ndomains, enabling students to grasp their real-world applications."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 5,
    "text": "Grade X Artificial Intelligence \n \n \nUnits \n \nSessions \n \nTopics Hours \n \n \n \n \n \nUnit -1-Revisiting AI Project \nCycle & Ethical Frameworks \nfor AI1 \n \n1.1 AI Project Cycle \n \nThe overview of the six stages of the AI Project Cycle \n \n \n \n \n \n \n15 \n \n1.2 Introduction to AI Domains \n \nThe three domains of AI and their applications \n \n1.3 Ethical Frameworks of AI \n \n• Frameworks \n• Ethical frameworks \n• Need of Ethical Frameworks for AI \n• Factors that influence our decision- making \n• Types of Ethical Frameworks \n• Bioethics and its principles \n• A use case of Bioethics \n \n \n \n \n \n \nUnit 2. Advanced concepts of \nModeling in AI \n \n2.1 Revisiting AI, ML and DL \n• Differentiate between AI, ML and DL \n• Common terminologies used with data \n \n \n \n \n \n \n \n \n \n \n \n \n25 \n \n \n2.2 Modelling \n \n• Types of AI models –Rule based, Learning \nbased \n• Categories of Machine learning based models \n– \n• Supe"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 5,
    "text": "rvised, Unsupervised and Reinforcement \nlearning models \n• Sub-categories of \n• Supervised Learning Model – Classification, \nRegression \n• Sub-categories of Unsupervised Learning \nModel – Clustering, Association \n \n2.3 Neural Networks \n• What is neural network? \n• How does AI make a decision? \n  \n3.1 Importance of Model Evaluation \n• What is evaluation? \n• Why do we need a model evaluation? \n \n \n \n \n \nUnit 3: Evaluating Models \n3.2 Splitting the training set data for \nEvaluation \n• What is Train-test split? \n• Why do we need to do Train- test split? \n \n \n \n \n \n \n \n \n \n \n25 \n3.3 What is Accuracy and Error? \n• Accuracy \n• Error \n \n \n \n3.4 Evaluation metrics for \nclassification \n• What is Classification? \n• Classification metrics \n• Confusion matrix \n• Accuracy from Confusion matrix \n• Precision from Confusion matrix \n• Recall from Confusion matrix \n• F1 Score \n3.5 Ethical concerns around m"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 5,
    "text": "odel \nevaluation \n• Bias \n• Transparency \n• Accountability \n \n \nUnit 4: Statistical Data \n4.1 No code AI for Statistical  Data • Meaning of No-Code AI \n• No-Code and Low-Code. \n• Some no-code tools \n \n28 \n4.2 Statistical Data: Use Case Walk \nthrough \n• Important concepts in Statistics. \n• Orange data mining \n• AI project cycle in Orange data mining (Palmer \npenguins case study) \n \n \n \n \n \n \n \n5.1 Introduction to Computer Vision \n \n• CV open-source tool \n• A Quick overview of computer vision \n• Computer Vision and Artificial Intelligence \n• Computer Vision v/s Image \nProcessing"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 6,
    "text": "Unit 5: Computer Vision \n \n \n \n \n \n \n \n \n \n5.2 Applications of CV \n• Facial Recognition \n• Face Filters \n• Google Search by Image \n• Computer Vision in retail \n• Self-Driving cars \n• Medical Imaging \n• Google Translate App \n \n30 \n \n \n5.3 Computer Vision Tasks \n• Classification \n• Classification + Localisation \n• Object Detection \n• Image Segmentation \n• Basics of Images and Pixels \n• Resolution & Pixel Value \n• Grayscale & RGB Images \n \n \n5.4 No-Code AI tools \n• Introduction to Lobe \n• Teachable Machine \n• Smart Sorter Activity \n• Orange Data Mining Tool \n• Use Case Walkthrough \n• Steps to project development \n \n \n5.5 Image Features \n• Introduction to image features \n• Examples \n• Conclusion \n \n5.6 Convolution • Convolution \n• What is Kernel? \n \n5.7 Convolution Neural Network \n• Introduction \n• Convolution Layer \n• Rectified Linear Unit \n• Pooling Layer \n• Fully Connected Layer \n \n \n \n5."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 6,
    "text": "8 Python libraries in  Computer \nVision \n \n \n• TensorFlow \n• Keras \n• OpenCV \n• Applications of OpenCV \n \n \n \n \n \n \n \n \n \nUnit-6 Natural \nLanguage Processing \n \n6.1 Introduction to NLP \n• Features of natural language \n• Computer language \n• Importance of NLP \n \n27 \n \n6.2 Applications of Natural Language \nProcessing \n• Voice Assistants \n• Autogenerated captions \n• Language translation \n• Sentiment analysis \n• Text classification \n• Keyword extraction \n \n \n6.3 Stages of Natural Language \nProcessing (NLP) \n• Lexical Analysis \n• Syntactic Analysis \n• Semantic Analysis \n• Discourse Integration \n• Pragmatic Analysis \n \n6.4 Chatbots Differences between a Script bot and a Smart bot \n \n6.5 Text Processing • Text Normalisation \n• Bag of words \n• TFIDF \n• Applications of TFIDF \n6.6 Natural Language  \nProcessing: Use Case  \nWalkthrough \n• Examples of code and no-code tools \n• Applications of Sentime"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 6,
    "text": "nt Analysis \n• Sentiment Analysis using the Orange Data Mining \ntool."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 7,
    "text": "Unit–1: Revisiting AI Project Cycle & Ethical \nFrameworks for AI \n \nLesson Title: Ethical Frameworks for AI Approach: Session + Activity \nSummary: There is a recapitulation of the AI Project Cycle and various domains of AI.  \nStudents will be introduced to ethics in AI and they will explore ethical frameworks for \nAI. They understand the need for such frameworks and the various factors that \ncontribute to  coming up with a framework of their own. They will also learn about \ndifferent types of  ethical frameworks and explore one of these frameworks in detail. \nThe module concludes   with a case study on how to apply ethical frameworks to AI \nsolutions to avoid their unintended consequences. \nLearning Objectives: \n \nStudents are: \n \n1. Briefed on the various stages of the AI Project Cycle. \n2. Briefed on the different domains of AI and their applications. \n3. Introduced to the ethical fram"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 7,
    "text": "eworks for AI. \n4. Introduced to types of ethical frameworks. \n5. Introduced to the principles of bioethics. \nLearning Outcomes: \n \nStudents will be able to: \n \n1. Outline the six stages of the AI Project Cycle. \n2. Elucidate the AI domains and their applications. \n3. Describe what are frameworks and ethical frameworks. \n4. Classify ethical frameworks based on sectors and value addition. \n5. Explore the bioethical framework and its principles in detail. \n6. Practice the application of an ethical framework for AI. \nPre-requisites: \n1. Basic knowledge of AI. \n2. Basic understanding of ethics and ethics in AI. \nKey-concepts: \n1. Introduction to ethical frameworks for AI \n2. Types of ethical frameworks \n3. Application of ethical frameworks for AI \n4. Principles of bioethics"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 8,
    "text": "1.1: AI Project Cycle \nLet’s revisit the concept of the AI Project Cycle. \n \nIntroduction \n \nLet us assume that you have to make a greeting card for your mother as it is her birthday. You \nare very excited about it and have thought of many ideas to execute the same. Let us look at  \nsome of the steps which you might take to accomplish this task: \n \n1. Look for some cool greeting card ideas from different sources. You might go online and \ncheck out some videos or you may ask someone who knows about it. \n2. After finalising the design, you would make a list of things that are required to make this \ncard. \n3. You will check if you have the material with you or not. If not, you could go and get all the \nitems required, ready for use. \n4. Once you have everything with you, you will start making the card. \n5. If you make a mistake in the card somewhere which cannot be rectified, you will disca"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 8,
    "text": "rd it \nand start remaking it. \n6. Once the greeting card is made, you will gift it to your mother. \n \nThese steps show how we plan to execute the tasks around us. Consciously or subconsciously  \nour mind makes up plans for every task which we have to accomplish which is why things  \nbecome clearer in our mind. Similarly, if we have to develop an AI project, the AI Project Cycle  \nprovides us with an appropriate framework which can lead us towards the goal. The AI project  \ncycle is the cyclical process followed to complete an AI project. The AI Project Cycle mainly has \n6 stages:"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 9,
    "text": "Starting with Problem Scoping, you set the goal for your AI project by stating the problem  \nwhich you wish to solve with it. Under problem scoping, we look at various parameters which \naffect the problem we wish to solve so that the picture becomes clearer. \nTo proceed, \n \n● You need to acquire data which will become the base of your project as it will help you \nunderstand what the parameters that are related to problem scoping are. \n \n● You go for data acquisition by collecting data from various reliable and authentic sources.  \nSince the data you collect would be in large quantities, you can try to give it a visual image of  \ndifferent types of representations like graphs, databases, flow charts, maps, etc. This makes it \neasier for you to interpret the patterns which your acquired data follows. \n \n● After exploring the patterns, you can decide upon the type of model you would build t"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 9,
    "text": "o \nachieve the goal. For this, you can research online and select various models which give a  \nsuitable output. \n \n● You can test the selected models and figure out which is the most efficient one. \n \n● The most efficient model is now the base of your AI project and you can develop your \nalgorithm around it. \n \n● Once the modelling is complete, you now need to test your model on some newly fetched \ndata. The results will help you in evaluating your model and improving it. \n \n● Finally, after evaluation, the deployment stage is crucial for ensuring the successful  \nintegration and operation of AI solutions in real-world environments, enabling them to deliver \nvalue and impact to users and stakeholders. \n \n \n       1.2: Introduction to AI Domains \n \nArtificial Intelligence becomes intelligent according to the training it gets. For training, the  \nmachine is fed with datasets. According to"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 9,
    "text": "the applications for which the AI algorithm is being  \ndeveloped, the data fed into it changes. With respect to the type of data fed in the AI model, AI \nmodels can be broadly categorized into three domains:"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 10,
    "text": "Statistical Data \n \nStatistical Data is a domain of AI related to data systems and processes, in which the system \ncollects numerous data, maintains data sets and derives meaning/sense out of them. \nThe information extracted through statistical data can be used to make a decision about it. \n \nExample of Statistical Data \n \nPrice Comparison Websites \nThese websites are being driven by lots and lots of data.  \nIf you have ever used these websites, you would know,  \nthe convenience of comparing the price of a product  \nfrom multiple vendors in one place. PriceGrabber,  \nPriceRunner, Junglee, Shopzilla, DealTime are some  \nexamples of price comparison websites. Nowadays, price \ncomparison websites can be found in almost every  \ndomain such as technology, hospitality, automobiles,  \ndurables, apparel, etc. \n \n \nComputer Vision \nComputer Vision, abbreviated as CV, is a domain of AI that depict"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 10,
    "text": "s the capability of a machine \nto get and analyse visual information and afterwards predict some decisions about it. The  \nentire process involves image acquiring, screening, analysing, identifying and extracting  \ninformation. This extensive processing helps computers to understand any visual content and  \nact on it accordingly. In computer vision, Input to machines can be photographs, videos and  \npictures from thermal or infrared sensors, indicators and different sources. \n \nComputer vision-related projects translate digital visual data into descriptions. This data is then \nturned into computer-readable language to aid the decision-making process. The main objective \nof this domain of AI is to teach machines to collect information from pixels. \n \nExamples of Computer Vision \n \nAgricultural Monitoring \n \nComputer vision is employed in agriculture for crop  \nmonitoring, pest detection,"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 10,
    "text": "and yield estimation. Drones  \nwith cameras capture aerial images of farmland, which are \nthen analysed to assess crop health and optimize farming  \npractices."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 11,
    "text": "Surveillance Systems \n \nComputer vision is used in surveillance systems to monitor  \npublic spaces, buildings, and borders. It can detect suspicious \nactivities, track individuals or vehicles, and provide real -time \nalerts to security personnel. \n \n \nNatural Language Processing \n \nNatural Language Processing, abbreviated as NLP, is a branch of artificial intelligence that deals \nwith the interaction between computers and humans using the natural language. Natural  \nlanguage refers to language that is spoken and written by people, and natural language  \nprocessing (NLP) attempts to extract information from the spoken and written word using  \nalgorithms. \nThe ultimate objective of NLP is to read, decipher, understand, and make sense of human \nlanguages in a valuable manner. \n \n \n   Examples of Natural Language Processing \n \n \nEmail filters \n \nEmail filters are one of the most basic and"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 11,
    "text": "initial applications of NLP online. It started  \nwith spam filters, uncovering certain words or \nphrases that signal a spam message. \n \n \n \nMachine Translation \n \nNLP is used in machine translation systems like Google Translate \nand Microsoft Translator to automatically translate text from  \none language to another. These systems analyze the structure  \nand semantics of sentences in the source language and generate \nequivalent translations in the target language."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 12,
    "text": "1.3: Ethical Frameworks for AI \n \nFrameworks \n \nFrameworks are a set of steps that help us in solving problems. It provides a step-by-step guide \nfor solving problems in an organized manner. Moreover, frameworks offer a structured  \napproach to problem-solving, ensuring that all relevant factors and considerations are taken into \naccount. Additionally, they serve as a common language for communication and  collaboration, \nfacilitating the sharing of best practices and promoting consistency in problem - solving \nmethodologies. \nYou may have used frameworks without knowing it! Can you think of one framework you have \ncome across during your AI journey? \n \n \nEthical Frameworks \n \nWe know that ethics are a set of values or morals which help us  \nseparate right from wrong. Frameworks are step-by-step \nguidance on solving problems. \n \nHence, Ethical frameworks are frameworks which help us ensu"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 12,
    "text": "re  \nthat the choices we make do not cause unintended harm. \nFurthermore, ethical frameworks provide a systematic approach  \nto navigating complex moral dilemmas by considering various  \nethical principles and perspectives. By utilizing ethical \nframeworks, individuals and organizations can make well- \ninformed decisions that align with their values and promote \npositive outcomes for all stakeholders involved."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 13,
    "text": "Why do we need Ethical Frameworks for AI? \n \nAs we have seen how bias could result in unwanted outcomes in AI solutions. Think of the hiring \nalgorithm which was biased against women applicants! \nAI is essentially being used as a decision-making/ influencing tool. As such we need to ensure \nthat AI makes morally acceptable recommendations \nEthical frameworks ensure that AI makes morally acceptable choices. If we use ethical  \nframeworks while building our AI solutions, we can avoid unintended outcomes, even before \nthey take place! \n \n \nSo far, we have understood why ethical frameworks are needed. Let’s \ntry to guess what such a framework would be made of! \n \nActivity: 1 My Goodness \n \n \nVisit the website – https://www.my-goodness.net/ \nTake a quick look at the video to learn more about the game! \nPlayers must make 10 decisions on how they would like to make a charitable donation. In mos"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 13,
    "text": "t \ncases, players will receive details about the recipients. They will also be given information on  \nthe intended use of the money they are donating. In a few instances, this may be hidden from  \nthem, however they can choose to reveal it. \nThis activity aims to understand an individual’s judgment. We are looking to discover potential \nbiases within us! \nData is collected anonymously and with your consent. \nIf you wish to delve deeper and explore your own decision-making, click on “yes.” \nPurpose: To understand how our decisions get influenced by our personal morals, values \nand ethics! \n \nSay: “Carefully read the descriptions provided that help you decide on donating. Explore your \ndecision-making ability.”"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 14,
    "text": "After clicking on “yes” you will be taken to a short survey. \nAfter the survey has been filled, you will see interesting insights about your decisions \n \n \nDid you discover any internal biases in your \ndecisions? \nDo you agree with the results shared by the game? \nFactors which could influence your decisions \nwithout you realizing it include \n• Identity of the charity recipient. \n• Location of the recipient. \n• Bias towards relatives. \n• Uncovering information available. \n \n \nThis is just an exercise to uncover our biases and thought processes behind making certain  \ndecisions. This will help us in producing a framework which can aid in making decisions which \nare ethically sounder. \nLet’s list at least 3 factors which knowingly or unknowingly influence our decision-making. \n \n \n \nCulture \n \nValue of humans  \nValue of non-humans \n \n \n \nIs the decision I am \ntaking aligned with  \nmy relig"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 14,
    "text": "ious views? \n \nReligion \n \n \nIntuition \n& \nValues \nDoes what I am \nthinking sound  \ncorrect?"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 15,
    "text": "Types of Ethical Frameworks \nThe various types of ethical frameworks are classified as follows: \n \n \n \n \n \nLet's delve into the classifications of ethical frameworks. \nEthical frameworks for AI can be categorized into two main types: sector-based and value- \nbased frameworks. \n1. Sector-based Frameworks: \nThese are frameworks tailored to specific sectors or industries. In the context of AI, one  \ncommon sector-based framework is Bioethics, which focuses on ethical considerations in \nhealthcare. It addresses issues such as patient privacy, data security, and the ethical use of AI in \nmedical decision-making. Sector-based ethical frameworks may also apply to domains such as  \nfinance, education, transportation, agriculture, governance, and law enforcement. \n2. Value-based Frameworks: \nValue-based frameworks focus on fundamental ethical principles and values guiding decision- \nmaking. It re"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 15,
    "text": "flects the different moral philosophies that inform ethical reasoning. Value-based \nframeworks are concerned with assessing the moral worth of actions and guiding ethical \nbehaviour. They can be further classified into three categories: \ni. Rights-based: Prioritizes the protection of human rights and dignity, valuing human life over \nother considerations. It emphasizes the importance of respecting individual autonomy, dignity, \nand freedoms. In the context of AI, this could involve ensuring that AI systems do not violate  \nhuman rights or discriminate against certain groups. \nii. Utility-based: Evaluates actions based on the principle of maximizing utility or overall good, \naiming to achieve outcomes that offer the greatest benefit and minimize harm. It seeks to"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 16,
    "text": "maximize overall utility or benefit for the greatest number of people. In AI, this might involve  \nweighing the potential benefits of AI applications against the risks they pose to society, such as \njob displacement or privacy concerns. \niii. Virtue-based: This framework focuses on the character and intentions of the individuals  \ninvolved in decision-making. It asks whether the actions of individuals or organizations align \nwith virtuous principles such as honesty, compassion, and integrity. In the context of AI, virtue \nethics could involve considering whether developers, users, and regulators uphold ethical  \nvalues throughout the AI lifecycle. \nThese classifications provide a structured approach for addressing ethical concerns in AI  \ndevelopment and deployment, ensuring that considerations relevant to specific sectors and \nfundamental ethical values are adequately addressed. \nLet’s"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 16,
    "text": "explore a popular framework which is used in the healthcare industry. \nBioethics \nBioethics is an ethical framework used in healthcare and life sciences. It deals with ethical \nissues related to health, medicine, and biological sciences, ensuring that AI applications in \nhealthcare adhere to ethical standards and considerations. \n \n \nPrinciples of bioethics: \n• Respect for Autonomy. \n• Do not harm. \n• Ensure maximum benefit for all. \n• Give justice. \n \n \n \n \n \n \n• “Non-maleficence” refers to the ethical principle of avoiding causing harm or negative \nconsequences. It emphasizes the obligation to minimize harm as much as possible and prioritize \nactions that prevent harm to individuals, communities, or the environment. \n \n• “Maleficence” refers to the concept of intentionally causing harm or wrongdoing. \n \n• “Beneficence\" refers to the ethical principle of promoting and maximizing the wel"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 16,
    "text": "l-being and \nwelfare of individuals and society. It emphasizes taking actions that produce positive outcomes \nand contribute to the overall good, ensuring that the greatest benefit is achieved for all \nstakeholders involved."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 17,
    "text": "Let’s look at a case study and see the impact of the application of an AI ethical framework on \nthe end outcome. \n \nCase Study \nA company aimed to support hospitals in optimizing patient care by \ncreating an AI algorithm designed to identify individuals at high risk. \nThe objective was to provide healthcare providers with valuable \ninsights to allocate resources effectively and ensure those most in  \nneed receive appropriate attention. However, potential unintended \nconsequences lead to some problems in the model, such as the \nalgorithm inadvertently exacerbating existing biases or inaccuracies in  \nthe data, potentially leading to misclassification of patients or \noverlooking critical cases. Addressing concerns about the algorithm's  \naccuracy and reliability becomes paramount, as any flaws in its design or \ntraining data could compromise patient care and outcomes \nThe problem it caused"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 17,
    "text": ": \nPatients from the Western region of a particular area, who were categorized at the same risk \nlevel by the algorithm, generally exhibited more severe health conditions compared to patients \nfrom other regions. \nWhy the problem happened: \n• The algorithm utilized was trained on healthcare expense data as a measure for health \nmetrics rather than actual physical illness. \n• This algorithm was created in the United States where less money is spent on western \nregion patient healthcare than other ethnic patient healthcare. \nThis meant the algorithm   \nWe can use principles of the Bioethics framework to ensure an ethical AI solution. \nThe four principles of bioethics can be used to ensure an ethical AI solution for the healthcare \nproblem. \ni. Respect for autonomy: Enabling users to be fully aware of decision-making. E.g., users of an \nAI algorithm should know how it functions. \n• The data"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 17,
    "text": "that models were trained on, and used to make \ndecisions, should be reproducible and accessible to the  \npatients. \n• In the event of performance concerns, model predictions and \ndata labels should be released."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 18,
    "text": "ii. Do not harm: Harm to anyone (be it human or non–human) must be avoided at all costs. If \nno choice is available path of least harm must be always chosen. \n• Promote well -being, minimize harm, and ensure that  \nbenefits and harms are distributed among stakeholders \nin a just manner. \n• The AI algorithm must be trained on data sets that \nequitably reduce harm for all, not just harm for some \ngroups. \n• In this instance, patients from other regions excluding \nwestern part who were less ill would receive more \nintensive care from doctors than patients who  \nactually require help. \n• This algorithm, if implemented, would actively harm  \npatients belong to western region by inappropriately \nrecommending healthcare resource allocation. \n \n \n \niii. Maximum benefit: Not only should we avoid harm our actions must focus on providing the \nmaximum benefit possible. \n• The solution should be held"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 18,
    "text": "to clinical practice standards, \nnot merely technological ethics standards. \n• It should go beyond nonmaleficence and strive for \nbeneficence. \n• Considering the example, we discussed, the AI algorithm \nshould not only avoid causing harm to patients from the \nwestern region but also provide benefits to these \npatients, as well as patients from other regions and of all \nraces. \n• Is there a better data set for training that reflects the  \nhealthcare needs and outcomes of patients of all races? \n• The data we use for training must be unbiased."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 19,
    "text": "iv. Justice: All benefits and burdens of a particular choice must be distributed in a justified \nmanner across people irrespective of their background. \n• Solution development requires concerted and in -depth \nknowledge of social structures at play that result in issues \nlike racism and sexism (a few types of societal biases). \n• The solution needs to be aware of social determinants of \nhealthcare and actively work against those structures. \n \n \nWe saw that abiding by bioethical principles could have helped us to avoid the unintended \nconsequences of the AI solution. \n \n \nTest Yourself: \n \n1. What is the purpose of defining the problem statement during the Problem Scoping stage in \nan AI project cycle? \nA) To collect data \nB) To understand the aim and objective of the project \nC) To train the model \nD) To process data \n \n2. In what ways can AI models be categorized based on the type of d"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 19,
    "text": "ata fed into them? \nA) Two domains \nB) Four domains \nC) Three domains \nD) Five domains \n \n3. In Statistical Data, what is the primary function of the system in relation to data? \nA) Generating large datasets \nB) Analyzing data to extract insights \nC) Converting data into images \nD) Distributing data across networks \n \n4. What is the main goal of Computer Vision projects? \nA) Translating audio data into visual descriptions \nB) Converting digital data into analogue signals \nC) Teaching machines to understand textual information \nD) Converting digital visual data into computer-readable language \n \n5. What is the primary focus of NLP? \nA) Analyzing computer languages \nB) Interacting between computers and humans using artificial language \nC) Dealing with the interaction between computers and humans using natural language \nD) Enhancing human-to-human communication"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 20,
    "text": "6. What do frameworks provide in the context of problem-solving? \nA) Random solutions \nB) Step-by-step guidance \nC) Legal advice \nD) Ethical justifications \n \n7. How are Ethical Frameworks for AI categorized? \nA) Into legal and illegal frameworks \nB) Into sector-based and value-based frameworks \nC) Into historical and contemporary frameworks \nD) Into theoretical and practical frameworks \n \n8. What is the central focus of virtue-based value-based frameworks? \nA) Maximizing utility \nB) Protecting human rights \nC) Aligning actions with ethical principles and beliefs \nD) Ensuring compliance with legal regulations \n \n9. Which of the following best describes rights-based value-based frameworks? \nA) Prioritizing human rights and dignity, valuing human life over other considerations \nB) Evaluating actions based on maximizing overall good and minimizing harm \nC) Centering on the character of the"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 20,
    "text": "decision-maker and the alignment of actions with personal \nor societal virtues \nD) Focusing on achieving outcomes that offer the greatest benefit \n \n10. What is the primary domain of application for Bioethics? \nA) Agriculture \nB) Healthcare and life sciences \nC) Information technology \nD) Environmental conservation \n \n11. Assertion: Ethics provide guidance in distinguishing right from wrong. \nReasoning: Ethics consist of a set of values and morals that  aid individuals in making moral \njudgments and decisions. \nA) Both Assertion and Reasoning are true, and Reasoning is the correct explanation of the \nAssertion. \nB) Assertion is true, but Reasoning is false. \nC) Both Assertion and Reasoning are true, but Reasoning is not the correct explanation of the \nAssertion. \nD) Assertion is false, but Reasoning is true. \n12. Assertion: Value-based frameworks in ethics provide guidance by focusing on"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 20,
    "text": "fundamental \nethical principles and values."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 21,
    "text": "Reasoning: These frameworks reflect different moral philosophies guiding ethical reasoning and \nare concerned with assessing the moral worth of actions. \nA) Both Assertion and Reasoning are true, and Reasoning is the correct explanation of the \nAssertion. \nB) Assertion is true, but Reasoning is false. \nC) Both Assertion and Reasoning are true, but Reasoning is not the correct explanation of the \nAssertion. \nD) Assertion is false, but Reasoning is true. \nReflection Time: \n1. Outline the main steps in the AI Project Cycle briefly. \n2. What roles does computer vision play in agricultural monitoring systems? \n3. Mention the factors which knowingly or unknowingly influence our decision-making. \n4. What is the necessity for Ethical Frameworks in AI development? \n5. Mention the key characteristics of sector-based frameworks. \n6. What do you mean by Bioethics? \n7. What is Natural Language Proces"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 21,
    "text": "sing? Explain any two real-life applications of NLP. \n8. How do value-based frameworks contribute to ethical decision-making by emphasizing \nfundamental principles and values? \nCase-Based Questions \n1. Case Scenario: \n \nIn a corporate setting, a multinational company is facing scrutiny over its environmental  \npractices, particularly regarding the disposal of industrial waste. The company has historically \nprioritized profit maximization and cost -cutting measures, leading to practices that result in  \nenvironmental harm and negative impacts on local communities. As public awareness and  \nconcern about environmental sustainability grow, stakeholders, including investors, customers, \nand advocacy groups, are calling for the company to adopt more responsible and sustainable  \nbusiness practices. \n \nQuestion: \n \nDrawing from the case presented, analyze the ethical considerations surrounding"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 21,
    "text": "the  \ncompany's environmental practices through the lens of value-based frameworks in ethics. \n \n2. Case Scenario: \nIn a rural farming community, a group of small-scale farmers is faced with a dilemma regarding \nthe use of pesticides on their crops. The farmers have traditionally relied on chemical"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 22,
    "text": "pesticides to control pests and maximize crop yields. However, concerns have been raised  \nabout the potential environmental and health impacts of pesticide use, including soil  \ncontamination, water pollution, and adverse effects on human health. Additionally,  \nneighboring communities and environmental advocacy groups have expressed opposition to  \nthe widespread use of pesticides, citing ecological damage and risks to biodiversity. \n \nQuestion: \nUsing the case provided, examine the ethical considerations surrounding pesticide use in the  \nagricultural sector, applying ethical frameworks to analyze the competing interests and values \nat stake."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 23,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only.  \n   Unit-2:  Advanced Concepts of Modeling in AI \n \n \n \nLesson Title: Advanced concepts of Modeling in AI Approach: Session + Activity \nSummary: There are two main categories of AI models:  Rule based and Learning based.  \nLearning based models can be further classified as: Supervised Learning, where machines are \ntaught using labeled data; Unsupervised Learning, where machines independently uncover  \npatterns from unlabeled data; and Reinforcement Learning, enabling computers to optimize  \ndecisions for rewards without direct programming. Neural networks, mimicking the brain's  \nneurons, automatically extract data features through interconnected nodes, making them \nefficient for processing large datasets like images. \nLearning Objectives: \n \n1. To familiarize students with sup"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 23,
    "text": "ervised, unsupervised and reinforcement learning \nbased approach. \n2. To Introduce students to the neural network. \nLearning Outcomes: \n \n1. Understand supervised, unsupervised and reinforcement learning based \napproach. \n2. Understand Neural Networks. \nPre-requisites: Essential understanding of Artificial Intelligence \nKey-concepts: \n \n1. Supervised, unsupervised and reinforcement learning based approach \n2. Neural Networks"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 24,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only.  \n2.1 Revisiting AI, ML, DL \n \nTo build  an AI based project, we need to work around Artificially  Intelligent models or  \nalgorithms. This could be done either by designing your own model or by using the pre-existing \nAI models. Before jumping into modelling let us clarify the definitions of Artificial Intelligence \n(AI), Machine Learning (ML) and Deep Learning (DL). \n \n \nDifferentiate between AI, ML, and DL \n \n \nAs you can see in the Venn Diagram given below, Artificial Intelligence is  the umbrella  \nterminology which covers machine and deep learning under it and Deep Learning comes  \nunder Machine Learning. It is a funnel type approach where there are a lot of applications of \nAI out of which few are those which come under ML out of which very few go into DL. \nPurpose: To di"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 24,
    "text": "fferentiate between Artificial Intelligence (AI), Machine Learning (ML) and \nDeep Learning (DL). \nSay: “As we enter the world of modelling, it is a good time to clarify something many of you may be  \nhaving doubts about. You may have heard the terms AI, ML and DL when research content online and  \nduring this course. They are of course related, but how? \nArtificial Intelligence, or AI for short, refers to any technique that enables computers to mimic  \nhuman intelligence. An artificially intelligent machine works on algorithms and data fed to it and gives the \ndesired output. \nMachine Learning, or ML for short, enables machines to improve at tasks with experience. The machine here \nlearns from the new data fed to it while testing and uses it for the next iteration. It also takes into  account \nthe times when it went wrong and considers the exceptions too. \nDeep Learning, or DL for short,"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 24,
    "text": "enables software to train itself to perform tasks with vast amounts of data. \nSince the system has got huge set of data, it is able to train itself with the help of multiple machine \nlearning algorithms working altogether to perform a specific task. \nArtificial Intelligence is the umbrella term which holds both Deep Learning as well as Machine Learning. \nDeep Learning, on the other hand, is the very specific learning approach which is a subset of  \nMachine Learning as it comprises of multiple Machine Learning algorithms.”"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 25,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only.  \n \n \n \n \nMachine Learning (ML) \nMachine Learning , or ML, enables machines to improve at tasks  with experience. The  \nmachine learns from its mistakes and takes them into consideration in the next execution. It \nimprovises itself using its own experiences. \n \n \n \n \nBlock Representation – Machine Learning (ML) \n \nThis is just a broad representation of how a machine learning model works. Input (past or  \nhistorical data) is given to the ML model and the model generates output by learning from the \ninput data."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 26,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only.  \nHere is an example which shows labelled images (every image is tagged either as apple or  \nstrawberry) are given as input to the ML model. ML model learns from the input data to  \nclassify between apples and strawberries and predicts the correct output as shown. \n \n \nExamples of Machine Learning (ML)  \n \nObject Classification \nIdentifies and labels objects present within an \nimage or data point. It determines the  \ncategory an object belongs to. \n \n \n \n \nAnomaly Detection \nAnomaly detection helps us find the \nunexpected things hiding in our data . For \nexample, tracking your heart rate, and finding \na sudden spike could be an anomaly, flagging \na potential issue. \n \n \n \n \n \nDeep Learning (DL) \nDeep Learning, or DL, enables software to train itself to perform tasks with vast am"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 26,
    "text": "ounts of  \ndata. In deep learning, the machine is trained with huge amounts of data which helps it into  \ntraining itself around the data. Such machines are intelligent enough to develop algorithms for \nthemselves. Deep Learning is the most advanced form of Artificial Intelligence out of these  \nthree. Following is the block diagram of deep learning:"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 27,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only.  \n \n \nBlock Representation- Deep Learning (DL) \n \n \n \nInput is given to an ANN, and after processing, the output is generated by the DL block. Here  \nis an example which shows pixels of a bird image given as input to the DL Model and the model \nis able to analyze and correctly predict that it is a bird using a deep learning algorithm (ANN). \n \nExamples of Deep Learning (DL) \nObject Identification \nObject classification in deep learning \ntackles the task of identifying and labeling \nobjects within an image. It essentially uses \npowerful algorithms to figure out what's \nin a picture and categorize those things. \n \n \n \nDigit Recognition \nDigit recognition in deep learning tackles  \nthe challenge of training computers to \nidentify handwritten digits (0-9) within \nimages."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 28,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only.  \nCommon terminologies used with data \n \n \nWhat is Data? \n▪ Data is information in any form \n▪ For e.g. A table with information about \nfruits is data \n▪ Each row will contain information about \ndifferent fruits \n▪ Each fruit is described by certain features \n \nWhat do you mean by Features? \n• Columns of the tables are called features \n• In the fruit dataset example, features may be \nname, color, size, etc. \n• Some features are special, they are called \nlabels \n \nWhat are Labels? \nData Labeling is the process of attaching \nmeaning to data \n• It depends on the context of the problem we are \ntrying to solve \n• For e.g. if we are trying to predict what fruit it is \nbased on the color of the fruit, then color is the  \nfeature, and fruit name is the label. \n• Data can be of two types"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 28,
    "text": "– Labeled and \nUnlabeled \n \n \nLabeled Data \n▪ Data to which some tag/label is attached. \n▪ For e.g. Name, type, number, etc. \nUnlabeled Data \n▪ The raw form of data \n▪ Data to which no tag is attached. \n \nWhat do you mean by a training data set? \n▪ The training data set is a collection of examples given to the model to analyze and \nlearn. \n▪ Just like how a teacher teaches a topic to the class through a lot of examples \nand illustrations. \n▪ Similarly, a set of labeled data is used to train the AI model."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 29,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only.  \n \n \nWhat do you mean by a testing data set? \n▪ The testing data set is used to test the accuracy of the model. \n▪ Just like how a teacher takes a class test related to a topic to evaluate the \nunderstanding level of students. \n▪ Test is performed without labeled data and then verify results with labels. \n2.2 Modelling \n \n \nAI Modelling refers to developing algorithms, also called models which can be trained to get \nintelligent outputs. That is, writing codes to make a machine artificially intelligent. \n \nTypes of AI Models \nGenerally, AI models can be classified as follows: \n \nRule Based Approach \nRule Based Approach refers to the AI modelling where the relationship or patterns in data are \n \nPurpose: Classification of Models into Rule-based approach and Learning approach. \nSa"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 29,
    "text": "y: “In general, there are two approaches taken by researchers when building AI models. They either  \ntake a rule-based approach or learning approach. A Rule based approach is generally based on the data \nand rules fed to the machine, where the machine reacts accordingly to deliver the desired  output. \nUnder learning approach, the machine is fed with data and the desired output to which the  machine \ndesigns its own algorithm (or set of rules) to match the data to the desired output fed into the  machine” \nSupervised Learning \nMachine Learning \n Unsupervised \nLearning \nLearning Based \nReinforcement \nLearning \nAI Models \n Artificial Neural \nNetworks \nRule Based \nDeep Learning \nConvolution Neural \nNetworks"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 30,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only.  \ndefined by the developer. The machine follows the rules or instructions mentioned by the  \ndeveloper, and performs its task accordingly. \nRule-based Chatbots are commonly used on websites to answer frequently asked questions  \n(FAQs) or provide basic customer support. Here's an example: \n \nScenario: A clothing website has a Chabot to answer questions about order tracking. \n1. Data: The Chabot doesn't require a massive dataset for training. It relies on a \npredefined set of questions and corresponding answers. \n2. Rules: The Chabot uses a decision tree approach with clearly defined rules to \nunderstand user queries and provide responses. Here's a simplified example: \no Rule 1: If the user's message contains keywords like \"track order,\" \"shipment  \nstatus,\" or \"delivery,\" procee"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 30,
    "text": "d to order tracking options. \no Rule 2: Under order tracking options: \n▪ If the user asks for their order number, prompt them to enter it. \n▪ If the user enters a valid order number, retrieve the tracking \ninformation from the database and display it. \n▪ If the user enters an invalid order number, provide an error message  \nand ask them to re-enter it. \no Rule 3: If the user's message doesn't match any defined rules, offer a message \nlike \"Sorry, I can't help you with that. Perhaps you can try searching  our FAQs \nor contact customer support.\" \n3. Interaction: When a user chats with the bot, their message is analyzed based on the  \ndefined rules. The Chabot responds with a pre-written answer or prompts the user for \nadditional information depending on the scenario. \n \nA drawback/feature for this approach is that the learning is static. The machine once trained, \ndoes not take into consid"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 30,
    "text": "eration any changes made in the original training dataset. That is, if  \nyou try testing the machine on a dataset which is different from the rules and data you fed it  \nat the training stage, the machine will fail and will not learn from its mistake. Once trained,  \nthe model cannot improvise itself on the basis of feedbacks. Thus, machine learning gets  \nintroduced as an extension to this as in th at case, the machine adapts to change in data and  \nrules and follows the updated path only, while a rule -based model does what it has been  \ntaught once."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 31,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only.  \nLearning Based Approach \nA learning -based approach is a method where a computer learns how to do something by  looking at \nexamples or getting feedback, similar to how we learn from experience. Instead of  being explicitly \nprogrammed for a task, the computer learns to perform it by analyzing data and finding patterns or rules \non its own. \n \n \n \nFor example, suppose you have a dataset of  \n1000 images of random stray dogs of your  \narea. Now you do not have any clue as to what \ntrend is being followed in this dataset as you  \ndon’t know their breed, or colour or any other \nfeature. Thus, you would put this into a \nlearning approach -based AI machine and the  \nmachine would come up with various patterns \nit has observed in the features of these 1000  \nimages. It might cluster"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 31,
    "text": "the data on the basis of \ncolour, size, fur style, etc. It might also come up \nwith some very unusual clustering algorithm  \nwhich you might not have even thought of! \n \n          Learning Based AI Model \n \nWe can say that it refers to the AI modelling where the machine learns by itself. Under the  \nLearning Based approach, the AI model gets trained on the data fed to it and then is able to  \ndesign a model which is adaptive to the change in data. That is, if the model is trained with X  \ntype of data and the machine designs the algorithm around it, the model would modify itself  \naccording to the changes which occur in the data so that all the exceptions are handled in this \ncase. \nFor example, A learning -based spam email filter is a computer program that automatically  \nidentifies whether an incoming email is spam or not. Instead of being explicitly programmed \nwith rules for identif"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 31,
    "text": "ying spam, the filter learns from examples of labeled emails during a  \ntraining phase. \n \nDuring training, the filter is provided with a large dataset of emails, each labeled as either  \nspam or legitimate (non -spam). The filter analyzes the content and characteristics of these  \nemails, such as words used, sender information, and presence of attachments. Using machine \nlearning algorithms, the filter learns to recognize patterns that distinguish spam from \nlegitimate emails."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 32,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only.  \nOnce trained, the filter can classify new incoming emails as spam or not spam based on the  \npatterns it learned. It continuously adapts and improves its accuracy over time as it encounters \nnew examples. This learning-based approach allows the filter to effectively identify and filter  \nout spam emails, helping users manage their email inbox more efficiently. \n \nCategories of Machine learning based models \nLearning-based approaches are indeed a broad category that encompass both machine \nlearning and deep learning. Machine learning can further be divided into three parts: \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nSupervised Learning \nIn a supervised learning model, the dataset which is fed to the machine is labelled. In other  \nwords, we can say that the dataset is known to th"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 32,
    "text": "e person who is training the machine only  \nthen he/she is able to label the data. A label is some information which can be used as a tag  \nfor data. For example, students get grades according to the marks they secure in \nexaminations. These grades are labels which categorize the students according to their marks. \n \n▪ Supervised Learning indicates having a supervisor as a \nteacher \n▪ For e.g. A math teacher teaches the class by making the  \nstudents learn using a lot of solved examples(training) and  \nthen test the knowledge gained by giving the class, problems \nto solve on their own. \nReinforcement \nLearning \nUnsupervised \nLearning \nSupervised \nLearning \nLearning Based Approach \n(Machine Learning)"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 33,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only.  \n▪ Similarly, Supervised Learning is when you make the machine learn by teaching or \ntraining the machine using labeled data. \n \n \n \n \nSupervised Learning – Example \n▪ Let’s consider the example of currency coins. \n▪ Problem Statement: Build a model to predict the coin based on its weight. \n▪ Assume that we have different currency coins (dataset) having different weights. \n▪ 1 Euro weighs 5 grams \n▪ 1 Dirham weighs 7 grams \n▪ 1 Dollar weighs 3 grams \n▪ 1 Rupee weighs 4 grams and so on \n▪ Feature – Weights \n▪ Label – Currency \n \n \nSo, if a model is trained in tagging the features i.e., the weights of the coin with the targets  \ni.e., currency, the trained model can be further be used to identify a coin based on its  \nweight (since it has already learnt). \n▪ In the example shown"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 33,
    "text": "in the \nimage, the model has learned \nfrom labeled input data and \nproduces output to classify them  \nas dogs and cats. \n▪ Therefore, you can see that the  \nmodel learns from the training \ndata and then applies the same  \nknowledge to test data."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 34,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only.  \nUnsupervised Learning \nAn unsupervised learning model works on unlabelled \ndataset. This means that the data which is fed to the  \nmachine is random and there is a possibility that the  \nperson who is training the model does not have any  \ninformation regarding it. The unsupervised learning  \nmodels are used to identify relationships, patterns and \ntrends out of the data which is fed into it. It helps the user \nin understanding what the data is about and what are the \nmajor features identified by the machine in it. \nFor example, you have a random data of 1000 dog images and you wish to understand some \npattern out of it, you would feed this data into the unsupervised learning model and would \ntrain the machine on it. After training, the machine would come up with  patterns whi"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 34,
    "text": "ch it \nwas able to identify out of it. The Machine might come up with patterns which are already \nknown to the user like colour or it might even come up with something very unusual like the \nsize of the dogs. \n▪ Unsupervised Learning is a type of learning without any guidance \n▪ For e.g. A child learning to swim on his own without any supervision. Here, the child is \nthe model trying to discover ways and techniques to swim and the swimming pool  is \nsimilar to the unknown data fed to the model. \n▪ Here, the machine is responsible to discover patterns, similarities, and differences on  \nits own based on the unlabeled dataset. \n \nUnsupervised Learning - Example \nLet’s consider the example of a supermarket \nAssume that we have a customer database with records of their \nproducts bought over a period. \nNow you being the marketing manager decides to send a \ngrocery offer message to those custo"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 34,
    "text": "mers who buys grocery  \nregularly. \n• Note that there was no customer labeled as grocery  shoppers and non-grocery \nshopper. \n• Model could discover patterns on its own and could come up with these two \nclusters/groups."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 35,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only.  \n• In the example shown in the image, the model  \nhas to process information without any labels. \n• It has to analyze and process the data to identify \nhidden patterns and attributes and then uses  \nthat to classify the animals into two categories  \nbased on similarities \nAs you observe in the image, input is not labeled but \nthe model can come up with two clusters by identifying similar patterns and attributes and  \nhave grouped them together- \n• All Cats have been grouped into cluster 1 \n• All Dogs have been grouped into cluster 2 \n \n \nTest Yourself: \nIdentify the model: Supervised or Unsupervised? \nCase 1: Social Media platforms identify your friend in a picture from an album of tagged  \nphotographs \n \n \n \n \n \n \n \n \nIt is supervised learning. Here social media platform is us"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 35,
    "text": "ing tagged photos to recognize the  \nperson. Therefore, the tagged photos become the labels of the pictures and we know that  \nwhen the machine is learning from labeled data, it is supervised learning. \nCase 2: OTT platform Recommendations based on someone’s watch history \n \nIt is unsupervised learning. This is what OTT platforms like Netflix, Pandora, and Spotify do all \nthe time; they collect the songs/movies that you like already, evaluate the features based on \nyour likes/dislikes and then recommend new movies/songs based on similar features."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 36,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only.  \nCase 3: Analyze bank data for suspicious-looking transactions and flag the fraud transactions \n[Note that suspicious transactions are not defined in this case] \n \nIt is unsupervised learning. In this case, the suspicious transactions are not defined, hence  \nthere are no labels of \"fraud\" and \"not fraud\". The model tries to identify outliers by looking  \nat anomalous transactions and flags them as 'fraud'. \nSupervised Vs. Unsupervised Learning \n \n \nReinforcement Learning \nThis learning approach enables the computer to make a series of decisions that maximize a  \nreward metric for the task without human intervention and without being explicitly \nprogrammed to achieve the task. \nReinforcement Learning – Example \n \n▪ Reinforcement learning is a type of learning in which a machine"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 36,
    "text": "learns to perform a \ntask through a repeated trial-and-error \nmethod. \n▪ Let’s say you provide an image of an apple to \nthe machine and ask the machine to predict it- \n▪ The machine first predicts it as ‘cherry’ and \nyou give negative feedback that it’s incorrect. \n▪ Now, the machine learns that it’s not a cherry."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 37,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only.  \n▪ Then again, you ask the machine to \npredict the fruit by giving an image of an  \napple as input; \n▪ Now, it knows it is not a cherry. \n▪ It predicts it as an apple and you give positive \nfeedback that it’s correct. \n▪ So, now the machine learns that this is an apple. \n \n \nWhat makes it different? \n1. For supervised learning and unsupervised learning, you need to have a pretty good \nidea of the data that you have, what’s going on, and how to solve the problem. \n2. However, you will frequently encounter situations where you have to deal with large \ncomplex problem spaces. \n3. You may need to respond to unforeseen environments, and you don’t have \nsufficient data on those specific scenarios. \n4. The environment may change. Hence your system needs to be adaptive. \nReinforcement"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 37,
    "text": "Learning will be important because it doesn’t require a lot of pre - \nexisting knowledge or data to provide useful solutions. \n \n \nExamples of Reinforcement Learning \n \n \n \n \n \n \n \n \n \nParking a car \n Humanoid walking"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 38,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only.  \nReinforcement \nLearning \nLearn by \nRewarding \nActions \nSupervised \nLearning \nSummary of ML Models \n• Supervised learning models are used when we want to determine relationships \nthrough training. \n• Unsupervised learning models are used when we want to discover new patterns from \ndata. \n• Reinforcement learning models are used when we want to implement machine \nlearning through a reward mechanism. \n  \n \n \n \n \n \n \n \n \n \nSub-categories of Supervised Learning Model \n \nThere are two types of Supervised Learning models: Classification model and Regression \nmodel. \n \n \n \n \n \n \n \n \n \nFamily of \nML Models \nUnsupervised \nLearning \nDiscover New \nPatterns \nDetermine \nrelationships \nthrough training"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 39,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only.  \nClassification Model \nHere the data is classified according to the \nlabels. For example, in the grading system, \nstudents are classified on the basis of the  \ngrades they obtain with respect to their  \nmarks in the examination. This model \nworks on discrete dataset which means  \nthe data need not be continuous. \nExamples of the Classification Model \n \nIn this case, the model would be trained on historical weather data that includes  \ntemperature information labeled as \"hot\" or \"cold\". The model would learn the patterns \nthat differentiate hot and cold weather based on \nfactors like: \n \n• Location (average temperatures vary \ngeographically) \n• Season (summer vs. winter) \n• High and low temperatures \n• Humidity \n \nWhen presented with weather data for tomorrow, the \ntrained class"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 39,
    "text": "ification model would analyze these \nfactors and predict the most likely category - \"hot\" or \"cold\" weather tomorrow. \n \nClassifying emails as spam or not: The model is shown tons of emails, both real ones (like  \nfrom friends or colleagues) and spam. The model learns what makes an email look like spam. \nOnce trained, the model sees a new email. It analyzes the clues in the email and decides: is  \nthis spam or not? It assigns a category - \"spam\" or \"not spam\" - just like sorting your mail. \n \n \n \n \nIn modern -day Email, classifiers identify if the email is spam and have evolved into other  \ncategories such as social, advertisement, notifications, etc. Similar models are increasingly  \nbeing used in messaging applications."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 40,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only.  \nRegression Model \nRegression: Such models work on  continuous data. For \nexample, if you wish to predict your next salary, then you  \nwould put in the data of your previous salary, any \nincrements, etc., and would train the model. Here, the data \nwhich has been fed to the machine is continuous. \n \n▪ Regression algorithms predict a continuous value based on the input variables. \n▪ Continuous values as Temperature, Price, Income, Age, etc. \n \n \n \nExamples of the Regression Model \nExample 1: Predicting temperature \nTemperature is a continuous variable, meaning it can  \ntake on any value within a range. Regression models are \nwell-suited for predicting continuous outputs. \nExample 2: Predicting the price of the house \nPredicting the price of the house based on some parameters: \n1."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 40,
    "text": "[Features/Independent Variables] \n1. No of bedrooms \n2. Carpet Size \n3. Garage Area \n2. [Label/Dependent Variable] \n1. Price [Label/Dependent Variable] \n▪ In the House Price Prediction Problem, we are trying to predict the price (dependent \nvariable) based on certain parameters like the number of bedrooms, carpet size, and  \ngarage area (independent variables). \nExample 3: Used Car Price Prediction \nThis model predicts the selling price of the car with the help of a few parameters like \n▪ fuel type,"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 41,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only.  \n▪ years of service, \n▪ the number of previous owners, \n▪ kilometers driven, \n▪ transmission type (manual/automatic) \nThis type of model will be of type regression since it will predict an approximate price \n(continuous value) of the car based on the training dataset. \n \n \nTest Yourself: \nIdentify the model: Classification or Regression? \nCase 1: Predicting whether a customer is eligible for a bank loan or not? \nIt is Classification. Binary Classification; since the model is going to predict whether or  \nnot the customer is eligible for a loan - The output will be either yes or no (discrete \nvalues) \n \nCase 2: Predicting weather for next 24 hours \nIt is Regression because predicting weather for next 24 hours will be a continuous range \n(it will keep changing over the period of"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 41,
    "text": "24 hours) \n \nSub-categories of Unsupervised Learning Model \nUnsupervised learning models can be further divided into two categories: Clustering model \nand Association model."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 42,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only.  \nWhat is Clustering? \n \n \n \nIn this example, we have input data with no class labels (unlabeled data), and this input data  \ncomprises of birds and animals. Note that, even though there were no class labels, the  \nunsupervised learning model was able to divide this data into two clusters based on clustering. \nThe two clusters have been formed based on the similarity of characteristics. The first cluster \ncomprises all the animals, and the second cluster comprises all the birds. \n \nDifference between Clustering and Classification \n▪ Classification uses predefined classes in which objects are assigned. \n▪ Clustering finds similarities between objects and places them in the same cluster and \nit differentiates them from objects in other clusters. \n \nClustering – Example \nJim enjoys"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 42,
    "text": "listening to music. Jim likes to listen to music having slow tempo and soft  \nintensity whereas he dislikes songs having fast tempo and high intensity. \n▪ We have grouped all the songs having slow tempo and soft intensity into 1 cluster that \nhe likes \n▪ While, songs with a fast tempo and high intensity into another cluster \n▪ Now if he listens to a new song X with a slow tempo and soft intensity. Could you \npredict will he like the song X or not? \nThis is how clustering techniques work. The clustering model will be able to identify  \nclusters based on some similarities or patterns which are not defined in the input. For  \nexample, tempo and intensity are the only features known, but clusters based on likes and \ndislikes have been grouped together and given as output. Similar techniques are used in  \nOTT platforms like Netflix/Spotify for recommendations."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 43,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only.  \nAssociation \nAssociation Rule is an unsupervised learning method that is used to find interesting \nrelationships between variables from the database. \n \n \n \n \n \nBased on the purchase pattern of customers A and B, can you predict any Customer X who \nbuys bread will most probably buy? \n \n \n \n \n \nBased on the purchase pattern of other customers, we can predict that there is high probability \nthat any customer x who buys bread will most probably buy butter. \nTherefore, such meaningful associations can be useful to recommend items to customers. This is \ncalled Association Rule."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 44,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only.  \n           Summary of detailed classification of ML models \n \n \n \nTest Yourself: \nLet’s have knowledge check based on learning approaches and its types! \nQ1. Which learning approach uses labelled data for training? \n \nQ2. The target variable is categorical in Problem? \n \n \nQ3. Which algorithmic model would you use when you have to predict a continuous \nvalued output? \n \n \nQ4. Which of the following is false about Reinforcement Learning? \n \n \n \n \nSupervised Learning Reinforcement Learning \nUnsupervised Learning \nRegression Clustering Classification \nRegression Clustering Classification \nUses Reward Mechanism Target is to Maximize the Reward \nPredicts a continuous value as output"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 45,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only.  \nQ5. Clustering is learning and its goal is to ? \n \n \n \n \n \nSub-Categories of Deep Learning \nDeep Learning enables software to train itself to perform tasks with vast amounts of data.  \nIn deep learning, the machine is trained with huge amounts of data which helps it to train  \nitself around the data. Such machines are intelligent enough to develop algorithms for  \nthemselves. There are two types of Deep Learning models: Artificial Neural Networks (ANN) \nand Convolution Neural Network (CNN). \n \n \n \n \n \n \n \n \nArtificial Neural networks (ANN) - Artificial Neural networks are modelled on the human brain \nand nervous system. They are able to automatically extract features without input from the  \nprogrammer. Every neural network node is essentially a machine learning algorithm. It"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 45,
    "text": "is  \nuseful when solving problems for which the data set is very large. \n \nConvolutional Neural Network (CNN) - Convolutional Neural Network is a Deep Learning  \nalgorithm which can take in an input image, assign importance (learnable weights and  \nbiases) to various aspects/objects in the image and be able to differentiate one from the o \n \n \n \n \nSupervised, Classify data points \ninto different classes \nUnsupervised, Divide the data \npoints into different groups \nUnsupervised, Predict the output based \non input data points"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 46,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only.  \n2.3 Artificial Neural Networks \n \n \n \nWhat is Neural Network? \nNeural networks are loosely modelled after  \nhow neurons in the human brain behave. The \nkey advantage of neural networks is that they \nare able to extract data features \nautomatically without needing the input of  \nthe programmer. A neural network is \nessentially a system of organizing machine  \nlearning algorithms to perform certain tasks. \nIt is a fast and efficient way to solve problems \nfor which the dataset is very large, such as in images. \n \n \nThis is a representation of how neural networks work: \n \n▪ A Neural Network is divided into multiple layers and each layer is further divided into \nseveral blocks called nodes. Each node has its own task to accomplish which is then \npassed to the next layer. \n▪ Neural"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 46,
    "text": "Network consists of an input layer, hidden layer which performs computation \nusing weights and biases on each node and finally, information is passed through these \nlayers to reach the output layer. \n• The first layer of a Neural Network is known as the input layer. The job of an input  \nlayer is to acquire data and feed it to the Neural Network. No processing occurs at  \nthe input layer. \n• Next to it, are the hidden layers. Hidden layers are the layers in which the whole  \nprocessing occurs. Their name essentially means that these layers are hidden and are \nnot visible to the user. Each node of these hidden layers has its own machine  \nlearning algorithm which it executes on the data received from the input layer. \nPurpose: To understand and experience what a neural network is like. \nBrief: \nNeural networks are loosely modelled after how neurons in the human brain behave. \nThe key adv"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 46,
    "text": "antage of neural networks  is that  they are  able to extract data  features \nautomatically without needing the input of the programmer. A neural network is essentially \na system of organizing machine learning algorithms to perform certain tasks. It is a fast and \nefficient way to solve problems for which the data set is very large, such as in images."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 47,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only.  \n▪ The hidden layer performs computation by means of weights and biases Information \npasses from one layer to the other after the value found from this calculation passed \nthrough a selected activation function. \n▪ The process of finding the right output begins with trial and error until the network \nfinally learns. \n▪ With each try, the weights are adjusted based on the error found between the  \ndesired output and the network output. \nThere can be multiple hidden layers in a neural network system and their number  \ndepends upon the complexity of the function for which the network has been \nconfigured. Also, the number of nodes in each layer can vary accordingly. The last  \nhidden layer passes the final processed data to the output layer which then gives it to  \nthe user as the"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 47,
    "text": "final output. Similar to the input layer, output layer too does not process \nthe data which it acquires. It is meant for user-interface. \n \nReal-world applications of neural network are facial recognition, customer support \nchatbot,      vegetable price prediction etc. \n \n \nHow does AI make a Decision? \nLet's say you want to go out to the park today. What would be your thought process? What  \nwould you consider? \nMost of us would want to avoid getting soaked in the rain. These are possible factors that  \nmay influence your decision whether to go out. So, the first question that you may ask is,  \n“Should I bring a rain jacket?” \nThen, you may also ask, “Should I bring an umbrella?” Or \nyou may also ask, “What is the weather now?” \nAnd finally, “What will the weather be like, later in the day?” \n \n \n \n    \nDo I have a jacket? Do I have an umbrella? Is it raining now? What is the weather"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 47,
    "text": "forecast for later?"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 48,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only.  \nNow, you have the factors that will influence your  \ndecision to go out. But take note, not all factors are  \nequal. Some factors are more important, while some \nare not. \nLet's see which one is more important. Let us rank  \nthem from the most important to the least \nimportant. \nFor me, “is it sunny now” is more important than  \n“the weather forecast later”. And “having a jacket”  \nis more important than “having an umbrella. We can \nput the ranking for this example. \n \nNow let us convert this to perceptron. \n \nGoing back to the earlier example, we have four inputs. So, let’s draw the perceptron with  \nfour inputs (from X1 to X4). Next, we have their weights (from W1 to W3). Then, we also  \nhave the bias B, with weight WB. \nFinally, we sum them all up, compare with threshold, a"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 48,
    "text": "nd we will get our output. \n \n \n \nNow we will fill in the four inputs with the factors that we have listed out. \n•Do I have a jacket? \n•Do I have umbrella? \n•Is it sunny now? \n•What is the weather forecast for later?"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 49,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only.  \n \nNow we will fill in the importance. But the importance is not very useful in mathematical \ncalculations. \nNext, let us assign some numbers to them. At the same time, we will also assign a number for \nthe bias weight (WB). \nHow do we know what should be the actual values for the weights? We will not know what are \nthe actual weights. However, we can make some assumptions. \n \n \n \n \nThe values for the weights can come from experience. He may have an experience being \nsunny now would most likely mean a bright day ahead, hence the high importance there. \nIt can also come from personal preference. A person may judge a particular factor more \nheavily as compared to another person. For example, she may be more concerned with  \nthe weather forecast, hence the higher importance there."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 49,
    "text": "The values for WB are also based on personal preference. If a person is more cautious,  \nhe may set the value for WB to be higher, hence his decision would gear towards staying \nindoors unless he is sure that it would not rain. On another hand, a person who is more  \ndaring will have a lower WB, hence he is more likely to go out regardless of the current  \nsituation. In this example, we choose 4 as we want to be more cautious."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 50,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only.  \n \n \n \nTherefore, there is no right or wrong answers in coming up with the values for the  \nweights. However, the effects of the values will determine the outcome that the person \nis going to take, whether to go out or not. That is the reason why everyone comes up  \nwith a different decision, even though the situation is the same for everyone. \nFor this example, let’s say: I have a jacket, I don’t have an umbrella, it is sunny now, and \nthe weather forecast is going to rain. We can convert the yes and no to numbers 1 and \n0. For bias, we will always take 1."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 51,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only.  \nFrom this calculation, the output is 0.5. Since this is higher than the threshold (which is \nzero), the result is I will go out to the park. \n \n \nNow let us change for another example. \nlet’s say: I don’t have a jacket, I have an umbrella, it is not sunny now, and the weather  \nforecast is ok. We will convert the yes and no to numbers 1 and 0. And similarly, for bias,  \nwe will take 1. \n \n \n \n \n \n \nFrom this calculation, the output is -0.5. Since this is lower than the threshold (which is \nzero), the result is I will not go out to the park."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 52,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only.  \n \n \nActivity 1 \nHuman Neural Network – The Game \n \n \nSession Preparation \n \n \nLogistics: For a class of 40 students [Individual Activity] \n \n \nMaterials Required: \n \nITEM QUANTITY \nImages (To be kept with the facilitator) 2 \nPost-It Notes 80 \nSketch-pens 40"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 53,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only.  \n \n \nLet us develop a better understanding about this concept with the help of a game called \nHuman Neural Network. \nGame Structure: \n \n \nLayers Number of Students Number of chits \nInput Layer 7 6 \nHidden Layer 1 6 4 \nHidden Layer 2 6 2 \nOutput Layer 1 - \nTOTAL 20 - \n \n \n \nPurpose: To understand and experience what a neural network is like. \nBrief: \nStudents will now experience how Neural networks work with the help of an activity. Each \nof the students will be considered as the node of either Input Layer,1 st Hidden Layer, 2nd \nHidden Layer or the Output Layer. The instructions and rules have been mentioned in the \nStudents Handbook. \nAfter arranging the students at their positions and handing them sticky notes to write, \nshow the sample image print -out to the input layer stu"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 53,
    "text": "dents. Let the students  \nunderstand and do by themselves after this. \nWhen to intervene? \nAsk the students to play the game with honesty. No two nodes can discuss anything.  \nEach one of them has to use their own discretion to understand and play."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 54,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only.  \nGround Rules: \n● No one is allowed to talk or discuss till the game ends. Fun of the game lies in playing it \nhonestly. \n● Each layer should sit distant to each other. \n● The image should only be shown to the Input layer and no one else. \n● The game is supposed to be played silently. This means that one has to write a word on the               \nchit and pass on the chit without speaking out aloud. \n● One needs to process the data as fast as possible, hence not take much time can be taken  \nto write and pass on the chits. \n● Input layer nodes cannot discuss the image shown with each other. Everyone has to use \ntheir own discretion. \n● No sentences or multiple words are to be written on the chit. Only one word per chit is  \nallowed. \n● Once the task of a layer is finished, that"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 54,
    "text": "layer needs to go and sit aside and not \ndisturb others till the game ends. \nGame Instructions: \nInput Layer: \n7 students will be standing as the nodes of an input layer. \nAll of them will be shown an image. After looking at it, they need to write 6 different  \nwords on 6 different chits. They have to choose the words which describe the image in  \nthe best way possible. They can also repeat the words if needed. \nAfter making these chits, they need to pass on one chit to each of the nodes of hidden \nlayer 1. That is, 1 chit will be given to one member. \n \nHidden Layer 1: \n6 students will be standing as the nodes of hidden layer 1. \nEach of them will receive 7 chits from 7 different input nodes. Now they have to take a  \ngood look at the chits and then write down 4 different words on 4 different chits. For this, \nthey can either use the same words as the input layer did, or they can make t"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 54,
    "text": "heir own  \ninformation (relevant to the context) and write it. \nNow these 4 chits are to be given randomly to any 4 nodes of Hidden Layer 2.Out of the \n6 nodes of 2nd hidden layer, one can choose any 4 and give once chit  to each. (For best \nresults, each node of hidden layer 2 should get almost same  number of chits thus the  \ndivision should be done properly) \n \nHidden Layer 2: \n6 Students will be standing as the nodes of hidden layer 2. \nEach one of them will get some number of chits from the previous layer. Now they have \nto perform the same task as hidden layer 1 and have to write down2 different words on \n2 different chits and pass it on to the output layer. \nOutput Layer: \nFinally, the output layer node will get 12 chits. Now s/he has to understand all the words \nand has to guess which image was shown to the input layer initially. \nOutput layer will then write a summary out of all"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 54,
    "text": "the words received to explain his/her \ndeduction. The summary should not be more than 5 lines."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 55,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only.  \nFinally, the output layer presents this summary in-front of everyone and the real image \nis finally revealed to all. \n \nIf the summary is accurate enough, the whole network wins else they lose. \n \n \nTest Yourself: \nChoose the most appropriate answer for each question. \n \n \n1. In which type of machine learning is the data labeled with the desired output? \na) Supervised Learning \nb) Unsupervised Learning \nc) Reinforcement Learning \nd) Deep Learning \n \n \n2. An email spam filter that learns to identify spam emails based on labeled examples is an \napplication of: \na) Supervised Learning \nb) Unsupervised Learning \nc) Reinforcement Learning \nd) Transfer Learning \n \n3. A machine learning algorithm that groups similar customer purchases into clusters for \nrecommendation systems uses:"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 55,
    "text": "a) Supervised Learning \nb) Unsupervised Learning \nc) Reinforcement Learning \nd) Neural Networks \n \n \n4. An AI agent playing a game and learning from its rewards and penalties is an example of: \na) Supervised Learning \nb) Unsupervised Learning \nc) Reinforcement Learning \nd) Evolutionary Learning"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 56,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only.  \n5. Which of the following statements is NOT true about supervised learning? \na) Requires labeled data for training. \nb) Used for classification and regression tasks. \nc) Can be less efficient for large datasets. \nd) Often used in image recognition applications. \n \n \n6. In an unsupervised learning scenario, the goal is to: \na) Predict a specific output based on labeled data. \nb) Identify patterns and relationships within unlabeled data. \nc) Train an AI agent through rewards and penalties. \nd) Develop complex neural network architectures. \n \n \n7. Clustering algorithms are commonly used in unsupervised learning for: \na) Spam filtering \nb) Image classification \nc) Stock price prediction \nd) Grouping similar data points \n \n \n8. Reinforcement learning is particularly useful for scen"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 56,
    "text": "arios where: \na) Large amounts of labeled data are available. \nb) The desired outcome is clear, but the path to achieve it is unknown. \nc) The data is structured and easily categorized. \nd) The task requires reasoning and logical deduction. \n \n \n9. Imagine an AI playing a game and learning to win by trial and error. This is an example of: \na) Supervised Learning \nb) Unsupervised Learning \nc) Reinforcement Learning \nd) Natural Language Processing"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 57,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only.  \n10. Artificial neural networks are inspired by the structure and function of: \na) The human brain \nb) Quantum computers \nc) Complex mathematical models \nd) High-speed processors \n \n \n11. The process of adjusting the weights in a neural network to improve performance is called: \na) Activation \nb) Learning \nc) Optimization \nd) Training \n \n12. A neural network with multiple layers of interconnected neurons is called a: \na) Single-layer network \nb) Deep Neural Network \nc) Linear network \nd) Perceptron \n \n \n13. Neural networks are particularly well-suited for tasks involving: \na) Simple calculations and mathematical operations \nb) Recognizing patterns in complex data like images and text \nc) Performing logical deductions and reasoning tasks \nd) Storing and retrieving large amounts"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 57,
    "text": "of information \n \n \n14. Training a neural network often requires: \na) A small set of labeled data samples \nb) A significant amount of data and computational resources \nc) A specific set of programming instructions \nd) A human expert to guide the learning process"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 58,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only.  \nAssertion and reasoning-based questions: \nQ1. Assertion: Unsupervised Learning is a type of learning without any guidance. \nReasoning: Unsupervised learning models work on unlabeled datasets, where the data fed  \ninto the machine is random and the person training the model may not have any prior  \ninformation about it. \nOptions: \n(a) Both A and R are true and R is the correct explanation for A \n(b) Both A and R are true and R is not the correct explanation for A \n(c) A is True but R is False \n(d) A is false but R is True \n \nQ2. Assertion (A): Information processing in a neural network relies on weights and biases \nassigned to nodes. \n \nReasoning (R): These weights and biases determine how strongly a node is influenced by its \ninputs and its overall contribution to the next lay"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 58,
    "text": "er. \n \nReflection Time: \nAnswer the following questions: \nQ1. Give difference between rule based and learning based AI models. \nQ2. What is supervised, unsupervised and reinforcement learning? Explain with examples. \nQ3. What is clustering and how is it different from classification? \nQ4. Explain neural networks. Also give functions of three layers of neural networks. Q5. \nDifferentiate between classification and regression model. \nQ6. What is neural network? Give the functioning of its three layers? \nQ7. Identify the type of learning (supervised, unsupervised, reinforcement learning) are the \nfollowing case studies most likely based on? \na) Case Study 1: \nA company wants to predict customer churn based on past purchasing behavior,  \ndemographics, and customer interactions. They have a dataset with labeled examples \nof customers who churned and those who did not. \nb) Case Study 2: \nA soc"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 58,
    "text": "ial media platform wants to group users based on their interests and behavior to \nrecommend relevant content. They have a large dataset of user interactions but no  \npredefined categories. Which type of learning is this case study most likely based on? \nc) Case Study 3:"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 59,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only.  \nAn autonomous vehicle is learning to navigate through a city environment. It receives \nfeedback in the form of rewards for reaching its destination safely and penalties for  \ntraffic violations. Which type of learning is this case study most likely based on? \nd) Case Study 4: \nA healthcare provider wants to identify patterns in patient data to personalize \ntreatment plans. They have a dataset with various patient attributes but no predefined \nlabels indicating specific treatment plans. Which type of learning is this case study  \nmost likely based on? \ne) Case Study 5: \nA manufacturing company wants to optimize its production process by detecting \nanomalies in sensor data from machinery. They have a dataset with examples of  \nnormal and anomalous behavior. Which type of learnin"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 59,
    "text": "g is this case study most likely  \nbased on? \n \nQ8. Identify the type of model (classification, regression, clustering, association model) are  \nthe following case studies most likely based on? \na) A bank wants to predict whether a loan applicant will \"default\" or \"non -default\" on \ntheir loan payments. They have a dataset containing information such as income,  \ncredit score, loan amount, and employment status. \n \nb) A real estate agency wants to predict the selling price of houses based on various  \nfeatures such as size, location, number of bedrooms, and bathrooms. They have a  \ndataset containing historical sales data. \n \nc) A marketing company wants to segment its customer base into distinct groups based  \non purchasing behavior for targeted marketing campaigns. They have a dataset \ncontaining information such as purchase history, frequency of purchases, and amount \nspent. \n \nd) A g"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 59,
    "text": "rocery store wants to identify associations between different products purchased  \nby customers to understand which products are commonly bought together. They have \na transaction dataset containing records of items purchased together during each  \ntransaction. \n \nQ9. A healthcare provider wants to improve patient care by predicting the length of hospital  \nstays for different medical conditions. They have a dataset containing patient demographics, \nmedical history, and treatment details. The task involves: \n \na) To predict whether a patient will have a short or long hospital stay. \nb) To predict the number of days a patient will stay in the hospital. \nc) To segment patients into groups with similar characteristics for personalized treatment \nplans. \nd) To identify patterns in patient treatments and outcomes."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 60,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only.  \nIdentify the type of model (classification, regression, clustering, and association model) in the \nabove tasks. \nQ10. Convert the following scenarios to perceptron: \na) Context: A manager is deciding whether to approve a work-from-home request \nfrom an employee. \nFactors: \n- Does the employee perform well when working remotely? \n- Are there any upcoming team meetings or collaborative projects? \n- Does the company's policy support remote work? \n- Is it beneficial for both the employee and the company? \n \n \nb) Context: A homeowner is deciding whether to invest in solar panels for their \nhouse. \nFactors: \n- Do I have a sufficient average amount of sunlight in my area? \n- Are there any available incentives or rebates for installing solar panels? \n- Does installing solar panels imp"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 60,
    "text": "act the value of my home? \n- Does solar energy lead to environmental benefits?"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 61,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only. \n \nUnit-3: Evaluating Models \n \nLesson Title: Evaluating Models Approach: Session + Activity \nSummary: In this module, students are introduced to the common metrics used to evaluate AI \nmodels. They will know how to derive and calculate the evaluation metrics and would also get \nan idea on how to improve the accuracy/efficiency of an AI Model. They will be introduced to \nthe concept of Train/ Test Split, Common evaluation metrics such as Accuracy, Confusion \nMatrix, Precision, Recall, F1 Score) Learners will also be able to identify the use of this metrics \nin use cases encountered in everyday life. \nLearning Objectives: \n \n1. To introduce students to the common metrics used to evaluate AI models \n2. To familiarize students with deriving and calculating the evaluation metrics \n3"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 61,
    "text": ". To enable students to recognize the most suitable evaluation metric for a given  \napplication. \nLearning Outcomes: \n \n1. Recognise common metrics used to evaluate AI models \n2. Derive and calculate the evaluation metrics \n3. Recognize the most suitable evaluation metric for a given application. \n  Pre-requisites: Essential understanding of Artificial Intelligence \nKey-concepts: \n \n1. Importance of model evaluation \n2. Evaluation metrics for classification"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 62,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only.  \nIntroduction \nTill now we have learnt about the 4 stages of AI project cycle, viz. Problem scoping, Data \nacquisition, Data exploration and modelling. While in modelling we can make different types \nof models, how do we check if one’s better than the other? That’s where Evaluation comes \ninto play. In the Evaluation stage, we will explore different methods of evaluating an AI model. \nModel Evaluation is an integral part of the model development process. It helps to find the \nbest model that represents our data and how well the chosen model will work in the future \n \n3.1: Importance of Model Evaluation \nWhat is evaluation? \n \n▪ Model evaluation is the process of using different \nevaluation metrics to understand a machine learning \nmodel’s performance \n▪ An AI model gets better"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 62,
    "text": "with constructive feedback \n▪ You build a model, get feedback from metrics, make \nimprovements and continue until you achieve a \ndesirable accuracy \n \n \n \n \n \n \n• It’s like the report card of your school \n• There are many parameters like grades, percentage, \npercentiles, ranks \n• Your academic performance gets evaluated and you know \nwhere to work more to get better"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 63,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only. \n \nNeed of model evaluation \nIn essence, model evaluation is like giving your AI model a report card. It helps you understand its \nstrengths, weaknesses, and suitability for the task at hand. This feedback loop is essential for \nbuilding trustworthy and reliable AI systems. \nAfter understanding the need for Model Evaluation, let’s know how to begin with the process. \nThere can be different Evaluation techniques, depending of the type and purpose of the model. \n \n \n3.2: Splitting the training set data for Evaluation \nTrain-test split \n▪ The train-test split is a technique for evaluating the performance of a machine learning  \nalgorithm \n▪ It can be used for any supervised learning algorithm \n▪ The procedure involves taking a dataset and dividing it into two subsets: The training"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 63,
    "text": "dataset and the testing dataset \n▪ The train-test procedure is appropriate when there is a sufficiently large dataset available"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 64,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only. \n \nNeed of Train-test split \n▪ The train dataset is used to make the model learn \n▪ The input elements of the test dataset are provided to the trained model. The model makes \npredictions, and the predicted values are compared to the expected values \n▪ The objective is to estimate the performance of the machine learning model on new data: \ndata not used to train the model \n \nThis is how we expect to use the model in practice. Namely, to fit it on available data with known \ninputs and outputs, then make predictions on new examples in the future where we do not \nhave the expected output or target values. \n \nRemember that It’s not recommended to use the data we used to build the model to evaluate \nit. This is because our model will simply remember the whole training set, and will th"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 64,
    "text": "erefore \nalways predict the correct label for any point in the training set. This is known as overfitting. \n \n \n3.3: Accuracy and Error \n▪ Bob and Billy went to a concert \n▪ Bob brought Rs 300 and Billy brought Rs 550 as \nthe entry fee for that \n▪ The entry fee per person was Rs 500 \n▪ Can you tell: \n▪ Who is more accurate? Bob or Billy? \n▪ How much is the error for both Bob and Billy in estimating the concert entry fee? \n \n \nYou will learn more about the concepts including train test split and cross validation in \nhigher classes."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 65,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only. \n \nAccuracy \n▪ Accuracy is an evaluation metric that allows you to measure the total number of \npredictions a model gets right. \n▪ The accuracy of the model and performance of the model is directly proportional, and \nhence better the performance of the model, the more accurate are the predictions. \nError \n▪ Error can be described as an action that is inaccurate or wrong. \n▪ In Machine Learning, the error is used to see how accurately our model can predict data it \nuses to learn new, unseen data. \n▪ Based on our error, we choose the machine learning model which performs best for a \nparticular dataset. \n \n \nError refers to the difference between a model's prediction and the actual outcome. It quantifies how often \nthe model makes mistakes. \n \n \nImagine you're training a model to p"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 65,
    "text": "redict if you have a certain disease (classification task). \n• Error: If the model predicts you don’t have a disease but you actually have a disease, that's \nan error. The error quantifies how far off the prediction was from reality. \n• Accuracy: If the model correctly predicts disease or no disease for a particular period, it  \nhas 100% accuracy for that period."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 66,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only. \n \nKey Points: \n• Here the goal is to minimize error and maximize accuracy. \n• Real-world data can be messy, and even the best models make mistakes. \n• Sometimes, focusing solely on accuracy might not be ideal. For instance, in medical \ndiagnosis, a model with slightly lower accuracy but a strong focus on avoiding incorrectly \nidentifying a healthy person as sick might be preferable. \n• Choosing the right error or accuracy metric depends on the specific task and its \nrequirements. \nUnderstanding both error and accuracy is crucial for effectively evaluating and improving AI \nmodels. \nActivity 1: Find the accuracy of the AI model \n \n \nCalculate the accuracy of the House Price prediction AI model \n• Read the instructions and fill in the blank cells in the table. \n• The formula for"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 66,
    "text": "finding error and accuracy is shown in the table \n• Accuracy of the AI model is the mean accuracy of all five samples \n• Percentage accuracy can be seen by multiplying the accuracy with 100 \n \nPredicted House \nPrice (USD) \nActual House \nPrice (USD) \nError Abs \n(Actual-Predicted) \nError Rate \n(Error/Actual) \nAccuracy \n(1-Error rate) \nAccuracy% \n(Accuracy*100)% \n391k 402k Abs (402k-391k)= \n11k \n11k/402k=0.027 1-0.027= 0.973 0.973*100%= 97.3% \n453k 488k     \n125k 97k     \n871k 907k     \n322k 425k     \n \n \n*Abs means the absolute value, which means only the magnitude of the difference without any \nnegative sign (if any)  \nThe Model Evaluation stands on the two pillars of accuracy and error. Let’s understand some \nmore metrics standing on these two pillars. \n \n \n \n \nPurpose: To understand how to calculate the error and the accuracy. \nSay: “The youth will understand the concept of accuracy and"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 66,
    "text": "error and practice it \nmathematically.”"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 67,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only. \n \n3.4: Evaluation metrics for Classification \n \n    What is Classification? \n▪ You go to a supermarket and were given two trolleys \n▪ In one, you have to place the fruits and vegetables; in \nthe other, you must put the grocery items like bread, \noil, egg, etc. \n▪ So basically, you are classifying the items of the \nsupermarket into two classes: \n▪ fruits and vegetables \n▪ grocery \n▪ Classification usually refers to a problem where a \nspecific type of class label is the result to be predicted \nfrom the given input field of data \n▪ For example, here we are working on a vegetable - \ngrocery-classifier model that predicts whether the \nitem in the supermarket is a vegetable or a grocery \nitem \n \n \n \nVisualizing the concept of \nclassification: Left 4 Classes; \nRight 2 classes \n \n \nTry"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 67,
    "text": "Yourself: \n  Which of this is a classification use case example? \n \n \n \n \nClassification Metrics \nPopular metrics used for classification model \n▪ Confusion matrix \n▪ Classification accuracy \n▪ Precision \n▪ Recall \nHouse price prediction Credit card fraud detection \nSalary prediction"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 68,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only. \n \n   Let’s understand these metrics in details: \n \n \nConfusion matrix \nLet’s say, based on some clinical parameters; you have designed a classifier that predicts \nwhether a person is infected with a certain disease or not. \n \n \nThe output is 1 if the person is infected or 0 if the person is not infected. That is, 1 and 0 signify \nwhether a person is infected or not. \n• The confusion matrix is a handy presentation \nof the accuracy of a model with two or more \nclasses \n• The table presents the actual values on the \ny-axis and predicted values on the x-axis \n• The numbers in each cell represents the \nnumber of predictions made by a machine \nlearning algorithm that falls into that \nparticular category \n \n \n \n \n \n \nFor example, a machine learning algorithm can predict 0 or 1 and eac"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 68,
    "text": "h prediction may actually \nhave been a 0 or 1."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 69,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 70,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only. \n \n \n \nActivity 2: Build the confusion matrix from scratch \nDuration: 10 minutes \n \n \nActivity Guidelines \n• Let’s assume we were predicting the presence of a disease; for example, \"yes\" would mean \nthey have the disease, and \"no\" would mean they don't have the disease \n• So, the AI model will have output is Yes or No \n• The following chart shows the actual values and \nthe predicted values \no Construct a confusion matrix. \no Can you tell how many are correct \npredictions among all predictions? \nPurpose: Learn how to create confusion matrix from the scratch. \nSay: “The youth need to analyze the situation and tabulate a non-numerical information \na numerical one.”"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 71,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only. \n \nFill the matrix based on the table given here. \n \n \n \n \n \nCount the number of rows having  YES in both \ncolumns of the table and put the count in the \nfirst cell. Similarly, number of rows having YES \nin the first column and NO in the second \ncolumn will be shown in the top right cell of \nconfusion matrix. Number of rows having NO \nin the first column and YES in the second \ncolumn will be shown in the down left cell of \nconfusion matrix. Lastly, number o f rows \nhaving NO in the first column and YES in the \nsecond column will be shown in the downright \ncell of confusion matrix. \nActivity Guidelines – Solution \n \n \n \nActivity Reflection \n▪ So, there are 07 correct predictions out of 10 predictions. \n▪ What do you think? How good is your model? \nNow that you know how to constru"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 71,
    "text": "ct a Confusion matrix, let’s understand each cell of the \nmatrix in details."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 72,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only. \n \nTrue Positive \n▪ True Positive (TP) is the outcome of the \nmodel correctly predicting \nthe positive class \n▪ Any class can be assumed as a positive \nclass, and the rest can be assumed as \nnegative \n▪ Let’s say class 1 is assumed as the positive \nclass \n▪ Can you tell the TP value from this matrix? \n \n \n \nScenario 1: \nConsider you are watching football world cup. Scenario \n2: \nConsider the earlier example of medical diagnosis of  \nan infected disease. \n \n \nTrue Positive examples \n▪ You had predicted that France would win the world cup, and it won. \n▪ In the earlier activity, the cases in which we predicted yes (they have the disease), and they \ndo have the disease. \n \nTrue Negative \n▪ True Negative (TN) is the outcome of the \nmodel correctly predicting the negative class. \n▪ S"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 72,
    "text": "ince in the previous example, class 1 is assumed \nthe positive class, class 0 should be assumed the \nnegative class. \n▪ Can you tell the TN value from this matrix? \n \n \nTrue Negative examples \n▪ You had predicted that Germany would not win, and it lost \n▪ In the earlier activity, the cases in which we predicted No (they don’t have the disease), \nand they don’t have the disease"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 73,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only. \n \nFalse Positive \n▪ False Positive (FP) is the outcome of the model \nwrongly predicting the negative class as positive class. \n▪ Here, when a class 0 is predicted as class 1, it falls into \nthe FP cell. \n▪ Can you tell the FP value from this matrix? \n \n \n \n \nFalse Positive examples \n▪ You had predicted that Germany would win, but it lost. \n▪ In the earlier activity, the cases in which we predicted Yes (they have the disease), and they \ndon’t have the disease. \n \n \n \n \nFalse Negative \n▪ False Negative (FN) is the outcome of the model  \nwrongly predicting the positive class as the \nnegative class. \n▪ Here, when class 1 is predicted as class 0, it falls \ninto the FN cell. \n▪ Can you tell the FN value from this matrix? \n \n \n \n \nFalse Negative examples \n▪ You had predicted that Fran"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 73,
    "text": "ce would not win but it won \n▪ In the earlier activity, the cases in which we predicted No (they don’t have the disease), \nand they have the disease"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 74,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only. \n \n    Accuracy from Confusion matrix \nClassification accuracy is the number of correct predictions made as a ratio of all predictions made. \n \n \nCalculate the Classification accuracy from this confusion matrix. \n \n \n \n \nCan we use Accuracy all the time? \n▪ It is only suitable when there are an equal number of observations in each class, i.e., a balanced \ndataset (which is rarely the case), and that all predictions and prediction errors are equally \nimportant, which is often not the case. \n▪ But why is that so? Let’s understand it better from the next activity \n \n \nActivity 3: Calculate the accuracy of the classifier model \nDuration: 20 minutes"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 75,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only. \n \n \n \nActivity Guidelines \n▪ Let’s assume you are testing your model on 1000 total test data. \n▪ Out of which the actual values are 900 Yes and only 100 No (Unbalanced dataset). \n▪ Let’s assume that you have built a faulty model which, irrespective of any input, will give a \nprediction as Yes. \n▪ Can you tell the classification accuracy of this model? \nStep 1: Construct the Actual value vs Predicted value table \n \n \nConsider ‘Yes ‘as the positive class and ‘No ‘as the negative class. \nStep 2: Construct the confusion matrix. \nActivity solution: Accuracy from Confusion matrix \nSo, the faulty model will predict all the 1000 input data as Yes. \n \n \n \nConsider ‘Yes ‘ as the positive class and ‘No ‘ as the negative class. \nConstruct the confusion matrix from the Actual vs Predicted t"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 75,
    "text": "able. \n \nPurpose: To design an AI model that predicts whether a student will pass a test (Yes) or not \npass a test (No). \nSay: It classifies the input into two classes Yes and No. Also, calculate the accuracy of the \nclassifier model and construct the confusion matrix for the model."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 76,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only. \n \nTotal predictions \nTotal predictions \n \n \nActivity solution: Accuracy from Confusion matrix \n \nStep 3: Now calculate the accuracy from this matrix. \nClassification accuracy = \nCorrect predictions\n \n=  TP+TN \nTP+TN+FP+FN \n \nStep 4: Converting the accuracy to percentage: = % \nClassification accuracy = \nCorrect predictions\n \n=  TP+TN \nTP+TN+FP+FN  900  \n= = 0.9 \n900+0+100+0 \n \n \nConverting the accuracy to percentage: 0.9x100 % = 90%"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 77,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only. \n \nSo, the faulty model you made is showing an accuracy of 90%. Does this make sense? \n \n \nSo, in cases of unbalanced data, we should use other metrics such as Precision, Recall or F1 score. \nLet’s understand them one by one… \n \n \nPrecision from Confusion matrix \n▪ Precision is the ratio of the total number of correctly \nclassified positive  examples and the total number of \npredicted positive examples. \n▪ Precision = 0.843 means that when our model predicts a \npatient has heart disease, it is correct around 84% of the \ntime. \n \nPrecision: where should we use it? \nThe metrics Precision is generally used for unbalanced datasets when  dealing with the False  \nPositives become important, and the model needs to reduce the FPs as much as possible. \n \n \nPrecision use case example \n▪ F"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 77,
    "text": "or example, take the case of predicting a good day based on weather \nconditions to launch satellite. \n▪ Let’s assume a  day with favorable weather condition is  considered \nPositive class and a day with non -favorable weather condition is \nconsidered as Negative class. \n▪ Missing out on predicting a good weather day is okay (low recall) \nbut predicting the bad weather day (Negative class) as a good weather  \nday (Positive class) to launch the satellite can be disastrous. \n▪ So, in this case, the FPs need to be reduced as much as possible. \n \n \n \n \nPrecision = Correct positive predictions \nTotal positive predictions \n= TP \nTP+FP"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 78,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only. \n \n \nRecall from Confusion matrix \n▪ The recall is the measure of our model correctly identifying True Positives \n▪ Thus, for all the patients who actually have heart disease, recall tells us how many we correctly \nidentified as having a heart disease. Recall  = 0.86 tells us that out of the total patients who \nhave heart disease 86% have been correctly identified. \n \n \nDo you know Recall is also called as Sensitivity or True Positive Rate? \n \n \nRecall: Where we should we use it? \nThe metrics Recall is generally used for unbalanced dataset when dealing with the False \nNegatives become important and the model needs to reduce the FNs as much as possible. \nRecall use case example \nFor example, for a covid-19 prediction classifier, let’s consider \ndetection of a covid-19 affected ca"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 78,
    "text": "se as positive class and detection of \ncovid-19 non-affected case as negative class. \n▪ Imagine if a covid-19 affected person (Positive) is falsely \npredicted as non-affected of Covid -19 (Negative), the person if \nrely solely on the AI would not get any treatment and also may \nend up infecting many other persons. \n▪ So, in this case, the FNs needs to be reduced as much as \npossible. \n▪ Hence, Precision is a go-to metrics for this kind of use case. \n \n \n \n \n \nRecall = Correct positive predictions \nTotal actual positive values \n= TP \nTP+FN"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 79,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only. \n \nF1 Score \n▪ F1-Score provides a way to combine both precisions and recall into a single measure that \ncaptures both properties \n▪ In those use cases, where the dataset is unbalanced, and we are unable to decide whether FP is \nmore important or FN, we should use the F1 score as the suitable metric. \n \n \n \nActivity 4: Decide the appropriate metric to evaluate the AI model \n \nDuration: 30 minutes \n \n \n \n \nScenario: Flagging fraudulent transactions \n• You have designed a model to detect any fraudulent transactions with credit card. \n• You are testing your model with highly unbalanced dataset. \n• What is the metric to be considered in this case? \n▪ It is okay to classify a legit transaction as fraudulent — it can always be re-verified by \npassing through additional checks. \n▪ But"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 79,
    "text": "it is definitely not okay to classify a fraudulent transaction as legit (false negative). \n▪ So here false negatives should be reduced as much as possible. \n▪ Hence in this case, Recall is more important. \n▪ For the given data, construct the confusion matrix. \n▪ Calculate the recall from the confusion matrix. \nF1 Score = 2 x Precision x Recall \nPrecision + Recall \nPurpose: To work with the given scenario and choose the most appropriate evaluation \nmetric to evaluate their model. \nSay: “Different evaluation metrics are used for evaluation in different scenarios and it is \nimportant that we realize how to choose the correct one.”"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 80,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only. \n \n \n \n \nFill the matrix based on the table given above. \n \n \n \n \n \n \n \n \n \nActivity solution: Decide the appropriate metric to evaluate the AI model \n \n \nCalculate the recall from the confusion matrix based on."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 81,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only. \n \n \n \nAre there any ethical concerns we need to keep in mind when performing model evaluation? \n3.2 Ethical concerns around model evaluation \nWhile evaluating an AI model, the following ethical concerns need to be kept in mind \n \n \n \n   Test Yourself  \n \nChoose the most appropriate answer for each question. \n \n \n1. In a medical test for a rare disease, out of 1000 people tested, 50 actually have the disease while  \n950 do not. The test correctly identifies 40 out of the 50 people with the disease as \npositive, but it also wrongly identifies 30 of the healthy individuals as positive. What is the accuracy \nof the test? \nA) 97% \nB) 90% \nC) 85% \nD) 70% \n2. A student solved 90 out of 100 questions correctly in a multiple-choice exam. What is the error rate \nof the student's answers?"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 81,
    "text": "A) 10% \nB) 9% \n \nC) 8% \nWrite the formula for recall: \nCalculate recall from the formula:"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 82,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only. \n \nD) 11% \n3. In a spam email detection system, out of 1000 emails received, 300 are spam. The system correctly \nidentifies 240 spam emails as spam, but it also marks 60 legitimate emails as spam. What is the \nprecision of the system? \nA) 80% \nB) 70% \nC) 75% \nD) 90% \n4. In a binary classification problem, a model predicts 70 instances as positive out of which 50 are \nactually positive. What is the recall of the model? \nA) 50% \nB) 70% \nC) 80% \nD) 100% \n5. In a sentiment analysis task, a model correctly predicts 120 positive sentiments out of 200 positive \ninstances. However, it also incorrectly predicts 40 negative sentiments as positive. What is the F1 \nscore of the model? \nA) 0.8 \nB) 0.75 \nC) 0.72 \nD) 0.82 \n6. A medical diagnostic test is designed to detect a certain disease. O"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 82,
    "text": "ut of 1000 people tested, 100 \nhave the disease, and the test identifies 90 of them correctly. However, it also wrongly identifies 50 \nhealthy people as having the disease. What is the precision of the test? \nA) 90% \nB) 80% \nC) 70% \nD) 60% \n7. A teacher's marks prediction system predicts the marks of a student as 75, but the actual marks \nobtained by the student are 80. What is the absolute error in the prediction? \nA) 5 \nB) 10 \nC) 15 \nD) 20"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 83,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only. \n \n8. The goal when evaluating an AI model is to: \nA) Maximize error and minimize accuracy \nB) Minimize error and maximize accuracy \nC) Focus solely on the number of data points used \nD) Prioritize the complexity of the model \n9. A high F1 score generally suggests: \nA) A significant imbalance between precision and recall \nB) A good balance between precision and recall \nC) A model that only performs well on specific data points \nD) The need for more training data \n10. How is the relationship between model performance and accuracy described? \nA) Inversely proportional \nB) Not related \nC) Directly proportional \nD) Randomly fluctuating \n \n \nReflection Time: \nQ1. What will happen if you deploy an AI model without evaluating it with known test set data? Q2. \nDo you think evaluating an"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 83,
    "text": "AI model is that essential in an AI project cycle? \nQ3. Explain train-test split with an example. \nQ4. “Understanding both error and accuracy is crucial for effectively evaluating and improving AI \nmodels.” Justify this statement. \n \nQ5. What is classification accuracy? Can it be used all times for evaluating AI models? \nAssertion and reasoning-based questions: \n \nQ1. Assertion: Accuracy is an evaluation metric that allows you to measure the total number of predictions a \nmodel gets right. \nReasoning: The accuracy of the model and performance of the model is directly proportional, and \nhence better the performance of the model, the more accurate are the predictions."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 84,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only. \n \nChoose the correct option: \n(a) Both A and R are true and R is the correct explanation for A \n(b) Both A and R are true and R is not the correct explanation for A \n(c) A is True but R is False \n(d) A is false but R is True \nQ2. Assertion: The sum of the values in a confusion matrix's row represents the total number of \ninstances for a given actual class. \nReasoning: This enables the calculation of class-specific metrics such as precision and recall, which \nare essential for evaluating a model's performance across different classes. \nChoose the correct option: \n(a) Both A and R are true and R is the correct explanation for A \n(b) Both A and R are true and R is not the correct explanation for A \n(c) A is True but R is False \n(d) A is false but R is True \n \nCase study-based ques"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 84,
    "text": "tions: \nQ1. Identify which metric (Precision or Recall) is to be used in the following cases and why? \na) Email Spam Detection \nb) Cancer Diagnosis \nc) Legal Cases (Innocent until proven guilty) \nd) Fraud Detection \ne) Safe Content Filtering (like Kids YouTube) \n \nQ2. Examine the following case studies. Draw the confusion matrix and calculate metrics such as \naccuracy, precision, recall, and F1-score for each one of them. \n \na. Case Study 1: \nA spam email detection system is used to classify emails as either spam (1) or not spam (0). Out \nof 1000 emails: \n- True Positives (TP): 150 emails were correctly classified as spam. \n- False Positives (FP): 50 emails were incorrectly classified as spam. \n- True Negatives (TN): 750 emails were correctly classified as not spam. \n- False Negatives (FN): 50 emails were incorrectly classified as not spam. \n-  \nb. Case Study 2: \nA credit scoring model i"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 84,
    "text": "s used to predict whether an applicant is likely to default on a loan \n(1) or not (0). Out of 1000 loan applicants: \n- True Positives (TP): 90 applicants were correctly predicted to default on the loan. \n- False Positives (FP): 40 applicants were incorrectly predicted to default on the loan. \n- True Negatives (TN): 820 applicants were correctly predicted not to default on the loan."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 85,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only. \n \n- False Negatives (FN): 50 applicants were incorrectly predicted not to default on the loan. \nCalculate metrics such as accuracy, precision, recall, and F1-score. \nc. Case Study 3: \nA fraud detection system is used to identify fraudulent transactions (1) from legitimate ones \n(0). Out of 1000 transactions: \n- True Positives (TP): 80 transactions were correctly identified as fraudulent. \n- False Positives (FP): 30 transactions were incorrectly identified as fraudulent. \n- True Negatives (TN): 850 transactions were correctly identified as legitimate. \n- False Negatives (FN): 40 transactions were incorrectly identified as legitimate. \n \nd. Case Study 4: \nA medical diagnosis system is used to classify patients as having a certain disease (1) or not \nhaving it (0). Out of 1000 pat"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 85,
    "text": "ients: \n- True Positives (TP): 120 patients were correctly diagnosed with the disease. \n- False Positives (FP): 20 patients were incorrectly diagnosed with the disease. \n- True Negatives (TN): 800 patients were correctly diagnosed as not having the disease. \n- False Negatives (FN): 60 patients were incorrectly diagnosed as not having the disease. \n \ne. Case Study 5: \nAn inventory management system is used to predict whether a product will be out of stock \n(1) or not (0) in the next month. Out of 1000 products: \n- True Positives (TP): 100 products were correctly predicted to be out of stock. \n- False Positives (FP): 50 products were incorrectly predicted to be out of stock.True Negatives (TN): 800 \nproducts were correctly predicted not to be out of stock. \n- True Negatives (TN): 800 products were correctly predicted not to be out of stock. \n-  \n- False Negatives (FN): 50 products were inc"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 85,
    "text": "orrectly predicted not to be out of stock."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 86,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only. \n \nUNIT 4: Statistical Data \n \n \n4.1: No-Code AI for Statistical Data \n \nLesson Title: No-Code AI for Statistical Data Approach: Session + Activity \nSummary: Understanding the importance and need of No -Code AI for Statistical Data,  \nadvantages, and disadvantages of using No -Code AI for Statistical Data, how to use No- \nCode AI tools for Statistical Data. \n \nLearning Objectives: \n● Understand the meaning of No-Code AI and the need of it. \n \n● Understand the difference between No-Code and Low-Code. \n \n● What are some no-code tools used for the statistical dataset? \n \n● How is the AI project cycle different for No-Code AI? \n \nLearning Outcomes: \n● Define No-Code and Low-Code AI. \n● Identify the differences between Code and No-Code AI concerning Statistical Data. \n● Relate AI pro"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 86,
    "text": "ject stages to the stages of No-Code AI projects. \n \nPre-requisites: Basic knowledge of AI project cycle. \n \nKey-concepts: \n● No code tools for AI projects \n● Understanding different types of approaches like code, low code and No-Code for \nstatistical data. \n● Identifying and recognizing various tools and platforms for low code and No-Code \napproaches"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 87,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only. \n \nData science is a journey of exploration and discovery. A rtificial Intelligence is a technology which  \ncompletely depends on data, which is fed into the machine which makes it intelligent. And depending \nupon the type of data we have; AI can be classified into three broad domains: Data science, Computer \nVision and Natural language processing. \n \nData Sciences is a concept to unify statistics, data analysis, machine learning and their  related \nmethods in order to understand and analyze actual phenomena with data. It employs techniques \nandtheories drawn from many fields within the context of Mathematics, Statistics, Computer Science, \nand Information Science. \n \n \nApplications of Data Science: \n \n \nInternet Search: All the search engines (including Google) make use of data"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 87,
    "text": "science algorithms to  \ndeliver the best result for our searched query in the fraction of a second. Considering the fact that  \nGoogle processes more than 20 petabytes of data every day, had there been no data science, Google \nwouldn’t have been the ‘Google’ we know today. \n \n \n \nTargeted Advertising: If you thought Search would have been \nthe biggest of all data science  applications, here is a  \nchallenger – the entire digital marketing spectrum. Starting  \nfrom the display banners on various websites to the digital  \nbillboards at the airports – almost all of them are decided by \nusing data science algorithms. This is the reason why digital  \nads have been able to get a much higher CTR (Call -Through \nRate) than traditional advertisements. They can be targeted  \nbased on a user’s past behaviour. \n \n \n \nWebsite Recommendations: Aren’t we all used to the suggestions about similar produ"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 87,
    "text": "cts on Amazon? \nThey not only help us find relevant products from billions of products available with them but also add \na lot to the user experience. A lot of companies have fervidly used this engine to \npromote their products in accordance with the user’s interest and relevance of information. Internet  \ngiants like Amazon, Twitter, Google Play, Netflix, LinkedIn, IMDB and many more use this system to  \nimprove the user experience. The recommendations are made based on previous search results for a user."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 88,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only. \n \nGenetics & Genomics: \n \nData Science applications also enable an advanced level \nof treatment personalization through research in  \ngenetics and genomics. Data science techniques allow  \nintegration of different kinds of data with genomic data  \nin disease research, which provides a deeper  \nunderstanding of genetic issues in reactions to particular \ndrugs and diseases. As soon as we acquire  reliable \npersonal genome data, we will achieve a deeper  \nunderstanding of human DNA. The advanced genetic risk \nprediction will be a major step towards more  individual \ncare. \n \n \n \n \n \n \n \nIntroduction to Low/No-Code AI approach for Statistical Data \nLet’s say you want to build a product, food delivery application. How do you go about starting it? \n \n \nBuilding a food delivery applic"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 88,
    "text": "ation involves several steps, from conceptualization to development, \ntesting, and deployment. The 3 most popular approaches to code are given below. \nActivity: Word Scramble the terms related to AI applications. \n \nPurpose: Recall of AI terms \n \nVANAGTOINI APP      \nUALTIRV SSISATANT     \nAGEGUALAN TIONSLATRAN"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 89,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only. \n \n \n \nCustom code is also known as high code. \nHow do we choose? Which of these 3 is the most suitable for our app? \n \nHigh code Low code No code \nHigh code development refers  \nto traditional software  \ndevelopment where  \nprogrammers write code  \nmanually using programming  \nlanguages like Java, Python, C#, \netc. \nLow code development  \ninvolves using platforms or  \ntools that provide visual  \ninterfaces and pre -built \ncomponents to streamline the \napplication development \nprocess. \nNo code development takes  \nlow code principles further by \nallowing users to create  \napplications without any  \ncoding or scripting knowledge. \nA team of software coders \nneed to write all the code \nmanually. \nProgrammers need to write \nsome code manually. \nCoding knowledge is not  \nrequired; h"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 89,
    "text": "ence anyone can \nmake the product. \nIt is expensive. It is less expensive compared \nto high code. \nIt is less expensive compared \nlow code. \nThe company can own the  \nproduct they create. You can  \ncreate anything and customise \nyour product in any way. \nYou can customise your  \nproduct to an extent only using \ncode. \nFor example, custom chatbot. \nLack of customisable options as \nNo-Code AI tools are limited to  \nfunctions in the tool. \nSimple to use as it uses drag- \nand-drop features instead of  \ncoding. \nNow that we have seen the differences, \nwhich approach do you think is the most suitable one for our Food Delivery app? Discuss!"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 90,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only. \n \n \n \n \nCan you think of an invention that has made life easier in terms of saving time/cost for you? \nSome inventions that have made life today easier are smartphones, credit cards, internet, online streaming \nservices, Refrigeration technology, GPS navigation, medical innovations etc. \nSimilar to those inventions, let’s look at how No-Code AI makes our lives easier! \n \n \n \n \n \nMore code to test out different algorithms… And \nmore code to pick the best algorithm… \n \n \n \n \n \n \n \n \nNo-Code \n▪ In No-Code AI, we can drag and drop, these \nmodels in few seconds. \n▪ No coding knowledge is required to implement \ncomplex ML algorithms \n▪ Drag and drop feature of a No -Code tool makes \nit easier. \n \n \n \n \n \n \n \n \n \nThat’s a lot of code, right? \nAnd that’s why we have No - \nCode AI."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 91,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only. \n \nWhy do we need No-Code AI? \n \n▪ We tend to run into many types of errors when we are coding, and it can be very \ntroublesome at times. \n▪ In No-Code AI since we do not need to code, we won’t have any code errors! \n▪ No-Code AI helps to save cost for businesses as it is costly to implement completely \ncoded AI systems. \n▪ Companies can implement AI with less stress and without the need to hire an AI staff \nwith No-Code AI. \n▪ No-Code AI is easy to use – even middle school students can create AI using No-Code \ntools \n▪ Since it has visual & drag-and-drop features, anyone can see what they are building in \nreal-time \n \nWho can use No-Code AI? \n▪ No-Code AI makes AI more accessible to the general public. \n▪ Non-technical people such as doctors, architects, musicians \nmay quickly"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 91,
    "text": "construct accurate AI models with no coding involved. \n \n \nLet’s look at a scenario to understand who can use No-Code AI \n▪ No-Code AI makes AI more accessible to the general public. \n▪ Non-technical people such as doctors, architects, musicians \nmay quickly construct accurate AI models with no coding involved. \nThus No -Code AI  can empower individuals and organizations across various industries and skill  \nlevels to harness the potential of artificial intelligence for their specific needs. \nLet’s look at a scenario to understand who can use No-Code AI. \n \n \n \n \n \n \n \n \n \nProblem: Kayla is a wildlife animal’s dietitian \nmanager at the zoo. She takes care of the cost of \nbuying meat and vegetables for animals. With the \nprices of food increasing rapidly, it will become \nmore expensive for the zoo to buy healthy and \nnutritious foods for its animals. Therefore, the \nzoo’s accounts team wa"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 91,
    "text": "nts to know the increase in \nthe price of food so that they can ask the \ngovernment or sponsors to fund for the food. Thus, \nKayla requires the help of AI to predict the price."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 92,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only. \n \nHowever, Kayla does not know how to code to build an AI model as she has not learnt AI before. \n \n \nSolution: \nShe finds a No-Code AI tool online that can help her build an AI model to predict the prices of meat and \nvegetables without any code! \nKayla can also use any popular No-Code Tool like Orange Data Mining to build a price prediction model. \nWe will look at how to build a simple price prediction model in a short while. From this  scenario you \ncan infer that: You do not need to know coding to build an AI model  and anyone can make use of No-\nCode AI to build an AI model. \n \nBenefits of No-Code Tools \n \n \n \n \nNow that we have discussed the advantages of No-Code tools, let us discuss the disadvantages too… \nDisadvantages of No-Code Tools \nLack of Flexibility \nDrag-and-dr"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 92,
    "text": "op elements can be very convenient. On the other hand, you are limited to those fixed  \nelements. Hence, you have a limitation in customizing your application in no-code platforms, and it  \ndoes not give you all the authority and flexibility you might need."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 93,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only. \n \nAutomation Bias \nAutomation bias is the tendency for humans to favor suggestions from automated decision-making \nsystems and to ignore contradictory information made without automation, even if it is correct. \nSecurity Issues \nNo code platforms do not essentially force you to think of security first or even evaluate security best \npractices. Therefore, these applications are only best suited for companies that don’t deal with  \nsensitive data, as these platforms usually offer limited control over it. \n \nPopular No-Code Tools \nHere are some of the top No-Code AI tools where we can build our AI models in. \n \n \n \nNo-Code tool Details Released \nAzure Machine Learning Cloud-based service provided by Microsoft July 2014 \nGoogle Cloud AutoML Cloud-based service provided by Google Ja"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 93,
    "text": "nuary \n2018 \nOrange Data Mining An open-source data visualization, machine \nlearning and data mining toolkit. \nDeveloper: University of Ljubljana \nOctober 1996 \nLobe AI Lobe AI is a machine learning platform that \nenables to create custom machine learning \nmodels using a visual interface \n2015 \nTeachable Machine Teachable Machine is a web-based tool that \nmakes creating machine learning models fast, \neasy, and accessible to everyone. \nNovember \n2017 \n \n \nAzure Machine Learning \nMicrosoft‘s Azure Machine Learning aims to simplify \nML processes. \n▪ It allows users to build ML models without \nhaving to touch any code, \n▪ and provides an easy interface for cleaning \nup your data, training models, evaluating  \nthem and, finally, putting them into  \nproduction."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 94,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only. \n \n \nGoogle Cloud AutoML \n \n▪ Users with limited ML knowledge  \ncan train high -quality models  \nspecific to their business needs with \nminimal effort. \n▪ They can build their own custom  \nmachine learning model in minutes \nand then use the models in their  \napplications and web sites. \nClick on Introducing Cloud AutoML  \nto watch a video on it. \n \n \n \n \nOrange Data Mining \n \n▪ Orange enables you to visualize data \nand perform data mining and \nmachine learning. \n▪ You can use this tool without \nwriting a single code. \n▪ This platform can be used for  \nanalysis, is relatively easy, and has \nbeautiful visuals."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 95,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only. \n \n \n \n \nNow, let us get back to building a simple prediction model using Orange Data Mining for Kayla! \n \nPurpose: To build an AI model \nto predict price using Orange \nData mining AI tool \nSteps for building a simple \nprice prediction model: \nStep 1: Download the \ndataset from \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nhttps://www.fao.org/worldfoodsituation/foodpricesindex/en/"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 96,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only. \n \nStep 2: Open Orange Data Mining \n▪ Double Click on Orange Icon \n▪ Open the tool \n \n \n \n \n \n \n \n \nStep 3: Upload the Dataset \n▪ Click on the File widget under Data Menu \n▪ File widget will appear on the canvas \n▪ Click on it and browse to the folder to upload the dataset \n▪ Select the target variable as Food Price Index, as we are trying to predict the price \nindex. \n \n \n \nStep 4: View the Dataset \n▪ Click on the Data Table widget under Data Menu \n▪ Data Table widget will appear on the canvas \n▪ Connect File to Data Table"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 97,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only. \n \n▪ Click on Data Table to view the dataset using the tool. \n \n \nStep 5: Select the Model for Prediction \n▪ Click on the Linear Regression widget under Model Menu \n▪ Linear Regression widget will appear on the canvas \n▪ Connect File to Linear Regression \n▪ Linear Regression is an algorithm used for Regression Model \n \n \n \n \nStep 6: Evaluate the Model \n▪ Click on the Test and Score widget under Evaluate Menu \n▪ Test and Score widget will appear on the canvas \n▪ Connect File and Linear Regression to Test and Score to check the performance \nparameters. \n▪ Click on Test and Score to view the parameters."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 98,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only. \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nStep 7:  Model Prediction \n▪ Click on the Prediction widget under Evaluate Menu \n▪ Prediction widget will appear on the canvas \n▪ Connect the Test and Score to the Prediction to check the prediction made by \nLogistic Regression Model. \n▪ Click on Prediction to view the price prediction. \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nKayla could use such a model to make the price prediction for animal feed and make a systematic \nfund-raising plan for the Zoo."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 99,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only. \n \nOther No code AI tools \nLobe \n \n \n \nTeachable Machine \n \n \n \n▪ Machine Learning has been made easy using Lobe. \n▪ It has everything that you need to bring your machine-learning \nideas to life. \n▪ Lobe helps you, train models with a free and easy-to-use tool. \n▪ It automatically trains a custom machine-learning model that \ncan be shipped in your app. \n \n \n \n \n▪ Teachable Machine is a web -based tool that  \nmakes creating machine learning models fast, easy and \naccessible to everyone. \n▪ It can be used to train a computer to recognize \nyour own images, sounds and poses. \n▪ No specific expertise or coding is required to use \nthis tool. \n \n \n \n \n \n \nTest Yourself: \n1. Orange data mining is an example of \na) Custom coding                               c) No code \nb) Low code"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 99,
    "text": "d) None of these. \n2. Select Which is not the feature of No code approach. \na) visual                                    c) code free \nb) Highly expensive     d) drag and drop \n3.    assembly relies on developers to write and deploy code. \na) High code                                       c) No code \nb) Low code     d) None of these  \nc) 4.Flexibility is often limited in"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 100,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only. \n \na) High code                                     c) No code \nb) High code and Low code    d) High code and No code. \n5. The organisation is heavily dependent on developer resources. This statement is true for \na) High code approach                   c) No code approach \nb) Low code approach   d) All of the above. \n \n \nAnswer the following briefly: \n1. Name any two-cloud based No-code AI tools? \n2. How accessible are no-code AI tools for non-technical users? \n3. What types of tasks can be accomplished with no-code AI tools? \n4. Can no-code AI tools be used for advanced projects? Justify. \n5. Do no-code AI tools require prior programming knowledge? Justify. \n \n \nAnswer the following in detail: \n1. What are the benefits of using No-code AI tools? \n2. What are the challenges face"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 100,
    "text": "d in using the No-code AI tools? \n3. Differentiate low code and No-code AI tools with examples. \n4. As the CEO of a small e-commerce startup, you're eager to leverage artificial intelligence  to \nenhance your platform's user experience and drive sales. However, your team lacks the  \ntechnical expertise to develop and deploy AI -powered solutions. What would be your  \nrecommendations for the CEO? \n5. Samarth attended a seminar on Artificial Intelligence and has now been asked to write a report \non his learnings from the seminar. Being a non -technical person, he understood that  the AI \nenabled machine uses data of different formats in many of the daily based applications  but \nfailed to sync it with the right terminologies and express the details. Help Samarth define  \nArtificial Intelligence, list the three domains of AI and the data that is used in these domains. \n \nReflection Time:"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 100,
    "text": "1. Would you like to explore the tools specified here to build No-Code AI projects? How? \n2. Are you aware of any other tools or platforms used for low code or No-Code AI Projects? List them."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 101,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only. \n \n4.2: Statistical Data: Use Case Walkthrough \n \nLesson Title: Statistical Data: Use Case Walkthrough  \nApproach: Session + Activity \nSummary: Introduction to a No-code AI tool for Statistical Data (Orange Data mining tool)  \nthrough some practical use cases. Mapping AI Project cycle with use cases and perform data \nexploration, modelling and evaluation with Orange data mining. \n \nLearning Objectives: \n● Understand what is Orange Data Mining? What are its features? \n \n● To perform Data Acquisition, Data Exploration, and Modelling on a No-Code tool. \n \n● How to map the AI project cycle to develop an AI solution with a No-Code tool. \n \n● Build the AI project using no code tool Orange Data Mining. \n \nLearning Outcomes: \n● Learner will be able to use no-code tool Orange Data mining"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 101,
    "text": ". \n \n● Learner will be able to map AI Project cycle with use cases. \n \n● Learner will be able to perform data exploration, modelling and evaluation with \nOrange data mining. \n \nPre-requisites: Basic knowledge of AI project cycle. \n \nKey-concepts: \n● Orange Data Mining is a machine learning tool for data analysis where we can \nperform operations through simple drag-and-drop steps. \n● A sample of the entire population is taken to perform computations. \n● Descriptive statistics – Mean, Median, Mode – help us to describe the data and its \nunderlying characteristics. \n● Distributions display the frequency of each value that appears in a data set. \n● Probability is the likelihood of an event occurring. \n● Variance measures how far each value in the data set is from the mean."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 102,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only. \n \n \nBefore we start with Orange data mining, let’s discuss some important concepts of Statistical Analysis \n \nImportant concepts in statistics \nStatistical sampling \n▪ The entire set of raw data that you may  \nhave available for a test or experiment is \nknown as the population. \n▪ You cannot necessarily measure the  \npatterns and trends across the entire \npopulation. \n▪ Take a sample, or portion of the  \npopulation, perform some computations. \n \n \n \n \nDescriptive statistics \n▪ Helps us to describe the data and  \nenables us to understand the underlying \ncharacteristics. \n▪ Mean — the central value, commonly \ncalled the average. \n▪ Median — the middle value if we ordered \nthe data from low to high and divided it  \nexactly in half. \n▪ Mode – the value which occurs most often. \n \nD"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 102,
    "text": "istributions"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 103,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only. \n \n▪ These are charts or graphs that display the frequency of each value that appears in a data set. \n▪ Some distributions contain some numbers much larger than others, causing the distributions \nto become skewed. \n▪ Normal distribution – A distribution that is symmetrical in shape with most values around the \ncentral peak. \nProbability \n▪ In simple terms, is the likelihood of an event occurring. \n▪ An event is the outcome of an experiment. \n▪ Events can be either independent or dependent. \nVariance \n▪ Variance measures how far each \nvalue in the data set is from the  \nmean (a measurement of the  \nspread of numbers in a data set) \n▪ Standard deviation – a calculation \nthat gives a value to represent  \nhow widely distributed the values \nare. \n▪ Outlier – A data point that lies at"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 103,
    "text": "an abnormal distance from other \nvalues. \n \n \n \n \n \n \n \n \n \n \n \n \n \nActivity: Mind map making \nPurpose: Reinforce the need of Descriptive statistics \n  \nSay: Use any mind map tool offline/online to  Craft a mind map in detailing the various   \ncontexts where mean, mode, and median are applied in real life."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 104,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only. \n \nMS Excel for Statistical Data \n \n \n           Activity template-MS Excel for Statistical Analysis: https://bit.ly/43SIq6K \nLong Link:  https://docs.google.com/spreadsheets/d/1f5G-\nJXyP7EV2fy1hax47YVaH5gyq8KZy/edit?usp=drive_link&ouid=109928090180926267402&rtpof=true&sd\n=true  \n \n \nGuidelines to Activity: \nUse the Activity template Link to access the file:   \nStep 1: Get the Add-in \n▪ Go to File \n▪ Click on Options \n▪ Click on Add-ins \n▪ Click on Analysis Tool Pak under Inactive Application Add-ins \n▪ In the bottom, you will find Manage-> Select Excel Add-ins-> Click on Go \n▪ Click Ok \n▪ Add-in pop-up window will appear \n▪ Check on Analysis Tool Pak (Put a tick) \n▪ Click on Ok \n▪ Once all the steps have been performed successfully, the Data Analysis option will appear \ninside"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 104,
    "text": "Data Menu \nStep 2: View the Speed Vs Distance Data available in the excel sheet \n▪ Identify the Independent and Dependent Features – X and Y \n \nStep 3: Visualize the Data using Scatter Plot \n▪ Select both columns- Speed and Distance \nActivity: Excel for Statistical Analysis \nPurpose: To use Excel tool for Simple linear regression of cars speed and distance \nSay: Download the template and follow the instructions"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 105,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only. \n \n▪ Go to Insert -> Charts -> Scatter \n▪ Scatter Plot will appear \n▪ Go to Chart Elements -> Edit Chart Title -> Distance Versus Speed \nStep 4: Plot the Regression Line \n▪ Click on the Scatter Plot \n▪ Click on Chart Design \n▪ Add Chart Element \n▪ Go to Trendline \n▪ Click on More Trendline Options \n▪ Click on Linear \n▪ Put a tick on \n▪ Display Equation on chart \n▪ Display R-squared value on chart \nStep 5: Verify the Linear Regression equation coefficients \n▪ Click on Data \n▪ Click on Data Analysis \n▪ Data Analysis option window will pop-up \n▪ Choose Regression \n▪ Click on Ok \n▪ Regression window will appear \n▪ Select Y Range -> Select the Distance column data along with column name Distance \n▪ Select X Range -> Select the Speed column data along with column name Speed \n▪ Put a t"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 105,
    "text": "ick on the check box for Labels as we have selected the column  data along with \ncolumn names \n▪ Select output range and click on any cell where you want the output to be displayed \n▪ Summary output for regression statistics will appear on the sheet \nStep 6: Find the distance using the generated linear equation as per y = mx + c \n▪ For the value of Speed(X) = 6, What will be the distance covered by the vehicle?"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 106,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only. \n \nOrange Data Mining \nWhat is Orange Data Mining (ODM)? \n▪ A machine learning tool for  \ndata analysis through Python \nand visual programming \n▪ We can perform operations \non data through simple  \ndrag and drop steps. \n▪ Orange enables you to visualize data and perform \ndata mining and machine learning. \n▪ You can use this tool without writing a single code. \n▪ This platform can be used for analysis, is relatively easy, and has beautiful visuals. \n \n \nOrange Data Mining: \nOrange is an open-source data mining and machine learning software suite designed for data analysis, \nvisualization, and exploration. It offers a graphical user interface (GUI) that allows users to interactively \nbuild data analysis workflows using various components called widgets. Each widget \nserves a speci"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 106,
    "text": "fic purpose in the data analysis process. Here's a brief description of some commonly \nused Orange data mining widgets. \n \n \nData Loading Widgets: These widgets help you bring your data into Orange from files or online \nsources. \nFile: Allows you to load data from files in various formats such as CSV, Excel, and SQL. URL: \nLoads data from a URL. \nData Table: Displays loaded data in a tabular format. \nData Exploration Widgets: These widgets allow you to look at your data in different ways, like scatter \nplots or histograms, to see patterns or trends. \nScatter Plot: Visualizes the relationship between two variables in the data. \nData Table: Allows for manual inspection and exploration of data. \nDistributions: Displays histograms and other statistical distributions of variables. \n \n \nPreprocessing Widgets: These widgets help you clean up your data, like filling in missing values or making"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 106,
    "text": "sure all your data is on the same scale. \nImpute: Handles missing values in the dataset. Normalize: Normalizes the data to a common scale. \nSelect Columns: Allows you to select specific columns from the dataset."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 107,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only. \n \nFeature Selection  Widgets: These widgets help you choose which parts of your data are most \nimportant for your analysis. \nSelect Columns: Allows you to choose relevant columns/features from the dataset. \nSelect Best Features: Automatically selects the best features based on certain criteria like mutual \ninformation or correlation. \n \nModelling Widgets: These widgets build models from your data, like decision trees or \nclustering algorithms, to help you understand it better. \nClassification Tree: Constructs a decision tree classifier. \nk-Means: Performs k-means clustering on the data. \nSupport Vector Machine: Trains a support vector machine classifier. \nLogistic Regression: Constructs a logistic regression model. \n \nEvaluation Widgets: These widgets help you see how well your"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 107,
    "text": "models are performing, so you can make \nadjustments if needed. \nTest & Score: Evaluates the performance of a predictive model on a test dataset. \nCross Validation: Performs cross-validation to assess model performance. \nROC Curve: Plots the receiver operating characteristic curve for binary classifiers. \n \nVisualization Widgets: These widgets help you turn your data into visual representations, like charts or \ngraphs, to make it easier to understand. \nBar Chart: Displays data in a bar chart format. \nHeat Map: Visualizes data using a heatmap. \nScatter Plot: Visualizes the relationship between two variables. \n \nThese are just a few examples of the wide range of widgets available in Orange. Users can combine \nthese widgets to create custom workflows for tasks such as data preprocessing, modelling, evaluation, \nand visualization, making it a powerful tool for data analysis and mining tasks."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 108,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only. \n \n \n \nWhen you open Orange you will see a welcome screen. We can start a new project here or open a \nproject that has already been made. We can explore."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 109,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only. \n \n \n               \n              Orange comes with a lot of widgets to work with. \nFile widget, lets us load a file into our Workspace/canvas."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 110,
    "text": "* Images shown here are the property of individual organisations and are used here for reference purpose only. \n \n \nData Table widget, lets us observe what the data in the file looks like. Let’s drag these two into our \nblank canvas (can also be done by clicking the widget)"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 112,
    "text": "Recall the AI Project Cycle"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 113,
    "text": "Let’s understand how we can apply the AI Project Cycle in Orange Data Mining."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 114,
    "text": "Thus, all the stages of AI project cycle can be mapped in Orange data mining tool. \n \n \n \nCASE STUDY: \nPalmer Penguins: Palmer Penguins are a species of penguin found in the Antarctic Peninsula region.  \nStudies about penguins, including Palmer Penguins, often focus on their behaviour, habitat,  \npopulation dynamics, and the effects of climate change on their ecosystems. Palmer Penguins dataset \ncan be accessed from https://www.kaggle.com/code/parulpandey/penguin-dataset-the-new-iris/data"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 115,
    "text": "The above image shows the index of this case study. \nScan the QR code for all files of PALMER PENGUINS. \nShort link: https://bit.ly/4atlCN7 \nLong Link : https://drive.google.com/drive/folders/1fmcRVb-ilTyUhmUv4DWT1BFsaCoQ2BmF?usp=drive_link"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 116,
    "text": "Problem scoping \n \n \n \nThe researchers want to predict the species of Palmer Penguins based on the \ncollected data. Can you help them? How? \nLet us look at the dataset! \nLook out for any differences in the physical features of the penguins!"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 118,
    "text": "Let’s teach an AI model to predict the penguin species in Orange Data Mining now! \nBased on features like their sizes, how long their beaks are, and the colors of their feathers. Now, you want \nto figure out which species of penguin is which. ODM is a smart tool that can analyze all the penguin data \nyou collected and learn to recognize patterns. \n \nThe link for steps creating the AI model can be accessed in the file  \nOrange data mining.pdf \n \n \n \n \nReflection \nAre there any limitations of using No-Code AI tools? Share your thoughts with the class?"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 119,
    "text": "Test Yourself: \n \n1. What type of tool is Orange? \na) Open-source b) Closed-source \nc) Paid software d) Hardware \n2. Which of the following tasks can be performed using Orange? \na) Classification b) Regression \nc) Clustering d) All of the above \n3. What type of data can be imported into Orange? \na) CSV b) Excel \nc) SQL databases d) All of the above \n4. What does the Data Table widget in Orange primarily facilitate? \na) Loading and viewing datasets b) Performing clustering analysis \nc) Running machine learning algorithms d) Evaluating \n \n5. Which component in Orange enables users to evaluate the performance of machine learning \nmodels? \n \na) Test & Score b) Data Table \n \nc) Data Projection d) Data Exploration \nReflection Time: \n1. Define No-Code and Low-Code AI. \n2. Identify the differences between Code and No-Code AI concerning Statistical Data. \n3. Relate AI project stages to the stages"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 119,
    "text": "of No-Code AI projects. \n4. Orange Data Mining is a machine learning tool for data analysis where we can perform \noperations through simple drag-and-drop steps. \n5. Descriptive statistics – Mean, Median, Mode – help us to describe the data and its underlying \ncharacteristics. \n6. No code tools for AI projects."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 120,
    "text": "Bibliography \n1. High Code vs. Low Code vs. No Code: Why Choose Just One? | Acquia. (n.d.). Retrieved \nSeptember 29, 2022, from https://www.acquia.com/blog/high-code-vs-low-code-vs-no- code-\nwhy-choose-just-one \n \n \n2. Mapping the No-Code AI landscape. (n.d.). Retrieved September 29, 2022, from \nhttps://levity.ai/blog/no-code-ai-map \n \n \n3. Penguin keeper Zuzana Boumrah celebrates London Zoo’s reopening on 2 December (c)ZSL \nwebsite.jpg (660×370). (n.d.). Retrieved September 29, 2022, \nfrom https://www.zsl.org/sites/default/files/styles/wysiwyg/public/image/2020 - \n12/Penguin%20keeper%20Zuzana%20Boumrah%20celebrates%20London%20Zoo%27s%2  \n0reopening%20on%202%20December%20%28c%29ZSL% 20website.jpg?itok=XwLZoEko \n \n \n4. Top 12 Benefits of No-Code App Development | Ǫuixy. (n.d.). Retrieved September 29, 2022, from \nhttps://quixy.com/blog/top-benefits-of-no-code-app-development/ \n \n \n5. Top"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 120,
    "text": "12 ‘No-Code’ Machine Learning Platforms In 2021. (n.d.). Retrieved September 29, 2022, \nFrom https://analyticsindiamag.com/top-12-no-code-machine-learning-platforms-in-2021/ \n \n \n6. Understand Text Mining Using No Code Tool Orange - Analytics Vidhya. (n.d.). Retrieved September \n29, 2022, from  https://www.analyticsvidhya.com/blog/2022/05/understand -text- mining-using-no-\ncode-tool-orange/ \n \n \n7. What is No Code AI? Importance and Benefits | Analytics Steps. (n.d.). Retrieved September 29, \n2022, from https://www.analyticssteps.com/blogs/what -no-code-ai-importance-and- benefits \n \n \n8. Penguin dataset: The new Iris. (n.d.). Kaggle.com. Retrieved July 8, 2022, from \nhttps://www.kaggle.com/code/parulpandey/penguin-dataset-the-new-iris/data"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 121,
    "text": "Unit 5: Computer Vision \n \n \nTitle: Computer Vision Approach: Practical Implementation \nSummary: Computer Vision is a branch of artificial intelligence that enables machines to  \ninterpret and understand visual information from the real world. This unit provides an in-depth \nexploration of various methodologies, and applications in computer vision, equipping students \nwith the skills necessary to analyze and process visual data. \nObjectives: \n1. To introduce students to the basic principles and techniques of computer vision. \n2. To familiarize students with common algorithms and tools used in image \nprocessing and analysis. \n3. To enable students to apply computer vision techniques to solve real-world \nproblems. \n4. To foster critical thinking and problem-solving skills in the domain of computer \nvision. \nLearning Outcomes: \n1. Understand the fundamental concepts and theories underlying"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 121,
    "text": "computer vision. \n2. Implement basic and advanced image processing techniques using \nprogramming languages such as Python. \n3. Apply computer vision techniques to tasks such as object detection, image \nsegmentation, and feature extraction. \n4. Develop ideas to solve real-world problems leveraging computer vision technologies. \nPre-requisites: Essential understanding of Artificial Intelligence \nKey-concepts: Image processing, feature extraction, object detection & recognition. \n \n5.1: Introduction \nIn the previous chapter, you studied the concepts of Artificial Intelligence for Data Sciences. It \nis a concept to unify statistics, data analysis, machine learning and their related methods to \nunderstand and analyse actual phenomena with data. \nAs we all know, artificial intelligence is a technique that enables computers to m1m1c human \nintelligence. As humans, we can see things, analyse the"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 121,
    "text": "m and then do the required action \nbased on what we see. \nBut can machines do the same? Can machines have the eyes that humans have? If you \nanswered yes, then you are right. The Computer Vision domain of Artificial Intelligence, enables \nmachines to see• through images or visual data, process and analyse them on the basis of \nalgorithms and methods to analyse actual phenomena with images. \nNow before we get into the concepts of Computer Vision, let us experience this domain with \nthe help of the following game:"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 122,
    "text": "* Emoji Scavenger Hunt: https://emojiscavengerhunt.withgoogle.com/ \n \n \nGo to the link and try to play the game Emoji Scavenger Hunt. The challenge here is to find 8 items \nwithin the time limit to pass. Did you manage to win? \n            What was the strategy that you applied to win this game? \n            Was the computer able to identify all the items you brought in front of it? \n            Did the lighting of the room affect the identifying of items by the machine? \n       \n         A Quick Overview of Computer Vision! \nComputer vision is the process of extraction of information from images, text, videos, etc. \nA system that can process, analyze and make sense of visual data in the same way as humans do. \n \n \nElephant \nHuman Vision System \n \n \nBrain \n \n \n \nEye \nSensing \nDevice \nInterpreting Device"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 123,
    "text": "Computer Vision and Artificial Intelligence \nComputer vision is a field of artificial intelligence (AI). \nAI enables computers to think, and computer vision enables AI to see, observe and make sense \nof visual data (like images & videos). \n \nComputer Vision Vs. Image Processing \nComputer Vision Image Processing \n• Computer vision deals with extracting  \ninformation from the input images or \nvideos to infer meaningful information and  \nunderstanding them to predict the visual \ninput \n• Computer Vision is a superset of \nImage Processing. \n• Examples - Object detection, \nHandwriting recognition, etc. \n• Image processing is mainly focused on  \nprocessing the raw input images to \nenhance them or preparing them to do \nother tasks \n• Image Processing is a subset of \nComputer Vision. \n• Examples - Rescaling image, Correcting \nbrightness, Changing tones, etc. \n \n5.1 Applications of Computer Visio"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 123,
    "text": "n \nThe concept of computer vision was first introduced in the 1970s. All these new \napplications of  computer vision excited everyone. Having said that, computer vision \ntechnology advanced enough to  make these applications available to everyone at ease \ntoday. However, in recent years the world witnessed a significant leap in technology that \nhas put  computer vision on the priority list of many  industries. Let us look at some of \nthem: \n \n \n \n \n \n \n \n \n \nArtificial Intelligence \nComputer \nVision \nDeep \nLearnin\ng \nMachine \nLearning \nFacial Recognition* : With the advent of smart cities and \nsmart homes, Computer Vision plays a vital role in making the \nhome smarter. Security being the most important application \ninvolves the use of Computer Vision for facial recognition. It \ncan be either guest recognition or log  maintenance of the \nvisitors. It  also finds its application in schools"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 123,
    "text": "for an \nattendance system based on facial recognition of students."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 124,
    "text": "Face Filters*: Modern-day apps like lnstagram and Snapchat \nhave a lot of features based on the  \nusage of computer vision. The application of face filters is one \namong them. Through the  camera, the machine or  the \nalgorithm is able to identify the facial dynamics of the person \nand applies the facial filter selected. \n \nGoogle's Search by  Image*: The maximum \namount of searching for data on Google's search \nengine comes from textual data, but at the same \ntime it has an interesting feature of getting \nsearch results through an  image. This uses \nComputer Vision as it compares different \nfeatures of the input image to the database of  \nimages and gives us the search result while at the \nsame time analysing various features  of the \nimage. \n \nComputer Vision in Retail*: The retail field has been one \nof the fastest-growing fields and at the same time is using \nComputer Vision for maki"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 124,
    "text": "ng the user experience more \nfruitful. Retailers can  use Computer Vision techniques to \ntrack customers' movements  through stores, analyse \nnavigational routes and detect walking  patterns. \n \n \n \nInventory Management is another such application. \nThrough security camera image analysis, a Computer \nVision algorithm can generate a very accurate estimate of \nthe items available in the  store. Also, it can analyse the \nuse of shelf space to identify suboptimal configurations  \nand suggest better item placement. \n \n \n \nSelf-Driving Cars: Computer Vision is the \nfundamental technology behind the \ndevelopment of autonomous vehicles. Most \nleading car manufacturers in the world  are \nreaping the benefits of investing in artificial \nintelligence for developing on -road versions of \nhands-free technology. This involves the process \nof identifying the objects, getting navigational \nroutes and al"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 124,
    "text": "so at the same time  environment \nmonitoring."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 125,
    "text": "Medical Imaging*: For the last decades, \ncomputer supported medical imaging \napplication has been a  trustworthy help for \nphysicians. It doesn't only create  and analyse \nimages, but also becomes an assistant  and \nhelps doctors with their interpretation. The \napplication is used to read and convert 20 scan \nimages into interactive 30 models that enable \nmedical professionals to gain a detailed \nunderstanding of a patient's health condition.   \n \n \n \n \nGoogle Translate App*: All you need to do to read signs in a \nforeign language is to point your phone's camera at the \nwords and  let the Google Translate app tell you what it \nmeans in your preferred language almost instantly. By using \noptical character recognition to  see the image and \naugmented reality to overlay an accurate translation, this is \na convenient tool that uses Computer Vision \n \n \n \n \n \n5.2 Computer Vision Tasks \n \nThe"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 125,
    "text": "various applications of Computer Vision are based on a certain number of tasks that are \nperformed to get certain information from the input image which can be directly used for \nprediction or forms the base for further analysis. The tasks used in a computer vision application are: \n \n \n \n \n \nObjects \n \nObjects \nDetection"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 126,
    "text": "Classification \n \nThe image Classification problem is the task of assigning an input image one label from a fixed \nset of categories. This is one of the core problems in CV that, despite its simplicity, has a large \nvariety of practical applications. \n \nClassification+ Localisation \n \nThis is the task that involves both processes of identifying what object is present in the image \nand at the same time identifying at what location that object is present in that image. It is \nused only for single objects. \n \nObject Detection \n \nObject detection is the process of finding instances of real-world objects such  as faces, \nbicycles, and buildings in images or videos. Object detection algorithms typically use \nextracted features and learning algorithms to recognize instances of an object category. It is \ncommonly used in applications  such as image  retrieval and automated  vehicle parking \nsyst"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 126,
    "text": "ems. \n \nInstance Segmentation \n \nInstance Segmentation is the process of detecting  instances of the objects, giving them a \ncategory, and then giving each pixel a label based on that. A segmentation algorithm takes an \nimage as input and outputs a collection of regions (or segments)."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 127,
    "text": "Basics of Images \n \nWe all see a lot of images around us and use them daily either through our mobile phones or \ncomputer system. But do we ask some basic questions to ourselves while we use them on \nregular basis? \n \n \nDon't know the answer yet? Don't worry, in this section, we will study the basics of an image: \n \nBasics of Pixels \n \nThe word \"pixel\" means a picture element. Every photograph, in digital form, is made \nup of pixels. They are the smallest unit of information that make up a picture. Usually \nround or square, they are typically arranged in a 2-dimensional grid. \nIn the image below, one portion has been magnified many times over so that you can see \nits composition in pixels. As you can see, the  pixels approximate the actual image. The \nmore pixels you have, the more closely the image resembles the original."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 128,
    "text": "Resolution \nThe number of pixels in an image is sometimes called the resolution. When the term is used to \ndescribe pixel count, one convention is to express resolution as the width by the height, for \nexample, a monitor resolution of 1280x1024. This means there are 1280 pixels from one side \nto the other, and 1024 from top to bottom. \nAnother convention is to express the number of pixels as a single number, like a 5 mega pixel \ncamera (a megapixel is a million pixels) . This means the pixels along the width multiplied by \nthe pixels along  the height of the image taken by the camera equals 5 million pixels. In the \ncase of our 1280x1024 monitors, it could also be expressed as 1280 x 1024 = 1,310,720, or 1.31 \nmega pixels. \n \nPixel value \n \nEach of the pixels that represent an image stored inside a computer has a pixel value that \ndescribes how bright that pixel is, and/or what colour it"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 128,
    "text": "should be. The most common pixel \nformat is the byte image, where this number is stored as an 8 -bit integer giving  a range of \npossible values from Oto  255.Typically, zero is to be taken as no colour or black and 255 is  \ntaken to be full colour or white. Why do we have a value of 255?  \nIn computer systems, computer data is in the form of ones and zeros,  \nwhich we call the binary system. Each bit in a computer system can  \nhave either a zero or a one. Since each pixel uses 1 byte of an image, \nwhich is equivalent to 8 bits of data. Since each bit can have  two  \npossible values which tell us that the 8 bits can have 255  \npossibilities of values that starts from 0 and ends at 255. \n \n \n \n \n \n \nGrayscale Images \nGrayscale images are images that have a range of shades of gray without apparent colour. The \ndarkest possible shade is black, which is the total absence of colour or zero v"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 128,
    "text": "alue of pixel. The \nlightest possible shade is white, which is the total presence of colour or 255 value of a \npixel. Intermediate shades of gray are represented by equal brightness levels of the three \nprimary colours. \nA grayscale has each pixel of size 1 byte having a single plane of 2d array of pixels. The size of \na grayscale image is defined as the Height x Width of that image. \nLet us look at an image to understand grayscale images. \nHere ^, represents exponent \n(2 raised to the power 8)"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 129,
    "text": "Here is an example of a grayscale image. As you check, the value of pixels is within the \nrange of 0 -255. The computers store the images we see in the form \nof these numbers. \n \nRGB Images \n \nAll the images that we see around us are coloured images. These images are \nmade up  of three primary colours Red, Green, and Blue.  \nAll the colours that are present can   be made by combining different  \nintensities of red, green, and blue. \n \n \n \nLet us experience! \n \nGo to this online link https://www.w3schools.com/colors/colors_rgb.asp.  On the basis of \nthis online tool, try and answer all the below mentioned questions. \n \n \n \n \n \n1) What is the output colour when you put R=G=B=255? \n \n \n \n2) What is the output colour when you put R=G=B=0? \n \n \n3) How does the colour vary when you put either of the three as 0 and then keep on varying the other \ntwo?"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 130,
    "text": "4) How does the output colour change when all the three colours are varied in same proportion? \n \n \n \n \n \n \n5) What is the RGB value of your favourite colour from the colour palette? \n \n \n \n \nWere you able to answer all the questions? If yes, then you would have understood how \nevery colour we see around is made. \nNow the question arises, how do computers store RGB images? Every RGB image is stored \nin the form of three different channels called the R channel, G channel, and the B channel. \nEach plane separately has many pixels with each pixel value varying from Oto 255. All the \nthree planes when combined form a colour  image. This means that in an RGB image, each \npixel has a set of three different values which together give colour to that particular pixel. \n \nFor Example, \n \n \n \n \n \n \n \nAs you can see, each colour  image is stored in the form of three different channels, each \nhaving"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 130,
    "text": "different intensity. All three channels combine to form a colour we see. \n \nIn the above given image, if we split the image into three different channels, namely Red (R), Green \n{G) and Blue (B), the individual  layers will have the following intensity of colours of the \nindividual pixels. These individual layers when stored in the memory looks like the image on \nthe extreme right . The images look in the grayscale image because each pixel has a value \nintensity of O to 255 and as  studied earlier, 0 is considered as black or no presence of colour \nand 255 means white or full presence  of colour. These three individual RGB values when \ncombined form the colour of each pixel. \nTherefore, each pixel in the RGB image has three values to form the complete colour."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 131,
    "text": "Task: \nGo to the following link www.piskelapp.com and create your pixel art. Try and make a GIF \nusing the online app for your pixel art. \n \n5.3 No-Code AI Tools: \nIntroduction to Lobe \n• Lobe.ai is an Auto-ML tool, which means that it is a no-code AI tool \n• It works with image classification and allows a set of images with labels and will \nautomatically find the most optimal model to classify the images \n \n            Introduction to Teachable Machine \n• Teachable Machine is an AI, Machine Learning, and Deep Learning tool that was \ndeveloped by Google in 2017 \n• It runs on top of tensorflow.js which was also developed by the same company \n• It is a web-based tool that allows training of a model based on different images, audio, \nor poses given as input through webcam or pictures \n \n                 \n \n \nActivity Time: Build a Smart Sorter \nPurpose: Using CV is to automate and enhance s"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 131,
    "text": "orting processes through computer \nvision technology."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 132,
    "text": "• Form groups of 4 members \n• Find images of Bottles, Cans and Paper online or from around. \n• Visit the No-code AI tool \n• Ensure to build 3 different classes [ Bottles, Cans and Paper]. \n• Train the model \n• Finally, test the classifier! \n \n \n \nOrange Data Mining Tool: \n \nLet’s work on a real-world Classification Model: Coral Bleaching (Use Case Walkthrough) \n \nWhat Are Coral Reefs? \n▪ Coral can be found in tropical ocean waters around the world. \n▪ Coral reefs are large underwater structures composed of the skeletons of marine  \ninvertebrates called coral. \n▪ Corals are an integral part of aquatic life. \n \n \n \n \n \n \n \n \n \nActivity Time: Build a classification model \nPurpose: Developing a classification model for early identification of coral bleaching to \nsafeguard marine ecosystems."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 133,
    "text": "What causes Coral Bleaching? \n \n \n \n \n \n \n \nUse Case Walkthrough - Steps involved in project development & required \ndataset can be checked using the links and QR code given below: \n \nShort link: https://bit.ly/orange_computer_vision \nLong Link: https://drive.google.com/drive/folders/1ppJ4d- \n8yOFJ2G22rHHpjNrK0ejdIAe5Q?usp=sharing \nor scan the QR code below \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nCoral bleaching has caused unbalanced scenarios in aquatic life. So, detecting bleached \ncorals at early stages prevents aquatic life from disaster"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 134,
    "text": "5.4 Image Features \nIn computer vision and image processing, a feature is a piece of information that is relevant \nfor solving the computational task related to a certain application. Features may be \nspecific structures in the image such as points, edges, or objects. \n \nFor example: \nImagine that your security camera is capturing an image. At the top of the image, we are given \nsix small patches of images. Our task is to find the exact location of those image patches in \nthe image. \nTake a pencil and mark the exact location of those patches in the image. \n \n \nWere you able to find the exact location of all the patches? \n \n \n \nWhich one was the most difficult to find? \n \n \n \n \nWhich one was the easiest to find? \n \n \n \n \nLet's Reflect: \nLet us take individual patches into account at once and then check the exact location of those \npatches. For Patch A and B: The patch A and Bare flat surf"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 134,
    "text": "aces in the image and are spread \nover a lot of area. They can be present at any location in a given area in the image. \nFor Patch C and D: The patches C and D are simpler as compared to  A and B. They are edges \nof a building and we can find an approximate location of these patches but finding the"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 135,
    "text": "exact location is still difficult. This is because the pattern is the same everywhere along \nthe edge. \nFor Patch E and F: The patches E and Fare the easiest to find in the image. The reason is that \nE and F are some corners of the building. This is because at the corners, wherever we \nmove this patch it will look different. \n \nConclusion \nIn image processing, we can get a lot  of  features from the image. It can be either a blob, \nan edge, or  a corner. These features help us to  perform various tasks and then get the \nanalysis done based on  the application. Now the question that arises is which of the \nfollowing are good features to  be used? As you saw in the previous activity, the features \nhaving the corners are easy to find as they can be  found only at a particular location in \nthe image, whereas the edges are spread over a line or an edge  look the same all along . \nThis tells u"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 135,
    "text": "s that the corners are always good features to extract from an  image followed \nby the edges. \nLet's look at another example to understand this . Consider the images given below and \napply the concept of good features for the following. \n \n \n \nIn the above image how would we determine the exact location of each patch? \n \nThe blue patch is a flat area and difficult to find and track. Wherever you move the blue \npatch it looks the same. The black patch has an edge. Moved along the edge (parallel to \nedge), it looks the same. The red patch is a corner. Wherever you move the patch, it looks \ndifferent, therefore it is unique. Hence, corners are considered to be good features in an \nimage."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 136,
    "text": "5.5 Convolution \nWe have learnt that computers store images in numbers and that pixels are arranged in \na particular manner to create the picture we can recognize. These pixels have values varying \nfrom Oto 255 and the value of the pixel determines the color of that pixel. \nBut what if we edit these numbers, will it bring a change to the image? The answer is yes. As \nwe change the values of these pixels, the image changes. This process of changing pixel values \nis the base of image editing. \nWe all use a lot of images editing software like photoshop and at the same time use apps \nlike lnstagram and Snapchat, which apply filters to the image to enhance the quality of \nthat image. \n \n \nAs you can see, different filters applied to an image change the pixel values evenly \nthroughout the image. How does this happen? This is done with the help of the \nprocess of convolution and the convolution"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 136,
    "text": "operator which is commonly used to create \nthese effects."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 137,
    "text": "Before we understand how the convolution operation works, let us try  and create a \ntheory for the convolution operator by experiencing it using an online application. \n \nTask \nGo to  the link https://setosa.io/ev/image -kernels/and scroll down to check the  \nconvolution matrix applied on the image. \nTry changing the values in the convolution operator and observe the modifications \nin the output image. Try these steps \n5.6.1 Change all to positive values \n5.6.2 Change all to negative values \n5.6.3 Have a mixture of negative and positive values \n \nLet us follow  the following steps to  understand how a convolution  operator works. The \nsteps to be followed are: \n \n \n \nTry experimenting with the following values to come up with a theory: \n \n5.6.3.1 Make 4 numbers negative. Keep the rest \nas 0. 5.6.3.2Now make one of them positive. \n5.6.3.3 Observe what happens. \n5.6.3.4 Now make the second"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 137,
    "text": "positive. \n \n \nWhat theory do you propose for convolution based on the observation?"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 138,
    "text": "It is time to test the theory. Change the location of the four numbers and follow the above \nmentioned steps. Does your theory hold true? \n \n \n \n \n \n \n \nIf yes, change the picture and try whether the theory holds true or not. If it does not hold true, \nmodify your theory and keep trying until it satisfies all the conditions. \n \nLet's Discuss \n \nWhat effect did you apply? \n \n \n \n \n \n \nHow did different kernels affect the image? \n \n \n \n \n \n \nWhy do you think we apply these effects? \n \n \n \n \n \n \n \nHow do you think the convolution operator works?"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 139,
    "text": "Convolution: Explained \n \n \nConvolution is a simple mathematical operation that is fundamental to many common image \nprocessing operators. Convolution  provides a way of multiplying together two arrays of \nnumbers, generally of different sizes, but of the same dimensionality, to produce a third array \nof numbers of the same dimensionality. \n \n \nAn (image) convolution is simply an element-wise multiplication of image arrays and another  \narray called the kernel followed by sum."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 140,
    "text": "As you can see here, \nI= Image Array \nK = Kernel Array \nI * K = Resulting array after performing the convolution operator \nNote: The Kernel is passed over the whole image to get the resulting array after convolution. \n \nWhat is a Kernel? \nA Kernel is a matrix, which is slid across the image and multiplied with the input such that the \noutput is enhanced in a certain desirable manner. Each kernel has a different value for different \nkinds of effects that we want to apply to an image. \nIn Image processing, we use the convolution operation to extract the features from the images \nwhich can le later used for further processing especially in Convolution Neural Network (CNN), \nwhich we will study later in the chapter. \nIn this process, we overlap the centre of the image with the centre of the kernel to obtain the \nconvolution output. In the process  of doing it,  the output image becomes small"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 140,
    "text": "er  as the \noverlapping is done at the edge row and column of the image. What if we want the output \nimage to be of the exact size of the input image, how can we achieve this? \nTo achieve this, we need to extend the edge values out by one in the original image while \noverlapping the centres and performing the convolution. This will help us keep the input and \noutput image of the  same size. While extending the edges, the pixel values are considered \nzero."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 141,
    "text": "Write Your Output Here: \n \n \n \n        \n       \n       \n       \n       \n       \n       \n \nSummary \n1. Convolution is a common tool used for image editing. \n2. It is an element-wise multiplication of an image and a kernel to get the desired output. \n3. In computer vision applications, it is used in Convolutional Neural Network (CNN) to extract image \nfeatures."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 142,
    "text": "5.6 Convolution Neural Networks (CNN) \n \nIntroduction \nA Convolutional Neural Network (CNN) is a Deep Learning algorithm that can take in an \ninput image, assign importance (learnable weights and biases) to various aspects/objects \nin the image, and be able to differentiate one from the other. \n \nThe process of deploying a CNN is as follows: \n \n \nIn the above diagram, we give an input image, which is then processed through a CNN \nand then gives prediction based on the label given in the particular dataset. \n \nThe different layers of a Convolutional Neural Network (CNN) are as follows:"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 143,
    "text": "A convolutional neural network consists of the following layers: \n \n5.7.1 Convolution Layer \n5.7.2 Rectified linear unit (ReLU) \n5.7.3 Pooling Layer \n5.7.4 Fully Connected Layer \n \n5.7.1 Convolution Layer \n \nIt is the first layer of a CNN. The objective of the Convolution Operation is to extract the \nhigh-level features such as edges, from the input image. CNN need not be limited to only \none Convolutional  Layer. Conventionally, the first Convolution Layer is responsible for \ncapturing the Low -Level features  such as edges, colour, gradient  orientation, etc. With \nadded layers, the  architecture adapts to  the High-Level features as well, giving us a \nnetwork that has a wholesome understanding of images inthe  dataset. \n \nIt uses convolution operation on the images. In the convolution layer, several kernels are \nused to produce several features. The output of this layer is called the"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 143,
    "text": "feature map. A feature \nmap is also called an activation map. We can use these terms interchangeably. \nThere are several uses we derive from the feature map: \n• We reduce the image size so that it can be processed more efficiently. \n• We only focus on the features of the image that can help us in processing the \nimage further. For example, you might only need to recognize someone's eyes, nose, and \nmouth to recognize the person. You might not need to see the whole face."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 144,
    "text": "5.7.2 Rectified Linear Unit Function \n \nThe next layer in the Convolution Neural Network is the Rectified Linear Unit function or \nthe ReLU layer. After we get the feature map, it is then passed onto the ReLU layer. This \nlayer simply gets rid of  all the negative numbers  in the feature map and lets the positive \nnumber stay as it is. \n \nThe process of passing it to the ReLU layer introduces non - linearity in the feature map. \nLet us see it through a graph. \n \n \nIf we see the two graphs side by side, the one on the left is a linear graph. This graph \nwhen passed through the ReLU layer gives the one on the right. The ReLU graph starts with \na horizontal straight line and then increases linearly as it reaches a positive number. \n \nNow the question arises, why do we pass the feature map to the ReLU layer? It is to make \nthe colour change more obvious and more abrupt?"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 145,
    "text": "As shown in the above -convolved image, there is a smooth grey gradient change from \nblack to white. After applying the ReLu function, we can see a more abrupt color change \nwhich makes the edges more obvious and acts as a better feature for the further layers in a \nCNN as it enhances the activation layer. \n \n5.7.3 Pooling Layer \n \nSimilar to the Convolutional Layer, the Pooling layer is responsible for reducing the spatial \nsize of the Convolved Feature while still retaining the important features. \n \nTwo types of pooling can be performed on an image. \n1. Max Pooling: Max Pooling returns the maximum value from the portion of the image \ncovered by the Kernel. \n2. Average Pooling: Max Pooling returns the maximum value from the portion of the \nimage covered by the Kernel."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 146,
    "text": "The pooling layer is important in the CNN as it performs a series of tasks which are \nas follows: \n \n1. Makes the image smaller and more manageable \n2. Makes the  image more resistant to  small transformations, distortions,  and \ntranslations in the input image. \n \n \nA small difference in the input image will create a very similar pooled image. \n \n \n5.7.4 Fully Connected Layer \n \nThe final layer in the CNN is the Fully Connected Layer (FC layer). The objective of a fully \nconnected layer is to take the results of the convolution/pooling process and use them to \nclassify the image into a label (in a simple classification example). \n \nThe output of convolution/pooling is flattened into a single vector of values, each \nrepresenting a  probability that a certain feature belongs to a label. For example, if the \nimage is of a cat, features  representing things like whiskers  or fur should have"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 146,
    "text": "high \nprobabilities for the label \"cat\"."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 147,
    "text": "Let's Summarize: \n \n \n \nWrite the whole process of how a CNN works on the basis of the above diagram."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 148,
    "text": "Test Yourself: \n1. What is the primary objective of the Convolution Layer in a Convolutional Neural Network (CNN)? \nA) To flatten the input image \nB) To assign importance to various aspects/objects in the image \nC) To reduce the spatial size of the input image \nD) To perform element-wise multiplication of image arrays \n \n2. Which of the following tasks is an example of computer vision? \nA) Rescaling an image \nB) Correcting brightness levels in an image \nC) Object detection in images or videos \nD) Changing tones of an image \n \n3. How is resolution typically expressed? \nA) By the number of pixels along the width and height, such as 1280x1024 \nB) By the brightness level of each pixel, ranging from 0 to 255 \nC) By the total number of pixels, such as 5 megapixels \nD) By the arrangement of pixels in a 2-dimensional grid \n \n4. What is the core task of image classification? \nA) Identifying objec"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 148,
    "text": "ts and their locations in images \nB) Segmenting objects into individual pixels \nC) Assigning an input image one label from a fixed set of categories \nD) Detecting instances of real-world objects in images \n \n5. What is the function of the Rectified Linear Unit (ReLU) layer in a CNN? \nA) To reduce the image size for more efficient processing \nB) To assign importance to various aspects/objects in the input image \nC) To get rid of negative numbers in the feature map and retain positive numbers \nD) To perform the convolution operation on the input image \n \n6. Object detection and handwriting recognition are examples of tasks commonly associated with: \nA) Computer vision \nB) Image processing \nC) Both computer vision and image processing \nD) Neither computer vision nor image processing \n \n7. What does the pixel value represent in an image? \nA) Width of the pixel \nB) Brightness or color of the"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 148,
    "text": "pixel \nC) Height of the pixel \nD) Resolution of the pixel"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 149,
    "text": "8. In the byte image format, what is the range of possible pixel values? \nA) 0 to 10 \nB) 0 to 100 \nC) 0 to 1000 \nD) 0 to 255 \n \n9. In a grayscale image, what does the darkest shade represent? \nA) Total presence of color \nB) Zero value of pixel \nC) Lightest shade of gray \nD) Maximum pixel value \n10. In an RGB image, what does a pixel with an intensity value of 0 represent? \nA) Full presence of color \nB) No presence of color \nC) Maximum brightness level \nD) Minimum brightness level \n \n11. Assertion: Object detection is a more complex task than image classification because it \ninvolves identifying both the presence and location of objects in an image. \n \nReasoning: Object detection algorithms need to not only classify the objects present in an \nimage but also accurately localize them by determining their spatial extent. \n \nSelect the appropriate option for the statements given above: \nA) Bo"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 149,
    "text": "th A and R are true and R is the correct explanation of A \nB) Both A and R are true and R is not the correct explanation of A \nC) A is true but R is false \nD) A is False but R is true \n \n12. Assertion: Grayscale images consist of shades of gray ranging from black to white, where \neach pixel is represented by a single byte, and the size of the image is determined by its \nheight multiplied by its width. \n \nReasoning: Grayscale images are represented using a three intensities per pixel, typically \nranging from 0 to 255. \n \nSelect the appropriate option for the statements given above: \nA) Both A and R are true and R is the correct explanation of A \nB) Both A and R are true and R is not the correct explanation of A \nC) A is true but R is false \nD) A is False but R is true"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 150,
    "text": "Reflection Time: \n \n \n1. Imagine you have a smartphone camera app that can recognize objects. When you point \nyour camera at a dog, the app identifies it as a dog, analyzing patterns and features in the \nimage. Behind the scenes, the app's software processes the image, detecting edges, shapes, \nand colors, then compares these features to a vast database to make accurate \nidentifications.” \nIdentify the technology used in the above scenario and explain the way it works. \n \n \n2. Enlist two smartphone apps that utilize computer vision technology? How have these apps \nimproved your efficiency or convenience in daily tasks? \n \n3. How an RGB image is different from a grayscale image? \n \n4. Determine the color of a pixel based on its RGB values mentioned \nbelow: (i) R=0, B=0, G=0 \n(ii) R=255, B=255, G=255 \n(iii) R=0, B=0, \nG=255 (iv) R=0, B=255, \nG=0 \n \n5. Briefly describe the purpose of the co"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 150,
    "text": "nvolution operator in image processing. \n \n \n6.  What are the different layers in Convolutional Neural Network? What features are likely \nto be detected by the initial layers of a neural network and how is it different from what is \ndetected by the later layers? \n \n7. “Imagine you're a researcher tasked with improving workplace safety in a \nmanufacturing environment. You decide to employ computer vision technology to \nenhance safety measures.” \n \n8. How would you utilize computer vision in two distinct applications to promote safety \nwithin the manufacturing plant, ensuring both the physical well -being of employees \nand the efficiency of operations? \nProvide detailed explanations for each application, including the specific computer vision \ntechniques or algorithms you would employ, and how they would contribute to achieving \nyour safety goals. \n \n9.  Explain the distinctions between im"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 150,
    "text": "age classification, classification with localization, object \ndetection, and instance segmentation in computer vision tasks. Provide examples for each \nto support your answer."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 151,
    "text": "10.  “Agriculture is an industry where precision and efficiency are crucial for sustainable \nproduction. Traditional farming methods often rely on manual labor and visual inspection, \nwhich can be time - consuming and error -prone. However, advancements in compute r \nvision technology offer promising solutions to optimize various agricultural processes. \n \n \nAgricultural drones equipped with high-resolution cameras and computer vision algorithms \nare increasingly being used to monitor crop health, detect diseases, and assess crop yields.” \n \nAnswer the following questions based on the case study mentioned above: \nHow does the integration of computer vision technology with drones improve efficiency in \nagricultural practices compared to traditional methods? \n   What are some key indicators or parameters that computer vision algorithms can analyze    \n   to assess crop health and detect di"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 151,
    "text": "seases? \n \n11. You are tasked with developing a computer vision system for a self-driving car company.   The \nsystem needs to accurately detect and classify various objects on the road to ensure safe \nnavigation. Imagine you're working on improving the object detection algorithm for the self-\ndriving car's computer vision system. During testing, you notice that the system occasionally \nmisclassifies pedestrians as cyclists, especially in low-light conditions. \n                    How would you approach addressing this issue? What steps would you take to enhance             \n                    the accuracy of pedestrian detection while ensuring the system's overall performance and   \n                    reliability on the road?"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 152,
    "text": "Unit 6: Natural Language Processing \n \nLesson Title: Natural Language Processing Approach: Session + Activity \nSummary: Students will be introduced to the NLP and its importance. They will receive an  \noverview of the various stages of NLP and test processing techniques used in Natural  Language \nProcessing (NLP). They will undertake activities to appreciate the distinction  between the Code vs \nNo-code NLP. They will understand the Bag of Words algorithm and the concept of TFIDF. \nLearning Objectives: \n \nStudents are introduced to \n1. NLP and its importance. \n2. Various applications of NLP. \n3. Different stages of NLP. \n4. Various text processing techniques used in NLP. \n5. Different No-Code NLP tools. \n6. The Bag of Words model. \n7. The concept of TFIDF. \n8. No code Orange Data Mining Tool \nLearning Outcomes: \n \nStudents will be able to: \n \n1. Describe the importance of pre-processing"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 152,
    "text": "NLP data. \n2. Recognize the different steps of NLP data pre-processing. \n3. Learners will be able to list several applications of NLP which can be \nimplemented without code. \n4. Enlist different No-Code NLP tools. \n5. Outline the concept of the Bag of Words algorithm. \n6. Explain the process of TFIDF. \n7. Explain Sentiment Analysis \nPre-requisites: None \nKey-concepts: \n \n1. Natural Language Processing \n2. Applications of NLP \n3. Different stages of NLP \n4. Text Processing techniques used in NLP \n5. Bag of Word \n6. TFIDF \n7. No code – Orange Data Mining Tool"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 153,
    "text": "6.1 Introduction \nA natural language is a human language, such as French, Spanish, English, Japanese, etc. \nFeatures of Natural Languages \n• They are governed by set rules that include syntax, lexicon, and semantics. \n• All natural languages are redundant, i.e., the information can be conveyed in multiple \nways. \n• All natural languages change over time. \nTest Yourself: \nChoose the right word: \n1. I am so tired; I want to take a ? \n \n \n2. Let’s her a letter. \n \n \n \nDo you see how same-sounding words can have totally different meanings? \n• Different meanings in different contexts. \nLet’s consider these three sentences: \nHis face turned red after he found out that he took the wrong bag. \nWhat does this mean? Is he feeling ashamed because he took another person’s bag instead of \nhis? Is he feeling angry because he did not manage to steal the bag that he has been  \ntargeting? \n \n \nThe red ca"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 153,
    "text": "r zoomed past his nose. \nProbably talking about the colour of the car"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 154,
    "text": "His face turns red after consuming the medicine. \nIs he having an allergic reaction? Or was he ashamed because he lost a bet (“I will not fall \nsick because of this”)? Or was he taking a medicine that dilates the artery? \n \n \nHere we can see that context is important. We understand a sentence almost intuitively, \ndepending on our history of using the language, and the memories that have been built \nwithin. In all three sentences, the word red has been used in three different ways which \naccording to the context of the statement changes its meaning completely. Thus, in natural \nlanguage, it is important to understand that a word can have multiple meanings and the \nmeanings fit into the statement according to the context of it. \n \n \nThink of some other words which can have multiple meanings and use them in sentences. \n \n \n \n \n \n \n \nComputer Language \nComputer languages are languages used t"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 154,
    "text": "o interact with a computer, such as Python, C++, \nJava, HTML, etc. \n \n \nCan computers understand our language? \nComputers require a specific set of instructions to  \nunderstand human input called programs. To talk to a \ncomputer, we convert natural language into a \nlanguage that a computer understands. We need \nNatural Language Processing to help computers  \nunderstand natural language. \nWhy is NLP important? \nComputers can only process electronic signals in the  \nform of binary language. Natural Language Processing \nfacilitates this conversion to digital form from the  \nnatural form. Thus, the whole purpose of NLP is to \nmake communication between computer systems and \nhumans possible. This includes creating different tools \nand techniques that facilitate better communication of \nintent and context."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 155,
    "text": "Demystify Natural Language Processing (NLP) \nNatural Language Processing, or NLP, is the sub -field of AI that is focused on enabling  \ncomputers to analyse, understand and process human languages to derive meaningful \ninformation from human language. \n \n \n \n6.2 Applications of Natural Language Processing \nSince Artificial Intelligence nowadays is becoming an integral part of our lives, its \napplications are very commonly used by the majority of people in their daily lives. Here are \nsome of the applications of Natural Language Processing which are used in the real-life \nscenario: \n \n \nAutogenerated captions: Captions are \ngenerated by turning natural speech into text in \nreal-time. It is a valuable feature for enhancing  \nthe accessibility of video content. \nFor example: \nAuto-generated captions on YouTube and Google \nMeet. \n \n \n \nVoice assistants: Voice assistants take \nour natural spe"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 155,
    "text": "ech, process it, and give  \nus an output. These assistants leverage  \nNLP to understand natural language and  \nexecute tasks efficiently.  \nFor example: \nHey Google, set an alarm at 3.30 pm \nHey Alexa, play some music \nHey Siri, what's the weather today \n  \nLanguage Translation: It incorporates  \nthe generation of translation from another \nlanguage. This involves the conversion of text \nor speech from one language to  another, \nfacilitating cross-linguistic \ncommunication and fostering global \nconnectivity. \nFor example: \nGoogle Translate"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 156,
    "text": "Sentiment Analysis: Sentiment Analysis is a \ntool to express an opinion, whether the \nunderlying sentiment is positive, negative, or \nneutral. Customer sentiment analysis helps in the \nautomatic detection of emotions when \ncustomers interact with the products, services, or \nbrand \n \n \nText Classification: Text classification is \na tool which classifies a sentence or  \ndocument category-wise. \nIn the example, we can observe news  \narticles containing information on various \nsectors, including Food, Sports, and Politics, \nbeing categorized through the text \nclassification process. This process classifies \nthe raw texts into predefined groups or  \ncategories. \n \n \nKeyword Extraction: Keyword extraction is a \ntool that automatically extracts the most used, \nimportant words and expressions from a text. It \ncan give valuable insights into people’s opinions \nabout any business on social media."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 156,
    "text": "Customer  \nService can be improved by using a Keyword  \nextraction tool. \n \n \nActivity 1: Keyword Extraction \n \n \nPurpose: To learn how to utilize an API for performing keyword extraction from a website. \n \n \nSay: “Keyword extraction in NLP involves automatically identifying and extracting the most important \nwords or phrases from a piece of text. These keywords represent the main topics or themes within \nthe text and are useful for tasks like document summarization, information retrieval, and \ncontent analysis.”"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 157,
    "text": "STEP – 1: Go to the given website:  \nhttps://cloud.google.com/natural-language \n \n \n \n \nSTEP – 2: Click on ‘Analyze’ and check the results. \n \n \n \n• The keywords from the  \nparagraph in the textbox have  \nbeen highlighted in different  \ncolours e.g., Google, Mountain \nView, etc. \n \n• Click on other options to check \nthe output. \n \n• Use your own text in the text box \nand observe the results."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 158,
    "text": "6.3 Stages of Natural Language Processing (NLP) \nThe different stages of Natural Language Processing (NLP) serve various purposes in the overall \ntask of understanding and processing human language. The stages of Natural  Language \nProcessing (NLP) typically involve the following: \n \n \n \n \nLexical Analysis: \nNLP starts with identifying the structure of input words. It is the process of dividing \na large chunk of words into structural paragraphs, sentences, and words. Lexicon stands for a \ncollection of the various words and phrases used in a language. \n \n \n \nLengthy text is broken down into chunks."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 159,
    "text": "Syntactic Analysis / Parsing \nIt is the process of checking the grammar of sentences and phrases. It forms a relationship \namong words and eliminates logically incorrect sentences. \n \n \n \n \nThe grammar is correct! \nSemantic Analysis \nIn this stage, the input text is now checked for meaning, and every word and phrase is checked \nfor meaningfulness. \nFor example: \nIt will reject a sentence that contains ‘hot ice cream’ in it. The \nfox jumped into the dog. \n \nSentences make actual sense!"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 160,
    "text": "Discourse Integration \nIt is the process of forming the story of the sentence. Every sentence should have a \nrelationship with its preceding and succeeding sentences. \n \nThe flow of words makes sense! \nPragmatic Analysis \nIn this stage, sentences are checked for their relevance in the real world. Pragmatic means \npractical or logical, i.e., this step requires knowledge of the intent in a sentence. It also \nmeans to discard the actual word meaning taken after semantic analysis and take the intended \nmeaning. \n \nThe intended meaning has been achieved!"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 161,
    "text": "In summary, \n \n \n \nTest Yourself: \nChoose the right word: \n1. Syntax refers to the grammatical structure of a sentence. \n \n \n \n \n2. Which technique is used to assess the meaningfulness of the input text?"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 162,
    "text": "Now, there are already many chatbots developed out there, and many of them use \nthe process we have used to create their chatbot. Let’s try some chatbots that have \nbeen deployed already. \n6.4 Chatbots \n \nActivity 2: Play with chatbots \n \n \nOne of the most common applications of Natural Language Processing is a chatbot. A chatbot \nis a computer program that's designed to simulate human conversation through voice \ncommands or text chats or both. It can learn over time how to best interact with \nhumans. It can answer questions and troubleshoot customer problems, evaluate and qualify \nprospects, generate sales leads and increase sales on an ecommerce site. There are a lot of  \nchatbots available. Let us try some of the chatbots and see how they work. \n \n \n \n \nElizabot - https://www.masswerk.at/elizabot/ \nMitsuki - https://www.kuki.ai/ \nCleverbot - https://www.cleverbot.com/ \nSingtel - https"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 162,
    "text": "://www.singtel.com/personal/support \nPurpose: Identify and interact with different chatbots. \n \n \nSay: “Have you ever wondered why chatbots are created? They are meant to make it feel as if we are \ntalking to a real human as this is the way we are comfortable with. There are several chatbots here. \nI will split you into groups. Spend some time interacting with the chatbot, and then we will review \nour experience.”"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 163,
    "text": "Let us discuss it! \n• Which chatbot did you try? Name anyone. \n• What is the purpose of this chatbot? \n• How was the interaction with the chatbot? \n• Did the chat feel like talking to a human or a robot? Why do you think so? \n• Do you feel that the chatbot has a certain personality? \nAs you interact with more and more chatbots, you would realise that some of them are  \nscripted or in other words are traditional chatbots while others are AI-powered and have \nmore knowledge. With the help of this experience, we can understand that there are 2 types \nof chatbots around us: Script-bot and Smart-bot. Let us understand what each of them \nmeans in detail. \n \n \n \n \n \n \nQuiz Time \n1. Natural Language Processing majorly deals with__________ processing. \na. Numeric data b. Textual data \nc. Image data d. Visual data \n2. ______________is an NLP tool to express an opinion, whether the underlying \nsent"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 163,
    "text": "iment is positive, negative, or neutral."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 164,
    "text": "a. Text Classification b. Machine Translation \nc. Sentiment Analysis d. Automatic Text Summarization \n3. What is the first stage of Natural Language Processing (NLP)? \na. Semantic Analysis b. Pragmatic Analysis \nc. Lexical Analysis d. Syntactic Analysis \n4. Words that we want to filter out before doing any analysis of the text are called__________. \na. Rare words b. Stop words \nc. Frequent words d. Filter words \n5. What does discourse integration involve in the context of sentence formation? \na. Identifying individual words in a sentence \nb. Forming a coherent story within a sentence \nc. Establishing relationships between preceding and succeeding sentences \nd. Applying punctuation and grammar rules to a sentence \n6.5 Text Processing \nHumans interact with each other very easily. For us, the natural languages that we use are so \nconvenient that we speak them easily and understand them well"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 164,
    "text": "too. But for computers, our \nlanguages are very complex. As you have already gone through some of the complications in \nhuman languages above, now it is time to see how Natural Language Processing makes it  \npossible for machines to understand and speak in Natural Languages just like humans. \nSince we all know that the language of computers is Numerical, the very first step that comes \nto our mind is to convert our language to numbers. This conversion takes a few steps \nto happen. The first step to it is Text Normalisation. Since human languages are complex, we \nneed to first of all simplify them in order to make sure that understanding becomes possible. \nText Normalisation helps in cleaning up the textual data in such a way that it comes down to \na level where its complexity is lower than the actual data. Let us go through Text \nNormalisation in detail. \nText Normalisation \nIn Text Nor"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 164,
    "text": "malisation, we undergo several steps to normalise the text to a lower level. Before \nwe begin, we need to understand that in this section, we will be working on a  collection of \nwritten text. That is, we will be working on text from multiple documents and the term used \nfor the whole textual data from all the documents altogether is known as  corpus. Not only \nwould we go through all the steps of Text Normalisation, we would also  work them out on a \ncorpus. Let us take a look at the steps:"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 165,
    "text": "Sentence Segmentation \nUnder sentence segmentation, the whole corpus is divided into sentences. Each sentence is \ntaken as a different data so now the whole corpus gets reduced to sentences. \n \n \nTokenization \nAfter segmenting the sentences, each sentence is then further divided into tokens. Tokens is \na term used for any word or number or special character occurring in a sentence. Under  \ntokenisation, every word, number and special character is considered separately and each of \nthem is now a separate token."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 166,
    "text": "Removing Stop words, Special Characters and Numbers \nIn this step, the tokens which are not necessary are removed from the token list. What are the \npossible words which we might not require? \nStop words are the words which occur very frequently in the corpus but do not add any value \nto it. Humans use grammar to make their sentences meaningful for the other person  to \nunderstand. But grammatical words do not add any essence to the information which is to be \ntransmitted through the statement hence they come under stop words. Some examples  of \nstop words are: \n \n \n \n \nThese words occur the most in any given corpus but talk very little or nothing about the \ncontext or the meaning of it. Hence, to make it easier for the computer to focus on \nmeaningful terms, these words are removed. \nAlong with these words, a lot of times our corpus might have special characters and/or  \nnumbers. Now it"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 166,
    "text": "depends on the type of corpus that we are working on whether we should \nkeep them in it or not. For example, if you are working on a document containing email IDs, \nthen you might not want to remove the special characters and numbers whereas in some \nother textual data if these characters do not make sense, then you can remove them along \nwith the stop words. \n \n \nConverting Text to a Common Case \nAfter the stop words removal, we convert the whole text into a similar case, preferably \nlowercase. This ensures that the case sensitivity of the machine does not consider the same \nwords as different just because of different cases."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 167,
    "text": "Here in this example, all the 6 forms of hello would be converted to lowercase and hence \nwould be treated as the same word by the machine. \n \n \nStemming \nIn this step, the remaining words are reduced to their root words. In other words, stemming is \nthe process in which the affixes of words are removed and the words are converted to  their \nbase form. \n \n \n \n \nNote that in stemming, the stemmed words (words that we get after removing the affixes)  \nmight not be meaningful. Here in this example as you can see: healed, healing and healer all \nwere reduced to heal but studies was reduced to studi after the affix removal which is not a \nmeaningful word. Stemming does not take into account whether the stemmed word is \nmeaningful or not. It just removes the affixes hence it is faster. \n \n \nWord Affixes Stem \nhealed -ed heal \nhealing -ing heal \nhealer -er heal \nstudies -es studi \nstudying -ing"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 167,
    "text": "study"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 168,
    "text": "Lemmatization \nStemming and lemmatization both are alternative processes to each other as the role of both \nthe processes is same – removal of affixes. But the difference between both of them is that in \nlemmatization, the word we get after affix removal (also known as lemma) is a \nmeaningful one. Lemmatization makes sure that a lemma is a word with meaning and hence \nit takes a longer time to execute than stemming. \n \n \n \nWord Affixes Stem \nhealed -ed heal \nhealing -ing heal \nhealer -er heal \nstudies -es study \nstudying -ing study \n \n \nAs you can see in the same example, the output for studies after affix removal has become \nstudy instead of studi. \n \nThe difference between stemming and lemmatization can be summarized by this example: \n \n \n \n \n \nWith this, we have normalised our text to tokens which are the simplest form of words \npresent in the corpus. Now it is time to convert the tok"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 168,
    "text": "ens into numbers. For this, we would \nuse the Bag of Words algorithm"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 169,
    "text": "Bag of Words \nBag of Words is a Natural Language Processing model which helps in extracting features out \nof the text which can be helpful in machine learning algorithms. In the bag of words, we get \nthe occurrences of each word and construct the vocabulary for the corpus. \n \n \n \n \nThis image gives us a brief overview of how the bag of words works. Let us assume that the  \ntext on the left in this image is the normalised corpus which we have got after going through \nall the steps of text processing. Now, as we put this text into the bag of words algorithm, the \nalgorithm returns to us the unique words out of the corpus and their occurrences in it. As you \ncan see on the right, it shows us a list of words appearing in the corpus and the numbers \ncorresponding to it show how many times the word has occurred in the text body. Thus, we  \ncan say that the bag of words gives us two things: \n1."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 169,
    "text": "A vocabulary of words for the corpus \n2. The frequency of these words (number of times it has occurred in the whole corpus). \nHere calling this algorithm a “bag” of words symbolises that the sequence of sentences or  \ntokens does not matter. In this case, all we need are the unique words and their frequency. \n \n \nHere is the step-by-step approach to implementing the bag of words algorithm: \n1. Text Processing: Collect data and pre-process it \n2. Create a Dictionary: Make a list of all the unique words occurring in the corpus. \n(Vocabulary) \n3. Create document vectors: For each document in the corpus, find out how many times the \nword from the unique list of words has occurred."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 170,
    "text": "4. Create document vectors for all the documents. \n \n \nLet us go through all the steps with an example: \nStep 1: Collecting data and pre-processing it. \n \n \nDocument 1: Aman and Avni are stressed \n \n \nDocument 2: Aman went to a therapist \n \n \nDocument 3: Avni went to download a health chatbot \n \n \nHere are three documents having one sentence each. After text normalisation, the text \nbecomes: \nDocument 1: [aman, and, avni, are, stressed] \nDocument 2: [aman, went, to, a, therapist] \nDocument 3: [avni, went, to, download, a, health, chatbot] \n \nStep 2: Create a Dictionary \nGo through all the steps and create a dictionary i.e., list down all the words which occur in all \nthree documents: \nDictionary: \n \naman and avni are stressed went \ndownload health chatbot therapist a to \n \nNote that even though some words are repeated in different documents, they are all written \njust once as while creat"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 170,
    "text": "ing the dictionary, we create the list of unique words. \n \n \nStep 3: Create a document vector \nIn this step, the vocabulary is written in the top row. Now, for each word in the document, if it \nmatches the vocabulary, put a 1 under it. If the same word appears again, increment the  \nprevious value by 1. And if the word does not occur in that document, put a 0 under it."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 171,
    "text": "aman and avni are stressed went to a therapist download health chatbot \n`1 1 1 1 1 0 0 0 0 0 0 0 \n \n \nSince, in the first document, we have words: aman, and, avni, are, stressed. So, all these words \nget a value of 1 and the rest of the words get a 0 value. \n \n \nStep 4: Create document vectors for all the documents. \nThe same exercise has to be done for all the documents. Hence, the table becomes: \n \naman and avni are stressed went to a therapist download health chatbot \n`1 1 1 1 1 0 0 0 0 0 0 0 \n1 0 0 0 0 1 1 1 1 0 0 0 \n0 0 1 0 0 1 1 1 0 1 1 1 \n \nIn this table, the header row contains the vocabulary of the corpus and three rows \ncorrespond to three different documents. Take a look at this table and analyse the \npositioning of 0s and 1s in it. \nFinally, this gives us the document vector table for our corpus. However, the \ntokens have still not been converted to numbers. This leads us to"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 171,
    "text": "the final step of \nour algorithm: TFIDF. \n \n \nTFIDF: Term Frequency & Inverse Document Frequency \nSuppose you have a book. Which characters or words do you think would occur the most in it? \n \n \n \n \n \nThe bag of words algorithm gives us the frequency of words in each document we have in our \ncorpus. It gives us an idea that if the word is occurring more in a document, its value is  more \nfor that document. For example, if I have a document on air pollution, air and pollution would \nbe the words which occur many times in it. And these words are valuable too as they  give us \nsome context around the document. But let us suppose we have 10 documents and  all of \nthem talk about different issues. One is on women's empowerment; the other is on  \nunemployment and so on. Do you think air and pollution would still be one of the most  \noccurring words in the whole corpus? If not, then which words"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 171,
    "text": "do you think would have the  \nhighest frequency in all of them?"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 172,
    "text": "And, this, is, the, etc. are the words which occur the most in almost all the documents. But  \nthese words do not talk about the corpus at all. Though they are important for humans as  \nthey make the statements understandable to us, for the machine they are a complete waste \nas they do not provide us with any information regarding the corpus. Hence, these are \ntermed as stop words and are mostly removed at the pre-processing stage only. \n \n \n \nTake a look at this graph. It is a plot of the occurrence of words versus their value. As you can \nsee, if the words have the highest occurrence in all the documents of the corpus, they are said \nto have negligible value hence they are termed as stop words. These words are mostly  \nremoved at the pre-processing stage only. Now as we move ahead from the stop words, the  \noccurrence level drops drastically and the words which have adequate occurrence"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 172,
    "text": "in the  \ncorpus are said to have some amount of value and are termed as frequent words. These words \nmostly talk about the document’s subject and their occurrence is adequate in the  corpus. \nThen as the occurrence of words drops further, the value of such wo rds rises. These  words \nare termed as rare or valuable words. These words occur the least but add the most  value to \nthe corpus. Hence, when we look at the text, we consider frequent and rare words. \nLet us now demystify TFIDF. TFIDF stands for Term Frequency and Inverse Document \nFrequency. TFIDF helps us identify the value of each word. Let us understand each term one \nby one. \n \n \nTerm Frequency \nTerm frequency is the frequency of a word in one document. Term frequency can easily be  \nfound in the document vector table as in that table we mention the frequency of each word \nof the vocabulary in each document."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 173,
    "text": "Here, you can see that the frequency of each word for each document has been recorded in \nthe table. These numbers are nothing but the Term Frequencies! \n \n \nInverse Document Frequency \nNow, let us look at the other half of TFIDF which is Inverse Document Frequency. For this, let \nus first understand what document frequency means. Document Frequency is the number of \ndocuments in which the word occurs irrespective of how many times it has occurred in those \ndocuments. The document frequency for the exemplar vocabulary would be: \n \nHere, you can see that the document frequency of ‘aman’, ‘avni’, ‘went’, ‘to’ and ‘a’ is 2 as they \nhave occurred in two documents. The rest of them occurred in just one document hence the \ndocument frequency for them is one. \nTalking about inverse document frequency, we need to put the document frequency in the  \ndenominator while the total number of documents"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 173,
    "text": "is the numerator. Here, the total number \nof documents is 3, hence inverse document frequency becomes: \n \n \n \n \n \nFinally, the formula of TFIDF for any word W becomes: \nTFIDF(W) = TF(W) * log( IDF(W) ) \nHere, log is to the base of 10. Don’t worry! You don’t need to calculate the log values by \nyourself. Simply use the log function in the calculator and find out! \nNow, let’s multiply the IDF values by the TF values. Note that the TF values are for each  \ndocument while the IDF values are for the whole corpus. Hence, we need to multiply the IDF \nvalues to each row of the document vector table."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 174,
    "text": "Here, you can see that the IDF values for Aman in each row are the same and a similar  \npattern is followed for all the words of the vocabulary. After calculating all the values, we get: \n \nFinally, the words have been converted to numbers. These numbers are the values of each  \nfor each document. Here, you can see that since we have less amount of data, words like ‘are’ \nand ‘and’ also have a high value. But as the IDF value increases, the value of that word \ndecreases. That is, for example: \nTotal Number of documents: 10 \nNumber of documents in which ‘and’ occurs: 10 \nTherefore, IDF(and) = 10/10 = 1 \nWhich means: log(1) = 0. Hence, the value of ‘and’ becomes 0. \nOn the other hand, the number of documents in which ‘pollution’ occurs: 3 IDF(pollution) = \n10/3 = 3.3333… \nThis means log(3.3333) = 0.522; which shows that the word ‘pollution’ has considerable value \nin the corpus. \nSummarisi"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 174,
    "text": "ng the concept, we can say that: \n1. Words that occur in all the documents with high term frequencies have the lowest values \nand are considered to be the stop words. \n2. For a word to have a high TFIDF value, the word needs to have a high term frequency but \nless document frequency which shows that the word is important for one document but is  \nnot a common word for all documents. \n3. These values help the computer understand which words are to be considered while  \nprocessing the natural language. The higher the value, the more important the word is for a \ngiven corpus."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 175,
    "text": "Applications of TFIDF \nTFIDF is commonly used in the Natural Language Processing domain. Some of its applications \nare: \n \n \nDocument \nClassification \nTopic Modelling Information \nRetrieval System \nStop word filtering \nHelps in classifying \nthe type and genre \nof a document. \nIt helps in predicting \nthe topic for a \ncorpus. \nTo extract the \nimportant \ninformation out of a \ncorpus. \nHelps in removing  \nunnecessary words \nfrom a text body. \n \n \n6.6 Natural Language Processing: Use Case Walkthrough \n \n \nExamples of Code and No-code NLP Tools \n \n \nCode NLP No-Code NLP \nNLTK package: Natural Language Tool Kit or \nNLTK is a package readily available for text  \nprocessing in Python. The package contains \nfunctions and modules which can be used \nfor Natural Language Processing. \nOrange Data Mining: It is a machine \nlearning tool for data analysis through \nPython and visual programming. We can"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 175,
    "text": "perform operations on data through simple \ndrag-and-drop steps. \n \nSpaCy: SpaCy is an open-source natural \nlanguage processing (NLP) library designed \nto build NLP applications. It offers various  \nfeatures such as tokenization, part-of- \nspeech tagging, named entity recognition, \ndependency parsing, and more. \nMonkeyLearn: MonkeyLearn is a text  \nanalysis platform that offers NLP tools and  \nmachine learning models for text analysis,  \nsupporting tasks such as classification,  \nsentiment analysis, and entity recognition.  \nUsers can create custom models or use pre- \ntrained ones for tasks like social media \nmonitoring and customer feedback analysis. \n \n \n \n \n \nPurpose: Students are introduced to the No-code tools for Natural Language Processing. \nThey will learn about Sentiment Analysis, one of the applications of NLP with the No-code tool \nOrange Data Mining. Learners will be able to u"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 175,
    "text": "nderstand this application with use cases"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 176,
    "text": "Applications of NLP \nIntroduction to Sentiment Analysis \n \nSentiment analysis is a natural language processing (NLP) technique used to analyze whether \na given textual data is positive, negative, or neutral. \nApplications of Sentiment Analysis-Customer Service \n \nCustomer sentiment analysis helps in the automatic detection of emotions when customers \ninteract with products, services, or brands. \nApplications of Sentiment Analysis –Voice of the Customer \n \n• Voice of the customer analysis helps to analyze customer feedback and gain \nactionable insights from it. \n• It measures the gap between what customers expect and what they actually \nexperience when they use the products or services,"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 177,
    "text": "Now, let’s understand Sentiment Analysis in detail using the Orange Data Mining tool. \nFollow the given link to understand the technique. \n \nTest Yourself: \n1. What is the primary challenge faced by computers in understanding human languages? \nA) Complexity of human languages \nB) Lack of computational power \nC) Incompatibility with numerical data \nD) Limited vocabulary \n2. How do voice assistants utilize NLP? \nA) To analyze visual data \nB) To process numerical data \nC) To understand natural language \nD) To execute tasks based on computer code \n3. Which of the following is NOT a step in Text Normalisation? \nA) Tokenization \nB) Lemmatization \nC) Punctuation removal \nD) Document summarization \n4. In the context of text processing, what is the purpose of tokenisation? \nA) To convert text into numerical data \nB) To segment sentences into smaller units \nC) To translate text into multiple langu"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 177,
    "text": "ages \nD) To summarize documents for analysis \n5. What distinguishes lemmatization from stemming? \n \nCase Walkthrough – Steps involved in project development \nShort Link - https://bit.ly/OrangeNLP \nLong Link - https://drive.google.com/drive/u/2/folders/1geFLXxV5890kfcakMfEg_KsH1LPcS_Iz \nOr Scan the QR code provided below."
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 178,
    "text": "A) Lemmatization produces meaningful words after affix removal, while stemming does not. \nB) Lemmatization is faster than stemming. \nC) Stemming ensures the accuracy of the final word. \nD) Stemming generates shorter words compared to lemmatization. \n6. What is the primary purpose of the Bag of Words model in Natural Language Processing? \nA) To translate text into multiple languages \nB) To extract features from text for machine learning algorithms \nC) To summarize documents for analysis \nD) To remove punctuation marks from text \n7. In the context of text processing, what are stop words? \nA) Words with the frequent occurrence in the corpus \nB) Words with negligible value that are often removed during preprocessing \nC) Words with the lowest occurrence in the corpus \nD) Words with the most value added to the corpus \n8. What is the characteristic of rare or valuable words in the described plo"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 178,
    "text": "t? \nA) They have the highest occurrence in the corpus \nB) They are often considered stop words \nC) They occur the least but add the most value to the corpus \nD) They are typically removed during preprocessing \n9. What information does the document vector table provide? \nA) The frequency of each word across all documents \nB) The frequency of each word in a single document \nC) The total number of words in the entire corpus \nD) The average word length in the entire corpus \n10. What is the primary purpose of TFIDF in text processing? \nA) To identify the presence of stop words in documents \nB) To remove punctuation marks from text \nC) To identify the value of each word in a document \nD) To translate text into multiple languages"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 179,
    "text": "11. Assertion: Pragmatic analysis in natural language processing (NLP) involves assessing \nsentences for their practical applicability in real-world scenarios. \nReasoning: Pragmatic analysis requires understanding the intended meaning behind \nsentences and considering their practical or logical implications, rather than solely relying on \nliteral word meanings obtained from semantic analysis. \nA) Both Assertion and Reasoning are true, and Reasoning is the correct explanation of the \nAssertion. \nB) Assertion is true, but Reasoning is false. \nC) Both Assertion and Reasoning are true, but Reasoning is not the correct explanation of \nthe Assertion. \nD) Assertion is false, but Reasoning is true. \n12. Assertion: Converting the entire text into lowercase following stop word removal is a \ncrucial preprocessing step in natural language processing. \nReasoning: This process ensures uniformity in wo"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 179,
    "text": "rd representation, preventing the machine \nfrom treating words with different cases as distinct entities, thereby enhancing the accuracy \nof subsequent text analysis. \nA) Both Assertion and Reasoning are true, and Reasoning is the correct explanation of the \nAssertion. \nB) Assertion is true, but Reasoning is false. \nC) Both Assertion and Reasoning are true, but Reasoning is not the correct explanation of \nthe Assertion. \nD) Assertion is false, but Reasoning is true. \n \nReflection Time: \n1. Mention a few features of natural languages. \n2. What is the significance of NLP? \n3. What do you mean by lexical analysis in NLP? \n4. What do you mean by a chatbot? \n5. What does the term \"Bag of Words\" refer to in Natural Language Processing (NLP)? \n6. Describe two practical uses of Natural Language Processing in real-world scenarios. \n7. Explain the process of stemming and lemmatization in text proc"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 179,
    "text": "essing, supported by an \nexample. \n8. Describe any four applications of TFIDF. \n9. Samiksha, a student of class X was exploring the Natural Language Processing domain. She"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 180,
    "text": "got stuck while performing the text normalisation. Help her to normalise the text on the  \nsegmented sentences given below: \nDocument 1: Akash and Ajay are best friends. \nDocument 2: Akash likes to play football but Ajay prefers to play online games. \n10. Through a step-by-step process, calculate TFIDF for the given corpus \nDocument 1: Johny Johny Yes Papa, \nDocument 2: Eating sugar? No Papa \nDocument 3: Telling lies? No Papa \nDocument 4: Open your mouth, Ha! Ha! Ha!"
  },
  {
    "path": "C:\\Users\\Vaibhav Gupta\\Downloads\\mini-rag-agent\\data\\sample\\AI_Facilitators_Handbook_X.pdf",
    "page": 181,
    "text": "CLASS – X ANSWER KEY (Unit-End Exercise) \n \n \nUNIT – 1: Ethical Frameworks for AI \nTEST YOURSELF \n1. B 2. C 3. B 4. D 5. C 6. B 7. B 8. C 9. A 10. B 11. A 12. A \n \n \nUNIT – 2: Advanced Concepts of Modelling in AI \nTEST YOURSELF \n1. A 2.A 3. B 4. C 5. C 6. B 7. D 8. B 9. C 10. A 11. B 12. B \n \n \nUNIT – 3: Evaluating Models \nTEST YOURSELF \n1. B 2.A 3. A 4. B 5. A 6. B 7. A 8. B 9. B 10. C \n \n \nUNIT – 4.1: Statistical Data \nTEST YOURSELF \n1. A 2. D 3. D 4. A 5. A \n \n \nUNIT – 4.2: Statistical Data \nTEST YOURSELF \n1. B 2. B 3. A 4. C 5. A \n \n \nUNIT – 5: Computer Vision \nTEST YOURSELF \n1. B 2. C 3. A 4. C 5. C 6. A 7. B 8. D 9. B 10. B 11. A 12. C \n \nUNIT – 6: Natural Language Processing  \nTest Yourself \n1. A 2. C 3. D 4. B 5. A 6. B 7. B 8. C 9. A 10. C 11. A 12. A"
  }
]